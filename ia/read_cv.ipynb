{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read PDF\n",
    "\n",
    "# from dotenv import load_dotenv\n",
    "# Charger les variables d'environnement\n",
    "# load_dotenv()\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def read_pdf(file_path: str) -> str:\n",
    "    \"\"\"Lit et extrait le texte d'un CV au format PDF d'une seule page.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Chemin d'accès vers le fichier PDF à lire\n",
    "\n",
    "    Returns:\n",
    "        str: Texte brut extrait du PDF\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: Si le fichier PDF n'existe pas\n",
    "        IndexError: Si le PDF est vide\n",
    "        Exception: Pour toute autre erreur lors de la lecture du PDF\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reader = PdfReader(file_path)\n",
    "        if len(reader.pages) == 0:\n",
    "            raise IndexError(\"Le PDF est vide\")\n",
    "        \n",
    "        page = reader.pages[0]  # Lecture de la première page uniquement\n",
    "        text_brut = page.extract_text()\n",
    "        \n",
    "        if not text_brut:\n",
    "            raise Exception(\"Aucun texte n'a pu être extrait du PDF\")\n",
    "            \n",
    "        return text_brut\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Le fichier {file_path} n'existe pas\")\n",
    "    except IndexError as e:\n",
    "        raise IndexError(str(e))\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Erreur lors de la lecture du PDF: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quentin Lim  \n",
      "Last year Student in \n",
      "Data Science\n",
      "quentinlim 384@ gm ail.com\n",
      "+33782885515\n",
      "linkedin.com /in/quentin-lim-\n",
      "978746250\n",
      "github.com /QL2111\n",
      "Profile\n",
      "Currently seeking an internship in \n",
      "Data Science starting in March \n",
      "2025 for a duration of 4 to 6 \n",
      "months.\n",
      "Skills\n",
      "M L, NLP, TensorFlow; Scikit-learn, \n",
      "M LFlow, Transform ers, LLM , Tim e \n",
      "Series.\n",
      "SQL, NoSQL, M ongoDB\n",
      "Qlik, Tableau, PowerBI\n",
      "OpenCV, YOLO\n",
      "Azure, AW S, Fabric\n",
      "Git/Agile m ethodology\n",
      "Python/R/Java/PySpark/JavaScript/\n",
      "PHP\n",
      "Gen AI\n",
      "Interests\n",
      "Board Games: Casual boarding\n",
      "gam es and Chess club\n",
      "Gaming: Played in competitives\n",
      "tournam ents, peaked GrandMaster\n",
      "in League of Legends\n",
      "Sailing: M em ber of the sailing club\n",
      "at La Rochelle Université\n",
      "Basket ball: Sports association\n",
      "during M iddle School, teamwork\n",
      "and fast decision making.\n",
      "Volunteering\n",
      "ESN Cosmolyon\n",
      "2023 – present\n",
      "Vice-President, holdings Culturals \n",
      "Event for internationals and local \n",
      "student(Board gam es/Day \n",
      "trips/Spanish dinner)\n",
      "Alter-ego Lyon 2\n",
      "2023 – present\n",
      "Buddy System  with Lyon 2 \n",
      "UniversityEducation\n",
      "Master in Data Science, Université Lyon 2 Lumière\n",
      "09/2023 – present\n",
      "•Expertise in advanced data analysis: ANOVA, time series, biostatistics, NLP/LLM, \n",
      "Computer Vision, and Deep Learning.\n",
      "•Proficiency in Big Data and MLOps: web scraping, data warehouses, model \n",
      "deployment, and pipelines.\n",
      "•Specialized in predictive analytics, focusing on the use of advanced statistical \n",
      "models and machine learning algorithms for forecasting and decision making.\n",
      "International Exchange Program, National Central University\n",
      "Taoyuan, Taïwan\n",
      "•GPA: 3.8 | Experience in data mining for biological data: autism classification, \n",
      "sentiment analysis and Graph Neural Networks presentation on Reddit data.\n",
      "•Research & Publications: Conducted a literature review on feature selection \n",
      "techniques and co-authored \"A Review of Feature Selection Techniques in Education\". \n",
      "Explored Transformer models for advanced data analysis.\n",
      "Erasmus + Mobility, South East Technological University\n",
      "Waterford, Ireland\n",
      "•First Class Honours | EDA & predictive modeling on Titanic and Tips datasets with \n",
      "up to 90% accuracy, NoSQL database creation for TFI bikes in Waterford, and data \n",
      "visualization in R with NYC flights data.\n",
      "•DevOps on AWS: EC2 instances, S3 buckets, configuration, and achieved \n",
      "automation with Python scripts.\n",
      "Professional Experience\n",
      "University Informatics Department, Lyon 2\n",
      "present\n",
      "Student Job at the IT department of the university, help desk, loan of computer and \n",
      "professional audiovisual equiment, teamwork.\n",
      "Internship Data Analyst, SYSBLOCK\n",
      "Paris, France\n",
      "•Dashboarding & Analytics: KPI derivation from Google Analytics data and \n",
      "interactive dashboards with Power BI.\n",
      "•Web Development & Blockchain: Experience with Next.js for web development and \n",
      "introduction to blockchain technologies.\n",
      "Projects\n",
      "Creation of a Logistic Regression R package\n",
      "•Logistic regression package from scratch :Implemented various optimizers \n",
      "(Adam, mini-batch, SGD) and applied regularization techniques (L1, L2, ElasticNet). \n",
      "•Successfully tested on classification tasks : achieved up to 90% accuracy on \n",
      "StudentPerformance, Creditcard,  datasets and achieved similar performance to \n",
      "scikit-learn..\n",
      "Projet NLP Analysis of TripAdvisor review\n",
      "•Web Scraping & Sentiment Analysis: Collected TripAdvisor data with \n",
      "BeautifulSoup and performed sentiment analysis on user reviews. Aggregated \n",
      "comments using clustering techniques.\n",
      "•End-to-End Application: Integrated a SQLite database and connected it to a \n",
      "Streamlit app for enhanced visualization. Deployed as a Docker image.\n",
      "•LLM & RAG for Summarization: Leveraged a Large Language Model (LLM) with \n",
      "Retrieval-Augmented Generation (RAG) to summarize user reviews effectively.\n",
      "Project AWS Cloud\n",
      "•AWS Deployment & Scaling: Successfully deployed a template website on EC2 \n",
      "instances with a connected relational database on AWS.\n",
      "•High Availability & Monitoring: Implemented an Auto Scaling Group with a Load \n",
      "Balancer and set up monitoring using custom CloudWatch metrics.\n",
      "Languages/References\n",
      "Languages: French - Native/Bilingual   English C1 - Fluent  Mandarin -\n",
      "Conversational\n",
      "References: Bernard Butler, Pr, SETU  bernard.butler@setu.ie   Liam Doyle, Pr,\n",
      "SETU  liam.doyle@setu.ie\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "<class 'str'>\n",
      "4231\n"
     ]
    }
   ],
   "source": [
    "reader = PdfReader(\"CV_V4_EN.pdf\")\n",
    "page = reader.pages[0] # 1 seule page\n",
    "text_brut = page.extract_text()\n",
    "print(text_brut)\n",
    "print(type(text_brut))\n",
    "print(len(text_brut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(read_pdf(\"CV_V4_EN.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Mistral Mini -> Reformulation Texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Formulation du prompt (CV texte brut + )\n",
    "# Ajouter les suivis de prix + impact ecologique ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import litellm\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA partir d\\'un texte brut venant d\\'un CV, extrait les informations suivantes au format JSON :\\n{\\n    \"Diplome\": [\\n      {\\n          \"niveau_etudes\": \"int\",\\n          \"domaine_etudes\": [\"str\"]\\n      }\\n    ],\\n\\n    \"Competences\": [\"str\"],\\n    \"Experiences\": [\\n        {\\n            \"domaine_activite\": [\"str\"],\\n            \"poste_occupe\": \"str\",\\n            \"duree\": \"int\"\\n        }\\n    ],\\n    \"Profil\": {\\n        \"titre\": \"str\",\\n        \"disponibilite\": \"str\"\\n    }\\n}\\n\\nTexte du CV :\\n\"Quentin Lim  \\nLast year Student in \\nData Science\\nquentinlim 384@ gm ail.com\\n+33782885515\\nlinkedin.com /in/quentin-lim-\\n978746250\\ngithub.com /QL2111\\nProfile\\nCurrently seeking an internship in \\nData Science starting in March \\n2025 for a duration of 4 to 6 \\nmonths.\\nSkills\\nM L, NLP, TensorFlow; Scikit-learn, \\nM LFlow, Transform ers, LLM , Tim e \\nSeries.\\nSQL, NoSQL, M ongoDB\\nQlik, Tableau, PowerBI\\nOpenCV, YOLO\\nAzure, AW S, Fabric\\nGit/Agile m ethodology\\nPython/R/Java/PySpark/JavaScript/\\nPHP\\nGen AI\\nInterests\\nBoard Games:\\xa0Casual boarding\\ngam es and Chess club\\nGaming:\\xa0Played in competitives\\ntournam ents, peaked GrandMaster\\nin League of Legends\\nSailing:\\xa0M em ber of the sailing club\\nat La Rochelle Université\\nBasket ball:\\xa0Sports association\\nduring M iddle School, teamwork\\nand fast decision making.\\nVolunteering\\nESN Cosmolyon\\n2023 – present\\nVice-President, holdings Culturals \\nEvent for internationals and local \\nstudent(Board gam es/Day \\ntrips/Spanish dinner)\\nAlter-ego Lyon 2\\n2023 – present\\nBuddy System  with Lyon 2 \\nUniversityEducation\\nMaster in Data Science, Université Lyon 2 Lumière\\n09/2023 – present\\n•Expertise in advanced data analysis: ANOVA, time series, biostatistics, NLP/LLM, \\nComputer Vision, and Deep Learning.\\n•Proficiency in Big Data and MLOps: web scraping, data warehouses, model \\ndeployment, and pipelines.\\n•Specialized in predictive analytics, focusing on the use of advanced statistical \\nmodels and machine learning algorithms for forecasting and decision making.\\nInternational Exchange Program, National Central University\\nTaoyuan, Taïwan\\n•GPA: 3.8 | Experience in data mining for biological data: autism classification, \\nsentiment analysis and Graph Neural Networks presentation on Reddit data.\\n•Research & Publications: Conducted a literature review on feature selection \\ntechniques and co-authored \"A Review of Feature Selection Techniques in Education\". \\nExplored Transformer models for advanced data analysis.\\nErasmus + Mobility, South East Technological University\\nWaterford, Ireland\\n•First Class Honours | EDA & predictive modeling on Titanic and Tips datasets with \\nup to 90% accuracy, NoSQL database creation for TFI bikes in Waterford, and data \\nvisualization in R with NYC flights data.\\n•DevOps on AWS: EC2 instances, S3 buckets, configuration, and achieved \\nautomation with Python scripts.\\nProfessional Experience\\nUniversity Informatics Department, Lyon 2\\npresent\\nStudent Job at the IT department of the university, help desk, loan of computer and \\nprofessional audiovisual equiment, teamwork.\\nInternship Data Analyst, SYSBLOCK\\nParis, France\\n•Dashboarding & Analytics: KPI derivation from Google Analytics data and \\ninteractive dashboards with Power BI.\\n•Web Development & Blockchain: Experience with Next.js for web development and \\nintroduction to blockchain technologies.\\nProjects\\nCreation of a Logistic Regression R package\\n•Logistic regression package from scratch :Implemented various optimizers \\n(Adam, mini-batch, SGD) and applied regularization techniques (L1, L2, ElasticNet). \\n•Successfully tested on classification tasks : achieved up to 90% accuracy on \\nStudentPerformance, Creditcard,  datasets and achieved similar performance to \\nscikit-learn..\\nProjet NLP Analysis of TripAdvisor review\\n•Web Scraping & Sentiment Analysis: Collected TripAdvisor data with \\nBeautifulSoup and performed sentiment analysis on user reviews. Aggregated \\ncomments using clustering techniques.\\n•End-to-End Application: Integrated a SQLite database and connected it to a \\nStreamlit app for enhanced visualization. Deployed as a Docker image.\\n•LLM & RAG for Summarization: Leveraged a Large Language Model (LLM) with \\nRetrieval-Augmented Generation (RAG) to summarize user reviews effectively.\\nProject AWS Cloud\\n•AWS Deployment & Scaling: Successfully deployed a template website on EC2 \\ninstances with a connected relational database on AWS.\\n•High Availability & Monitoring: Implemented an Auto Scaling Group with a Load \\nBalancer and set up monitoring using custom CloudWatch metrics.\\nLanguages/References\\nLanguages:\\xa0French - Native/Bilingual \\xa0\\xa0English C1 - Fluent\\xa0\\xa0Mandarin -\\nConversational\\nReferences:\\xa0Bernard Butler, Pr, SETU\\xa0\\xa0bernard.butler@setu.ie \\xa0\\xa0Liam Doyle, Pr,\\nSETU\\xa0\\xa0liam.doyle@setu.ie\\n|\\n|\\n|\\n|\\n|\"\\n\\nNe retourne que le JSON\\n'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reformulation_prompt = f\"\"\"\n",
    "A partir d'un texte brut venant d'un CV, extrait les informations suivantes au format JSON :\n",
    "{{\n",
    "    \"Diplome\": [\n",
    "      {{\n",
    "          \"niveau_etudes\": \"int\",\n",
    "          \"domaine_etudes\": [\"str\"]\n",
    "      }}\n",
    "    ],\n",
    "\n",
    "    \"Competences\": [\"str\"],\n",
    "    \"Experiences\": [\n",
    "        {{\n",
    "            \"domaine_activite\": [\"str\"],\n",
    "            \"poste_occupe\": \"str\",\n",
    "            \"duree\": \"int\"\n",
    "        }}\n",
    "    ],\n",
    "    \"Profil\": {{\n",
    "        \"titre\": \"str\",\n",
    "        \"disponibilite\": \"str\"\n",
    "    }}\n",
    "}}\n",
    "\n",
    "Texte du CV :\n",
    "\"{text_brut}\"\n",
    "\n",
    "Ne retourne que le JSON\n",
    "\"\"\"\n",
    "reformulation_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification de la clé API\n",
    "#  api_key=os.getenv(\"MISTRAL_API_KEY\")\n",
    "# api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m23:33:42 - LiteLLM:DEBUG\u001b[0m: utils.py:308 - \n",
      "\n",
      "\u001b[92m23:33:42 - LiteLLM:DEBUG\u001b[0m: utils.py:308 - \u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92m23:33:42 - LiteLLM:DEBUG\u001b[0m: utils.py:308 - \u001b[92mlitellm.completion(model='mistral/ministral-3b-latest', messages=[{'role': 'user', 'content': '\\nA partir d\\'un texte brut venant d\\'un CV, extrait les informations suivantes au format JSON :\\n{\\n    \"Diplome\": [\\n      {\\n          \"niveau_etudes\": \"int\",\\n          \"domaine_etudes\": [\"str\"]\\n      }\\n    ],\\n\\n    \"Competences\": [\"str\"],\\n    \"Experiences\": [\\n        {\\n            \"domaine_activite\": [\"str\"],\\n            \"poste_occupe\": \"str\",\\n            \"duree\": \"int\"\\n        }\\n    ],\\n    \"Profil\": {\\n        \"titre\": \"str\",\\n        \"disponibilite\": \"str\"\\n    }\\n}\\n\\nTexte du CV :\\n\"Quentin Lim  \\nLast year Student in \\nData Science\\nquentinlim 384@ gm ail.com\\n+33782885515\\nlinkedin.com /in/quentin-lim-\\n978746250\\ngithub.com /QL2111\\nProfile\\nCurrently seeking an internship in \\nData Science starting in March \\n2025 for a duration of 4 to 6 \\nmonths.\\nSkills\\nM L, NLP, TensorFlow; Scikit-learn, \\nM LFlow, Transform ers, LLM , Tim e \\nSeries.\\nSQL, NoSQL, M ongoDB\\nQlik, Tableau, PowerBI\\nOpenCV, YOLO\\nAzure, AW S, Fabric\\nGit/Agile m ethodology\\nPython/R/Java/PySpark/JavaScript/\\nPHP\\nGen AI\\nInterests\\nBoard Games:\\xa0Casual boarding\\ngam es and Chess club\\nGaming:\\xa0Played in competitives\\ntournam ents, peaked GrandMaster\\nin League of Legends\\nSailing:\\xa0M em ber of the sailing club\\nat La Rochelle Université\\nBasket ball:\\xa0Sports association\\nduring M iddle School, teamwork\\nand fast decision making.\\nVolunteering\\nESN Cosmolyon\\n2023 – present\\nVice-President, holdings Culturals \\nEvent for internationals and local \\nstudent(Board gam es/Day \\ntrips/Spanish dinner)\\nAlter-ego Lyon 2\\n2023 – present\\nBuddy System  with Lyon 2 \\nUniversityEducation\\nMaster in Data Science, Université Lyon 2 Lumière\\n09/2023 – present\\n•Expertise in advanced data analysis: ANOVA, time series, biostatistics, NLP/LLM, \\nComputer Vision, and Deep Learning.\\n•Proficiency in Big Data and MLOps: web scraping, data warehouses, model \\ndeployment, and pipelines.\\n•Specialized in predictive analytics, focusing on the use of advanced statistical \\nmodels and machine learning algorithms for forecasting and decision making.\\nInternational Exchange Program, National Central University\\nTaoyuan, Taïwan\\n•GPA: 3.8 | Experience in data mining for biological data: autism classification, \\nsentiment analysis and Graph Neural Networks presentation on Reddit data.\\n•Research & Publications: Conducted a literature review on feature selection \\ntechniques and co-authored \"A Review of Feature Selection Techniques in Education\". \\nExplored Transformer models for advanced data analysis.\\nErasmus + Mobility, South East Technological University\\nWaterford, Ireland\\n•First Class Honours | EDA & predictive modeling on Titanic and Tips datasets with \\nup to 90% accuracy, NoSQL database creation for TFI bikes in Waterford, and data \\nvisualization in R with NYC flights data.\\n•DevOps on AWS: EC2 instances, S3 buckets, configuration, and achieved \\nautomation with Python scripts.\\nProfessional Experience\\nUniversity Informatics Department, Lyon 2\\npresent\\nStudent Job at the IT department of the university, help desk, loan of computer and \\nprofessional audiovisual equiment, teamwork.\\nInternship Data Analyst, SYSBLOCK\\nParis, France\\n•Dashboarding & Analytics: KPI derivation from Google Analytics data and \\ninteractive dashboards with Power BI.\\n•Web Development & Blockchain: Experience with Next.js for web development and \\nintroduction to blockchain technologies.\\nProjects\\nCreation of a Logistic Regression R package\\n•Logistic regression package from scratch :Implemented various optimizers \\n(Adam, mini-batch, SGD) and applied regularization techniques (L1, L2, ElasticNet). \\n•Successfully tested on classification tasks : achieved up to 90% accuracy on \\nStudentPerformance, Creditcard,  datasets and achieved similar performance to \\nscikit-learn..\\nProjet NLP Analysis of TripAdvisor review\\n•Web Scraping & Sentiment Analysis: Collected TripAdvisor data with \\nBeautifulSoup and performed sentiment analysis on user reviews. Aggregated \\ncomments using clustering techniques.\\n•End-to-End Application: Integrated a SQLite database and connected it to a \\nStreamlit app for enhanced visualization. Deployed as a Docker image.\\n•LLM & RAG for Summarization: Leveraged a Large Language Model (LLM) with \\nRetrieval-Augmented Generation (RAG) to summarize user reviews effectively.\\nProject AWS Cloud\\n•AWS Deployment & Scaling: Successfully deployed a template website on EC2 \\ninstances with a connected relational database on AWS.\\n•High Availability & Monitoring: Implemented an Auto Scaling Group with a Load \\nBalancer and set up monitoring using custom CloudWatch metrics.\\nLanguages/References\\nLanguages:\\xa0French - Native/Bilingual \\xa0\\xa0English C1 - Fluent\\xa0\\xa0Mandarin -\\nConversational\\nReferences:\\xa0Bernard Butler, Pr, SETU\\xa0\\xa0bernard.butler@setu.ie \\xa0\\xa0Liam Doyle, Pr,\\nSETU\\xa0\\xa0liam.doyle@setu.ie\\n|\\n|\\n|\\n|\\n|\"\\n\\nNe retourne que le JSON\\n'}], max_tokens=1500, temperature=0.3, api_key='dkMKu81kFgJeP7HmIqjztosQTxyiynW6')\u001b[0m\n",
      "\u001b[92m23:33:42 - LiteLLM:DEBUG\u001b[0m: utils.py:308 - \n",
      "\n",
      "\u001b[92m23:33:42 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:386 - self.optional_params: {}\n",
      "\u001b[92m23:33:42 - LiteLLM:DEBUG\u001b[0m: utils.py:308 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "\u001b[92m23:33:42 - LiteLLM:INFO\u001b[0m: utils.py:2974 - \n",
      "LiteLLM completion() model= ministral-3b-latest; provider = mistral\n",
      "\u001b[92m23:33:42 - LiteLLM:DEBUG\u001b[0m: utils.py:2977 - \n",
      "LiteLLM: Params passed to completion() {'model': 'ministral-3b-latest', 'functions': None, 'function_call': None, 'temperature': 0.3, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 1500, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'mistral', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'user', 'content': '\\nA partir d\\'un texte brut venant d\\'un CV, extrait les informations suivantes au format JSON :\\n{\\n    \"Diplome\": [\\n      {\\n          \"niveau_etudes\": \"int\",\\n          \"domaine_etudes\": [\"str\"]\\n      }\\n    ],\\n\\n    \"Competences\": [\"str\"],\\n    \"Experiences\": [\\n        {\\n            \"domaine_activite\": [\"str\"],\\n            \"poste_occupe\": \"str\",\\n            \"duree\": \"int\"\\n        }\\n    ],\\n    \"Profil\": {\\n        \"titre\": \"str\",\\n        \"disponibilite\": \"str\"\\n    }\\n}\\n\\nTexte du CV :\\n\"Quentin Lim  \\nLast year Student in \\nData Science\\nquentinlim 384@ gm ail.com\\n+33782885515\\nlinkedin.com /in/quentin-lim-\\n978746250\\ngithub.com /QL2111\\nProfile\\nCurrently seeking an internship in \\nData Science starting in March \\n2025 for a duration of 4 to 6 \\nmonths.\\nSkills\\nM L, NLP, TensorFlow; Scikit-learn, \\nM LFlow, Transform ers, LLM , Tim e \\nSeries.\\nSQL, NoSQL, M ongoDB\\nQlik, Tableau, PowerBI\\nOpenCV, YOLO\\nAzure, AW S, Fabric\\nGit/Agile m ethodology\\nPython/R/Java/PySpark/JavaScript/\\nPHP\\nGen AI\\nInterests\\nBoard Games:\\xa0Casual boarding\\ngam es and Chess club\\nGaming:\\xa0Played in competitives\\ntournam ents, peaked GrandMaster\\nin League of Legends\\nSailing:\\xa0M em ber of the sailing club\\nat La Rochelle Université\\nBasket ball:\\xa0Sports association\\nduring M iddle School, teamwork\\nand fast decision making.\\nVolunteering\\nESN Cosmolyon\\n2023 – present\\nVice-President, holdings Culturals \\nEvent for internationals and local \\nstudent(Board gam es/Day \\ntrips/Spanish dinner)\\nAlter-ego Lyon 2\\n2023 – present\\nBuddy System  with Lyon 2 \\nUniversityEducation\\nMaster in Data Science, Université Lyon 2 Lumière\\n09/2023 – present\\n•Expertise in advanced data analysis: ANOVA, time series, biostatistics, NLP/LLM, \\nComputer Vision, and Deep Learning.\\n•Proficiency in Big Data and MLOps: web scraping, data warehouses, model \\ndeployment, and pipelines.\\n•Specialized in predictive analytics, focusing on the use of advanced statistical \\nmodels and machine learning algorithms for forecasting and decision making.\\nInternational Exchange Program, National Central University\\nTaoyuan, Taïwan\\n•GPA: 3.8 | Experience in data mining for biological data: autism classification, \\nsentiment analysis and Graph Neural Networks presentation on Reddit data.\\n•Research & Publications: Conducted a literature review on feature selection \\ntechniques and co-authored \"A Review of Feature Selection Techniques in Education\". \\nExplored Transformer models for advanced data analysis.\\nErasmus + Mobility, South East Technological University\\nWaterford, Ireland\\n•First Class Honours | EDA & predictive modeling on Titanic and Tips datasets with \\nup to 90% accuracy, NoSQL database creation for TFI bikes in Waterford, and data \\nvisualization in R with NYC flights data.\\n•DevOps on AWS: EC2 instances, S3 buckets, configuration, and achieved \\nautomation with Python scripts.\\nProfessional Experience\\nUniversity Informatics Department, Lyon 2\\npresent\\nStudent Job at the IT department of the university, help desk, loan of computer and \\nprofessional audiovisual equiment, teamwork.\\nInternship Data Analyst, SYSBLOCK\\nParis, France\\n•Dashboarding & Analytics: KPI derivation from Google Analytics data and \\ninteractive dashboards with Power BI.\\n•Web Development & Blockchain: Experience with Next.js for web development and \\nintroduction to blockchain technologies.\\nProjects\\nCreation of a Logistic Regression R package\\n•Logistic regression package from scratch :Implemented various optimizers \\n(Adam, mini-batch, SGD) and applied regularization techniques (L1, L2, ElasticNet). \\n•Successfully tested on classification tasks : achieved up to 90% accuracy on \\nStudentPerformance, Creditcard,  datasets and achieved similar performance to \\nscikit-learn..\\nProjet NLP Analysis of TripAdvisor review\\n•Web Scraping & Sentiment Analysis: Collected TripAdvisor data with \\nBeautifulSoup and performed sentiment analysis on user reviews. Aggregated \\ncomments using clustering techniques.\\n•End-to-End Application: Integrated a SQLite database and connected it to a \\nStreamlit app for enhanced visualization. Deployed as a Docker image.\\n•LLM & RAG for Summarization: Leveraged a Large Language Model (LLM) with \\nRetrieval-Augmented Generation (RAG) to summarize user reviews effectively.\\nProject AWS Cloud\\n•AWS Deployment & Scaling: Successfully deployed a template website on EC2 \\ninstances with a connected relational database on AWS.\\n•High Availability & Monitoring: Implemented an Auto Scaling Group with a Load \\nBalancer and set up monitoring using custom CloudWatch metrics.\\nLanguages/References\\nLanguages:\\xa0French - Native/Bilingual \\xa0\\xa0English C1 - Fluent\\xa0\\xa0Mandarin -\\nConversational\\nReferences:\\xa0Bernard Butler, Pr, SETU\\xa0\\xa0bernard.butler@setu.ie \\xa0\\xa0Liam Doyle, Pr,\\nSETU\\xa0\\xa0liam.doyle@setu.ie\\n|\\n|\\n|\\n|\\n|\"\\n\\nNe retourne que le JSON\\n'}], 'thinking': None}\n",
      "\u001b[92m23:33:42 - LiteLLM:DEBUG\u001b[0m: utils.py:2980 - \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.3, 'max_tokens': 1500}\n",
      "\u001b[92m23:33:42 - LiteLLM:DEBUG\u001b[0m: utils.py:308 - Final returned optional params: {'temperature': 0.3, 'max_tokens': 1500, 'extra_body': {}}\n",
      "\u001b[92m23:33:42 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:386 - self.optional_params: {'temperature': 0.3, 'max_tokens': 1500, 'extra_body': {}}\n",
      "\u001b[92m23:33:42 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:682 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://api.mistral.ai/v1/ \\\n",
      "-d '{'model': 'ministral-3b-latest', 'messages': [{'role': 'user', 'content': '\\nA partir d\\'un texte brut venant d\\'un CV, extrait les informations suivantes au format JSON :\\n{\\n    \"Diplome\": [\\n      {\\n          \"niveau_etudes\": \"int\",\\n          \"domaine_etudes\": [\"str\"]\\n      }\\n    ],\\n\\n    \"Competences\": [\"str\"],\\n    \"Experiences\": [\\n        {\\n            \"domaine_activite\": [\"str\"],\\n            \"poste_occupe\": \"str\",\\n            \"duree\": \"int\"\\n        }\\n    ],\\n    \"Profil\": {\\n        \"titre\": \"str\",\\n        \"disponibilite\": \"str\"\\n    }\\n}\\n\\nTexte du CV :\\n\"Quentin Lim  \\nLast year Student in \\nData Science\\nquentinlim 384@ gm ail.com\\n+33782885515\\nlinkedin.com /in/quentin-lim-\\n978746250\\ngithub.com /QL2111\\nProfile\\nCurrently seeking an internship in \\nData Science starting in March \\n2025 for a duration of 4 to 6 \\nmonths.\\nSkills\\nM L, NLP, TensorFlow; Scikit-learn, \\nM LFlow, Transform ers, LLM , Tim e \\nSeries.\\nSQL, NoSQL, M ongoDB\\nQlik, Tableau, PowerBI\\nOpenCV, YOLO\\nAzure, AW S, Fabric\\nGit/Agile m ethodology\\nPython/R/Java/PySpark/JavaScript/\\nPHP\\nGen AI\\nInterests\\nBoard Games:\\xa0Casual boarding\\ngam es and Chess club\\nGaming:\\xa0Played in competitives\\ntournam ents, peaked GrandMaster\\nin League of Legends\\nSailing:\\xa0M em ber of the sailing club\\nat La Rochelle Université\\nBasket ball:\\xa0Sports association\\nduring M iddle School, teamwork\\nand fast decision making.\\nVolunteering\\nESN Cosmolyon\\n2023 – present\\nVice-President, holdings Culturals \\nEvent for internationals and local \\nstudent(Board gam es/Day \\ntrips/Spanish dinner)\\nAlter-ego Lyon 2\\n2023 – present\\nBuddy System  with Lyon 2 \\nUniversityEducation\\nMaster in Data Science, Université Lyon 2 Lumière\\n09/2023 – present\\n•Expertise in advanced data analysis: ANOVA, time series, biostatistics, NLP/LLM, \\nComputer Vision, and Deep Learning.\\n•Proficiency in Big Data and MLOps: web scraping, data warehouses, model \\ndeployment, and pipelines.\\n•Specialized in predictive analytics, focusing on the use of advanced statistical \\nmodels and machine learning algorithms for forecasting and decision making.\\nInternational Exchange Program, National Central University\\nTaoyuan, Taïwan\\n•GPA: 3.8 | Experience in data mining for biological data: autism classification, \\nsentiment analysis and Graph Neural Networks presentation on Reddit data.\\n•Research & Publications: Conducted a literature review on feature selection \\ntechniques and co-authored \"A Review of Feature Selection Techniques in Education\". \\nExplored Transformer models for advanced data analysis.\\nErasmus + Mobility, South East Technological University\\nWaterford, Ireland\\n•First Class Honours | EDA & predictive modeling on Titanic and Tips datasets with \\nup to 90% accuracy, NoSQL database creation for TFI bikes in Waterford, and data \\nvisualization in R with NYC flights data.\\n•DevOps on AWS: EC2 instances, S3 buckets, configuration, and achieved \\nautomation with Python scripts.\\nProfessional Experience\\nUniversity Informatics Department, Lyon 2\\npresent\\nStudent Job at the IT department of the university, help desk, loan of computer and \\nprofessional audiovisual equiment, teamwork.\\nInternship Data Analyst, SYSBLOCK\\nParis, France\\n•Dashboarding & Analytics: KPI derivation from Google Analytics data and \\ninteractive dashboards with Power BI.\\n•Web Development & Blockchain: Experience with Next.js for web development and \\nintroduction to blockchain technologies.\\nProjects\\nCreation of a Logistic Regression R package\\n•Logistic regression package from scratch :Implemented various optimizers \\n(Adam, mini-batch, SGD) and applied regularization techniques (L1, L2, ElasticNet). \\n•Successfully tested on classification tasks : achieved up to 90% accuracy on \\nStudentPerformance, Creditcard,  datasets and achieved similar performance to \\nscikit-learn..\\nProjet NLP Analysis of TripAdvisor review\\n•Web Scraping & Sentiment Analysis: Collected TripAdvisor data with \\nBeautifulSoup and performed sentiment analysis on user reviews. Aggregated \\ncomments using clustering techniques.\\n•End-to-End Application: Integrated a SQLite database and connected it to a \\nStreamlit app for enhanced visualization. Deployed as a Docker image.\\n•LLM & RAG for Summarization: Leveraged a Large Language Model (LLM) with \\nRetrieval-Augmented Generation (RAG) to summarize user reviews effectively.\\nProject AWS Cloud\\n•AWS Deployment & Scaling: Successfully deployed a template website on EC2 \\ninstances with a connected relational database on AWS.\\n•High Availability & Monitoring: Implemented an Auto Scaling Group with a Load \\nBalancer and set up monitoring using custom CloudWatch metrics.\\nLanguages/References\\nLanguages:\\xa0French - Native/Bilingual \\xa0\\xa0English C1 - Fluent\\xa0\\xa0Mandarin -\\nConversational\\nReferences:\\xa0Bernard Butler, Pr, SETU\\xa0\\xa0bernard.butler@setu.ie \\xa0\\xa0Liam Doyle, Pr,\\nSETU\\xa0\\xa0liam.doyle@setu.ie\\n|\\n|\\n|\\n|\\n|\"\\n\\nNe retourne que le JSON\\n'}], 'temperature': 0.3, 'max_tokens': 1500, 'extra_body': {}}'\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[92m23:33:43 - LiteLLM:DEBUG\u001b[0m: utils.py:308 - RAW RESPONSE:\n",
      "{\"id\": \"8a0db6dad04d498a80f7febbe42facb7\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"```json\\n{\\n    \\\"Diplome\\\": [\\n        {\\n            \\\"niveau_etudes\\\": \\\"Master\\\",\\n            \\\"domaine_etudes\\\": [\\\"Data Science\\\"]\\n        }\\n    ],\\n    \\\"Competences\\\": [\\n        \\\"M L\\\", \\\"NLP\\\", \\\"TensorFlow\\\", \\\"Scikit-learn\\\", \\\"M LFlow\\\", \\\"Transformers\\\", \\\"LLM\\\", \\\"Time Series\\\",\\n        \\\"SQL\\\", \\\"NoSQL\\\", \\\"MongoDB\\\", \\\"Qlik\\\", \\\"Tableau\\\", \\\"PowerBI\\\", \\\"OpenCV\\\", \\\"YOLO\\\", \\\"Azure\\\", \\\"AWS\\\", \\\"Fabric\\\",\\n        \\\"Git/Agile methodology\\\", \\\"Python\\\", \\\"R\\\", \\\"Java\\\", \\\"PySpark\\\", \\\"JavaScript\\\", \\\"PHP\\\", \\\"Gen AI\\\"\\n    ],\\n    \\\"Experiences\\\": [\\n        {\\n            \\\"domaine_activite\\\": [\\\"Data Science\\\"],\\n            \\\"poste_occupe\\\": \\\"Student Job at the IT department of the university\\\",\\n            \\\"duree\\\": 1\\n        },\\n        {\\n            \\\"domaine_activite\\\": [\\\"Data Science\\\"],\\n            \\\"poste_occupe\\\": \\\"Internship Data Analyst\\\",\\n            \\\"duree\\\": 1\\n        }\\n    ],\\n    \\\"Profil\\\": {\\n        \\\"titre\\\": \\\"Currently seeking an internship in Data Science starting in March 2025 for a duration of 4 to 6 months.\\\",\\n        \\\"disponibilite\\\": \\\"March 2025\\\"\\n    }\\n}\\n```\", \"refusal\": null, \"role\": \"assistant\", \"annotations\": null, \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1741818823, \"model\": \"ministral-3b-latest\", \"object\": \"chat.completion\", \"service_tier\": null, \"system_fingerprint\": null, \"usage\": {\"completion_tokens\": 310, \"prompt_tokens\": 1265, \"total_tokens\": 1575, \"completion_tokens_details\": null, \"prompt_tokens_details\": null}}\n",
      "\n",
      "\n",
      "\u001b[92m23:33:43 - LiteLLM:INFO\u001b[0m: utils.py:1143 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m23:33:43 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:576 - completion_response _select_model_name_for_cost_calc: mistral/ministral-3b-latest\n",
      "\u001b[92m23:33:43 - LiteLLM:DEBUG\u001b[0m: utils.py:4270 - checking potential_model_names in litellm.model_cost: {'split_model': 'ministral-3b-latest', 'combined_model_name': 'mistral/ministral-3b-latest', 'stripped_model_name': 'ministral-3b-latest', 'combined_stripped_model_name': 'mistral/ministral-3b-latest', 'custom_llm_provider': 'mistral'}\n",
      "\u001b[92m23:33:43 - LiteLLM:DEBUG\u001b[0m: utils.py:4467 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n",
      "\u001b[92m23:33:43 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:926 - response_cost_failure_debug_information: {'error_str': \"This model isn't mapped yet. model=mistral/ministral-3b-latest, custom_llm_provider=mistral. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\", 'traceback_str': 'Traceback (most recent call last):\\n  File \"d:\\\\Anaconda\\\\envs\\\\challengeIA\\\\Lib\\\\site-packages\\\\litellm\\\\utils.py\", line 4360, in _get_model_info_helper\\n    raise ValueError(\\nValueError: This model isn\\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"d:\\\\Anaconda\\\\envs\\\\challengeIA\\\\Lib\\\\site-packages\\\\litellm\\\\litellm_core_utils\\\\litellm_logging.py\", line 908, in _response_cost_calculator\\n    response_cost = litellm.response_cost_calculator(\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"d:\\\\Anaconda\\\\envs\\\\challengeIA\\\\Lib\\\\site-packages\\\\litellm\\\\cost_calculator.py\", line 852, in response_cost_calculator\\n    raise e\\n  File \"d:\\\\Anaconda\\\\envs\\\\challengeIA\\\\Lib\\\\site-packages\\\\litellm\\\\cost_calculator.py\", line 840, in response_cost_calculator\\n    response_cost = completion_cost(\\n                    ^^^^^^^^^^^^^^^^\\n  File \"d:\\\\Anaconda\\\\envs\\\\challengeIA\\\\Lib\\\\site-packages\\\\litellm\\\\cost_calculator.py\", line 790, in completion_cost\\n    raise e\\n  File \"d:\\\\Anaconda\\\\envs\\\\challengeIA\\\\Lib\\\\site-packages\\\\litellm\\\\cost_calculator.py\", line 768, in completion_cost\\n    ) = cost_per_token(\\n        ^^^^^^^^^^^^^^^\\n  File \"d:\\\\Anaconda\\\\envs\\\\challengeIA\\\\Lib\\\\site-packages\\\\litellm\\\\cost_calculator.py\", line 296, in cost_per_token\\n    model_info = _cached_get_model_info_helper(\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"d:\\\\Anaconda\\\\envs\\\\challengeIA\\\\Lib\\\\site-packages\\\\litellm\\\\utils.py\", line 4223, in _cached_get_model_info_helper\\n    return _get_model_info_helper(model=model, custom_llm_provider=custom_llm_provider)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"d:\\\\Anaconda\\\\envs\\\\challengeIA\\\\Lib\\\\site-packages\\\\litellm\\\\utils.py\", line 4470, in _get_model_info_helper\\n    raise Exception(\\nException: This model isn\\'t mapped yet. model=mistral/ministral-3b-latest, custom_llm_provider=mistral. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\\n', 'model': 'ministral-3b-latest', 'cache_hit': False, 'custom_llm_provider': 'mistral', 'base_model': None, 'call_type': 'completion', 'custom_pricing': False}\n"
     ]
    }
   ],
   "source": [
    "# litellm._turn_on_debug()\n",
    "# Température, plus c'est proche de 1, plus c'est créatif\n",
    "# On cherche à savoir combien de token on devrait mettre\n",
    "\n",
    "CV_reformuler = litellm.completion(\n",
    "            model=\"mistral/ministral-3b-latest\",  # Choix d'un modèle petit\n",
    "            messages=[{\"role\": \"user\", \"content\": reformulation_prompt}],\n",
    "            max_tokens=1500,\n",
    "            temperature=0.3,\n",
    "            api_key=os.getenv(\"MISTRAL_API_KEY\"),\n",
    "        )\n",
    "\n",
    "resultat = CV_reformuler[\"choices\"][0][\"message\"][\n",
    "            \"content\"\n",
    "        ].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Diplome\": [\n",
      "        {\n",
      "            \"niveau_etudes\": \"Master\",\n",
      "            \"domaine_etudes\": [\"Data Science\"]\n",
      "        }\n",
      "    ],\n",
      "    \"Competences\": [\n",
      "        \"M L\", \"NLP\", \"TensorFlow\", \"Scikit-learn\", \"M LFlow\", \"Transformers\", \"LLM\", \"Time Series\",\n",
      "        \"SQL\", \"NoSQL\", \"MongoDB\", \"Qlik\", \"Tableau\", \"PowerBI\", \"OpenCV\", \"YOLO\", \"Azure\", \"AWS\", \"Fabric\",\n",
      "        \"Git/Agile methodology\", \"Python\", \"R\", \"Java\", \"PySpark\", \"JavaScript\", \"PHP\", \"Gen AI\"\n",
      "    ],\n",
      "    \"Experiences\": [\n",
      "        {\n",
      "            \"domaine_activite\": [\"Data Science\"],\n",
      "            \"poste_occupe\": \"Student Job at the IT department of the university\",\n",
      "            \"duree\": 1\n",
      "        },\n",
      "        {\n",
      "            \"domaine_activite\": [\"Data Science\"],\n",
      "            \"poste_occupe\": \"Internship Data Analyst\",\n",
      "            \"duree\": 1\n",
      "        }\n",
      "    ],\n",
      "    \"Profil\": {\n",
      "        \"titre\": \"Currently seeking an internship in Data Science starting in March 2025 for a duration of 4 to 6 months.\",\n",
      "        \"disponibilite\": \"March 2025\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "1016\n"
     ]
    }
   ],
   "source": [
    "# Le CV fait 4231 en len\n",
    "# len de 1863 pour 500 max tokens\n",
    "# len de 4429 pour 1500 max tokens -> C'est OK, on essaye avec 1000 max tokens\n",
    "print(resultat)\n",
    "print(len(resultat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[161]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m CV_json = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresultat\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\challengeIA\\Lib\\json\\__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\challengeIA\\Lib\\json\\decoder.py:338\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    334\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    335\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    336\u001b[39m \n\u001b[32m    337\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m     end = _w(s, end).end()\n\u001b[32m    340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\challengeIA\\Lib\\json\\decoder.py:356\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    354\u001b[39m     obj, end = \u001b[38;5;28mself\u001b[39m.scan_once(s, idx)\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_cv(text_brut: str, temperature: float = 0.01, max_tokens: int = 1500) -> str:\n",
    "    \"\"\"\n",
    "    Analyse un CV en format texte et retourne les informations structurées en JSON.\n",
    "\n",
    "    Args:\n",
    "        text_brut (str): Texte brut du CV à analyser\n",
    "        temperature (float, optional): Paramètre de créativité du modèle. Defaults to 0.2.\n",
    "        max_tokens (int, optional): Nombre maximum de tokens pour la réponse. Defaults to 1500.\n",
    "\n",
    "    Returns:\n",
    "        str: Informations en string(réponse du LLM) structurées du CV au format JSON\n",
    "\n",
    "    Raises:\n",
    "        Exception: En cas d'erreur d'API ou de parsing JSON\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reformulation_prompt = f\"\"\"\n",
    "        À partir du texte brut d'un CV, extrais les informations suivantes au format JSON. \n",
    "        Si une information n'est pas explicitement mentionnée dans le texte, retourne `null` ou une liste vide.\n",
    "        Ne devine pas les informations manquantes et ne retourne que ce qui est clairement présent dans le texte.\n",
    "\n",
    "        Format JSON attendu :\n",
    "        {{\n",
    "            \"Diplome\": [\n",
    "                {{\n",
    "                    \"niveau_etudes\": \"str\",  // Ex: \"Licence\", \"Master\", \"Doctorat\"\n",
    "                    \"domaine_etudes\": [\"str\"]  // Ex: [\"Informatique\", \"Mathématiques\"]\n",
    "                }}\n",
    "            ],\n",
    "            \"Competences\": [\"str\"],  // Ex: [\"Python\", \"Gestion de projet\"]\n",
    "            \"Experiences\": [\n",
    "                {{\n",
    "                    \"domaine_activite\": [\"str\"],  // Ex: [\"Tech\", \"Finance\"]\n",
    "                    \"poste_occupe\": \"str\",  // Ex: \"Développeur Python\"\n",
    "                    \"duree\": \"str\"  // Ex: \"2 ans\"\n",
    "                }}\n",
    "            ],\n",
    "            \"Profil\": {{\n",
    "                \"titre\": \"str\",  // Ex: \"Développeur Full-Stack\"\n",
    "                \"disponibilite\": \"str\"  // Ex: \"Immédiate\"\n",
    "            }}\n",
    "        }}\n",
    "\n",
    "        Texte du CV :\n",
    "        \"{text_brut}\"\n",
    "\n",
    "        Ne retourne que le JSON, sans commentaires supplémentaires.\n",
    "        \"\"\"\n",
    "\n",
    "        CV_reformuler = litellm.completion(\n",
    "            model=\"mistral/mistral-medium\",\n",
    "            messages=[{\"role\": \"user\", \"content\": reformulation_prompt}],\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            api_key=os.getenv(\"MISTRAL_API_KEY\"),\n",
    "        )\n",
    "\n",
    "        # Extraire et parser le JSON de la réponse\n",
    "        resultat = CV_reformuler[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        return resultat\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Erreur lors de l'analyse du CV: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m23:39:35 - LiteLLM:DEBUG\u001b[0m: utils.py:308 - \n",
      "\n",
      "\u001b[92m23:39:35 - LiteLLM:DEBUG\u001b[0m: utils.py:308 - \u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92m23:39:35 - LiteLLM:DEBUG\u001b[0m: utils.py:308 - \u001b[92mlitellm.completion(model='mistral/mistral-medium', messages=[{'role': 'user', 'content': '\\n        À partir du texte brut d\\'un CV, extrais les informations suivantes au format JSON. \\n        Si une information n\\'est pas explicitement mentionnée dans le texte, retourne `null` ou une liste vide.\\n        Ne devine pas les informations manquantes et ne retourne que ce qui est clairement présent dans le texte.\\n\\n        Format JSON attendu :\\n        {\\n            \"Diplome\": [\\n                {\\n                    \"niveau_etudes\": \"str\",  // Ex: \"Licence\", \"Master\", \"Doctorat\"\\n                    \"domaine_etudes\": [\"str\"]  // Ex: [\"Informatique\", \"Mathématiques\"]\\n                }\\n            ],\\n            \"Competences\": [\"str\"],  // Ex: [\"Python\", \"Gestion de projet\"]\\n            \"Experiences\": [\\n                {\\n                    \"domaine_activite\": [\"str\"],  // Ex: [\"Tech\", \"Finance\"]\\n                    \"poste_occupe\": \"str\",  // Ex: \"Développeur Python\"\\n                    \"duree\": \"str\"  // Ex: \"2 ans\"\\n                }\\n            ],\\n            \"Profil\": {\\n                \"titre\": \"str\",  // Ex: \"Développeur Full-Stack\"\\n                \"disponibilite\": \"str\"  // Ex: \"Immédiate\"\\n            }\\n        }\\n\\n        Texte du CV :\\n        \"Quentin Lim  \\nLast year Student in \\nData Science\\nquentinlim 384@ gm ail.com\\n+33782885515\\nlinkedin.com /in/quentin-lim-\\n978746250\\ngithub.com /QL2111\\nProfile\\nCurrently seeking an internship in \\nData Science starting in March \\n2025 for a duration of 4 to 6 \\nmonths.\\nSkills\\nM L, NLP, TensorFlow; Scikit-learn, \\nM LFlow, Transform ers, LLM , Tim e \\nSeries.\\nSQL, NoSQL, M ongoDB\\nQlik, Tableau, PowerBI\\nOpenCV, YOLO\\nAzure, AW S, Fabric\\nGit/Agile m ethodology\\nPython/R/Java/PySpark/JavaScript/\\nPHP\\nGen AI\\nInterests\\nBoard Games:\\xa0Casual boarding\\ngam es and Chess club\\nGaming:\\xa0Played in competitives\\ntournam ents, peaked GrandMaster\\nin League of Legends\\nSailing:\\xa0M em ber of the sailing club\\nat La Rochelle Université\\nBasket ball:\\xa0Sports association\\nduring M iddle School, teamwork\\nand fast decision making.\\nVolunteering\\nESN Cosmolyon\\n2023 – present\\nVice-President, holdings Culturals \\nEvent for internationals and local \\nstudent(Board gam es/Day \\ntrips/Spanish dinner)\\nAlter-ego Lyon 2\\n2023 – present\\nBuddy System  with Lyon 2 \\nUniversityEducation\\nMaster in Data Science, Université Lyon 2 Lumière\\n09/2023 – present\\n•Expertise in advanced data analysis: ANOVA, time series, biostatistics, NLP/LLM, \\nComputer Vision, and Deep Learning.\\n•Proficiency in Big Data and MLOps: web scraping, data warehouses, model \\ndeployment, and pipelines.\\n•Specialized in predictive analytics, focusing on the use of advanced statistical \\nmodels and machine learning algorithms for forecasting and decision making.\\nInternational Exchange Program, National Central University\\nTaoyuan, Taïwan\\n•GPA: 3.8 | Experience in data mining for biological data: autism classification, \\nsentiment analysis and Graph Neural Networks presentation on Reddit data.\\n•Research & Publications: Conducted a literature review on feature selection \\ntechniques and co-authored \"A Review of Feature Selection Techniques in Education\". \\nExplored Transformer models for advanced data analysis.\\nErasmus + Mobility, South East Technological University\\nWaterford, Ireland\\n•First Class Honours | EDA & predictive modeling on Titanic and Tips datasets with \\nup to 90% accuracy, NoSQL database creation for TFI bikes in Waterford, and data \\nvisualization in R with NYC flights data.\\n•DevOps on AWS: EC2 instances, S3 buckets, configuration, and achieved \\nautomation with Python scripts.\\nProfessional Experience\\nUniversity Informatics Department, Lyon 2\\npresent\\nStudent Job at the IT department of the university, help desk, loan of computer and \\nprofessional audiovisual equiment, teamwork.\\nInternship Data Analyst, SYSBLOCK\\nParis, France\\n•Dashboarding & Analytics: KPI derivation from Google Analytics data and \\ninteractive dashboards with Power BI.\\n•Web Development & Blockchain: Experience with Next.js for web development and \\nintroduction to blockchain technologies.\\nProjects\\nCreation of a Logistic Regression R package\\n•Logistic regression package from scratch :Implemented various optimizers \\n(Adam, mini-batch, SGD) and applied regularization techniques (L1, L2, ElasticNet). \\n•Successfully tested on classification tasks : achieved up to 90% accuracy on \\nStudentPerformance, Creditcard,  datasets and achieved similar performance to \\nscikit-learn..\\nProjet NLP Analysis of TripAdvisor review\\n•Web Scraping & Sentiment Analysis: Collected TripAdvisor data with \\nBeautifulSoup and performed sentiment analysis on user reviews. Aggregated \\ncomments using clustering techniques.\\n•End-to-End Application: Integrated a SQLite database and connected it to a \\nStreamlit app for enhanced visualization. Deployed as a Docker image.\\n•LLM & RAG for Summarization: Leveraged a Large Language Model (LLM) with \\nRetrieval-Augmented Generation (RAG) to summarize user reviews effectively.\\nProject AWS Cloud\\n•AWS Deployment & Scaling: Successfully deployed a template website on EC2 \\ninstances with a connected relational database on AWS.\\n•High Availability & Monitoring: Implemented an Auto Scaling Group with a Load \\nBalancer and set up monitoring using custom CloudWatch metrics.\\nLanguages/References\\nLanguages:\\xa0French - Native/Bilingual \\xa0\\xa0English C1 - Fluent\\xa0\\xa0Mandarin -\\nConversational\\nReferences:\\xa0Bernard Butler, Pr, SETU\\xa0\\xa0bernard.butler@setu.ie \\xa0\\xa0Liam Doyle, Pr,\\nSETU\\xa0\\xa0liam.doyle@setu.ie\\n|\\n|\\n|\\n|\\n|\"\\n\\n        Ne retourne que le JSON, sans commentaires supplémentaires.\\n        '}], max_tokens=1500, temperature=0.01, api_key='dkMKu81kFgJeP7HmIqjztosQTxyiynW6')\u001b[0m\n",
      "\u001b[92m23:39:35 - LiteLLM:DEBUG\u001b[0m: utils.py:308 - \n",
      "\n",
      "\u001b[92m23:39:35 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:386 - self.optional_params: {}\n",
      "\u001b[92m23:39:35 - LiteLLM:DEBUG\u001b[0m: utils.py:308 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "\u001b[92m23:39:35 - LiteLLM:INFO\u001b[0m: utils.py:2974 - \n",
      "LiteLLM completion() model= mistral-medium; provider = mistral\n",
      "\u001b[92m23:39:35 - LiteLLM:DEBUG\u001b[0m: utils.py:2977 - \n",
      "LiteLLM: Params passed to completion() {'model': 'mistral-medium', 'functions': None, 'function_call': None, 'temperature': 0.01, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 1500, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'mistral', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'user', 'content': '\\n        À partir du texte brut d\\'un CV, extrais les informations suivantes au format JSON. \\n        Si une information n\\'est pas explicitement mentionnée dans le texte, retourne `null` ou une liste vide.\\n        Ne devine pas les informations manquantes et ne retourne que ce qui est clairement présent dans le texte.\\n\\n        Format JSON attendu :\\n        {\\n            \"Diplome\": [\\n                {\\n                    \"niveau_etudes\": \"str\",  // Ex: \"Licence\", \"Master\", \"Doctorat\"\\n                    \"domaine_etudes\": [\"str\"]  // Ex: [\"Informatique\", \"Mathématiques\"]\\n                }\\n            ],\\n            \"Competences\": [\"str\"],  // Ex: [\"Python\", \"Gestion de projet\"]\\n            \"Experiences\": [\\n                {\\n                    \"domaine_activite\": [\"str\"],  // Ex: [\"Tech\", \"Finance\"]\\n                    \"poste_occupe\": \"str\",  // Ex: \"Développeur Python\"\\n                    \"duree\": \"str\"  // Ex: \"2 ans\"\\n                }\\n            ],\\n            \"Profil\": {\\n                \"titre\": \"str\",  // Ex: \"Développeur Full-Stack\"\\n                \"disponibilite\": \"str\"  // Ex: \"Immédiate\"\\n            }\\n        }\\n\\n        Texte du CV :\\n        \"Quentin Lim  \\nLast year Student in \\nData Science\\nquentinlim 384@ gm ail.com\\n+33782885515\\nlinkedin.com /in/quentin-lim-\\n978746250\\ngithub.com /QL2111\\nProfile\\nCurrently seeking an internship in \\nData Science starting in March \\n2025 for a duration of 4 to 6 \\nmonths.\\nSkills\\nM L, NLP, TensorFlow; Scikit-learn, \\nM LFlow, Transform ers, LLM , Tim e \\nSeries.\\nSQL, NoSQL, M ongoDB\\nQlik, Tableau, PowerBI\\nOpenCV, YOLO\\nAzure, AW S, Fabric\\nGit/Agile m ethodology\\nPython/R/Java/PySpark/JavaScript/\\nPHP\\nGen AI\\nInterests\\nBoard Games:\\xa0Casual boarding\\ngam es and Chess club\\nGaming:\\xa0Played in competitives\\ntournam ents, peaked GrandMaster\\nin League of Legends\\nSailing:\\xa0M em ber of the sailing club\\nat La Rochelle Université\\nBasket ball:\\xa0Sports association\\nduring M iddle School, teamwork\\nand fast decision making.\\nVolunteering\\nESN Cosmolyon\\n2023 – present\\nVice-President, holdings Culturals \\nEvent for internationals and local \\nstudent(Board gam es/Day \\ntrips/Spanish dinner)\\nAlter-ego Lyon 2\\n2023 – present\\nBuddy System  with Lyon 2 \\nUniversityEducation\\nMaster in Data Science, Université Lyon 2 Lumière\\n09/2023 – present\\n•Expertise in advanced data analysis: ANOVA, time series, biostatistics, NLP/LLM, \\nComputer Vision, and Deep Learning.\\n•Proficiency in Big Data and MLOps: web scraping, data warehouses, model \\ndeployment, and pipelines.\\n•Specialized in predictive analytics, focusing on the use of advanced statistical \\nmodels and machine learning algorithms for forecasting and decision making.\\nInternational Exchange Program, National Central University\\nTaoyuan, Taïwan\\n•GPA: 3.8 | Experience in data mining for biological data: autism classification, \\nsentiment analysis and Graph Neural Networks presentation on Reddit data.\\n•Research & Publications: Conducted a literature review on feature selection \\ntechniques and co-authored \"A Review of Feature Selection Techniques in Education\". \\nExplored Transformer models for advanced data analysis.\\nErasmus + Mobility, South East Technological University\\nWaterford, Ireland\\n•First Class Honours | EDA & predictive modeling on Titanic and Tips datasets with \\nup to 90% accuracy, NoSQL database creation for TFI bikes in Waterford, and data \\nvisualization in R with NYC flights data.\\n•DevOps on AWS: EC2 instances, S3 buckets, configuration, and achieved \\nautomation with Python scripts.\\nProfessional Experience\\nUniversity Informatics Department, Lyon 2\\npresent\\nStudent Job at the IT department of the university, help desk, loan of computer and \\nprofessional audiovisual equiment, teamwork.\\nInternship Data Analyst, SYSBLOCK\\nParis, France\\n•Dashboarding & Analytics: KPI derivation from Google Analytics data and \\ninteractive dashboards with Power BI.\\n•Web Development & Blockchain: Experience with Next.js for web development and \\nintroduction to blockchain technologies.\\nProjects\\nCreation of a Logistic Regression R package\\n•Logistic regression package from scratch :Implemented various optimizers \\n(Adam, mini-batch, SGD) and applied regularization techniques (L1, L2, ElasticNet). \\n•Successfully tested on classification tasks : achieved up to 90% accuracy on \\nStudentPerformance, Creditcard,  datasets and achieved similar performance to \\nscikit-learn..\\nProjet NLP Analysis of TripAdvisor review\\n•Web Scraping & Sentiment Analysis: Collected TripAdvisor data with \\nBeautifulSoup and performed sentiment analysis on user reviews. Aggregated \\ncomments using clustering techniques.\\n•End-to-End Application: Integrated a SQLite database and connected it to a \\nStreamlit app for enhanced visualization. Deployed as a Docker image.\\n•LLM & RAG for Summarization: Leveraged a Large Language Model (LLM) with \\nRetrieval-Augmented Generation (RAG) to summarize user reviews effectively.\\nProject AWS Cloud\\n•AWS Deployment & Scaling: Successfully deployed a template website on EC2 \\ninstances with a connected relational database on AWS.\\n•High Availability & Monitoring: Implemented an Auto Scaling Group with a Load \\nBalancer and set up monitoring using custom CloudWatch metrics.\\nLanguages/References\\nLanguages:\\xa0French - Native/Bilingual \\xa0\\xa0English C1 - Fluent\\xa0\\xa0Mandarin -\\nConversational\\nReferences:\\xa0Bernard Butler, Pr, SETU\\xa0\\xa0bernard.butler@setu.ie \\xa0\\xa0Liam Doyle, Pr,\\nSETU\\xa0\\xa0liam.doyle@setu.ie\\n|\\n|\\n|\\n|\\n|\"\\n\\n        Ne retourne que le JSON, sans commentaires supplémentaires.\\n        '}], 'thinking': None}\n",
      "\u001b[92m23:39:35 - LiteLLM:DEBUG\u001b[0m: utils.py:2980 - \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.01, 'max_tokens': 1500}\n",
      "\u001b[92m23:39:35 - LiteLLM:DEBUG\u001b[0m: utils.py:308 - Final returned optional params: {'temperature': 0.01, 'max_tokens': 1500, 'extra_body': {}}\n",
      "\u001b[92m23:39:35 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:386 - self.optional_params: {'temperature': 0.01, 'max_tokens': 1500, 'extra_body': {}}\n",
      "\u001b[92m23:39:35 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:682 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://api.mistral.ai/v1/ \\\n",
      "-d '{'model': 'mistral-medium', 'messages': [{'role': 'user', 'content': '\\n        À partir du texte brut d\\'un CV, extrais les informations suivantes au format JSON. \\n        Si une information n\\'est pas explicitement mentionnée dans le texte, retourne `null` ou une liste vide.\\n        Ne devine pas les informations manquantes et ne retourne que ce qui est clairement présent dans le texte.\\n\\n        Format JSON attendu :\\n        {\\n            \"Diplome\": [\\n                {\\n                    \"niveau_etudes\": \"str\",  // Ex: \"Licence\", \"Master\", \"Doctorat\"\\n                    \"domaine_etudes\": [\"str\"]  // Ex: [\"Informatique\", \"Mathématiques\"]\\n                }\\n            ],\\n            \"Competences\": [\"str\"],  // Ex: [\"Python\", \"Gestion de projet\"]\\n            \"Experiences\": [\\n                {\\n                    \"domaine_activite\": [\"str\"],  // Ex: [\"Tech\", \"Finance\"]\\n                    \"poste_occupe\": \"str\",  // Ex: \"Développeur Python\"\\n                    \"duree\": \"str\"  // Ex: \"2 ans\"\\n                }\\n            ],\\n            \"Profil\": {\\n                \"titre\": \"str\",  // Ex: \"Développeur Full-Stack\"\\n                \"disponibilite\": \"str\"  // Ex: \"Immédiate\"\\n            }\\n        }\\n\\n        Texte du CV :\\n        \"Quentin Lim  \\nLast year Student in \\nData Science\\nquentinlim 384@ gm ail.com\\n+33782885515\\nlinkedin.com /in/quentin-lim-\\n978746250\\ngithub.com /QL2111\\nProfile\\nCurrently seeking an internship in \\nData Science starting in March \\n2025 for a duration of 4 to 6 \\nmonths.\\nSkills\\nM L, NLP, TensorFlow; Scikit-learn, \\nM LFlow, Transform ers, LLM , Tim e \\nSeries.\\nSQL, NoSQL, M ongoDB\\nQlik, Tableau, PowerBI\\nOpenCV, YOLO\\nAzure, AW S, Fabric\\nGit/Agile m ethodology\\nPython/R/Java/PySpark/JavaScript/\\nPHP\\nGen AI\\nInterests\\nBoard Games:\\xa0Casual boarding\\ngam es and Chess club\\nGaming:\\xa0Played in competitives\\ntournam ents, peaked GrandMaster\\nin League of Legends\\nSailing:\\xa0M em ber of the sailing club\\nat La Rochelle Université\\nBasket ball:\\xa0Sports association\\nduring M iddle School, teamwork\\nand fast decision making.\\nVolunteering\\nESN Cosmolyon\\n2023 – present\\nVice-President, holdings Culturals \\nEvent for internationals and local \\nstudent(Board gam es/Day \\ntrips/Spanish dinner)\\nAlter-ego Lyon 2\\n2023 – present\\nBuddy System  with Lyon 2 \\nUniversityEducation\\nMaster in Data Science, Université Lyon 2 Lumière\\n09/2023 – present\\n•Expertise in advanced data analysis: ANOVA, time series, biostatistics, NLP/LLM, \\nComputer Vision, and Deep Learning.\\n•Proficiency in Big Data and MLOps: web scraping, data warehouses, model \\ndeployment, and pipelines.\\n•Specialized in predictive analytics, focusing on the use of advanced statistical \\nmodels and machine learning algorithms for forecasting and decision making.\\nInternational Exchange Program, National Central University\\nTaoyuan, Taïwan\\n•GPA: 3.8 | Experience in data mining for biological data: autism classification, \\nsentiment analysis and Graph Neural Networks presentation on Reddit data.\\n•Research & Publications: Conducted a literature review on feature selection \\ntechniques and co-authored \"A Review of Feature Selection Techniques in Education\". \\nExplored Transformer models for advanced data analysis.\\nErasmus + Mobility, South East Technological University\\nWaterford, Ireland\\n•First Class Honours | EDA & predictive modeling on Titanic and Tips datasets with \\nup to 90% accuracy, NoSQL database creation for TFI bikes in Waterford, and data \\nvisualization in R with NYC flights data.\\n•DevOps on AWS: EC2 instances, S3 buckets, configuration, and achieved \\nautomation with Python scripts.\\nProfessional Experience\\nUniversity Informatics Department, Lyon 2\\npresent\\nStudent Job at the IT department of the university, help desk, loan of computer and \\nprofessional audiovisual equiment, teamwork.\\nInternship Data Analyst, SYSBLOCK\\nParis, France\\n•Dashboarding & Analytics: KPI derivation from Google Analytics data and \\ninteractive dashboards with Power BI.\\n•Web Development & Blockchain: Experience with Next.js for web development and \\nintroduction to blockchain technologies.\\nProjects\\nCreation of a Logistic Regression R package\\n•Logistic regression package from scratch :Implemented various optimizers \\n(Adam, mini-batch, SGD) and applied regularization techniques (L1, L2, ElasticNet). \\n•Successfully tested on classification tasks : achieved up to 90% accuracy on \\nStudentPerformance, Creditcard,  datasets and achieved similar performance to \\nscikit-learn..\\nProjet NLP Analysis of TripAdvisor review\\n•Web Scraping & Sentiment Analysis: Collected TripAdvisor data with \\nBeautifulSoup and performed sentiment analysis on user reviews. Aggregated \\ncomments using clustering techniques.\\n•End-to-End Application: Integrated a SQLite database and connected it to a \\nStreamlit app for enhanced visualization. Deployed as a Docker image.\\n•LLM & RAG for Summarization: Leveraged a Large Language Model (LLM) with \\nRetrieval-Augmented Generation (RAG) to summarize user reviews effectively.\\nProject AWS Cloud\\n•AWS Deployment & Scaling: Successfully deployed a template website on EC2 \\ninstances with a connected relational database on AWS.\\n•High Availability & Monitoring: Implemented an Auto Scaling Group with a Load \\nBalancer and set up monitoring using custom CloudWatch metrics.\\nLanguages/References\\nLanguages:\\xa0French - Native/Bilingual \\xa0\\xa0English C1 - Fluent\\xa0\\xa0Mandarin -\\nConversational\\nReferences:\\xa0Bernard Butler, Pr, SETU\\xa0\\xa0bernard.butler@setu.ie \\xa0\\xa0Liam Doyle, Pr,\\nSETU\\xa0\\xa0liam.doyle@setu.ie\\n|\\n|\\n|\\n|\\n|\"\\n\\n        Ne retourne que le JSON, sans commentaires supplémentaires.\\n        '}], 'temperature': 0.01, 'max_tokens': 1500, 'extra_body': {}}'\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[92m23:39:47 - LiteLLM:DEBUG\u001b[0m: utils.py:308 - RAW RESPONSE:\n",
      "{\"id\": \"2ece9e6095684d51b9f2561ab9d68d8c\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\n  \\\"Diplome\\\": [\\n    {\\n      \\\"niveau_etudes\\\": \\\"Master\\\",\\n      \\\"domaine_etudes\\\": [\\\"Data Science\\\"]\\n    }\\n  ],\\n  \\\"Competences\\\": [\\n    \\\"ML\\\",\\n    \\\"NLP\\\",\\n    \\\"TensorFlow\\\",\\n    \\\"Scikit-learn\\\",\\n    \\\"MLFlow\\\",\\n    \\\"Transformers\\\",\\n    \\\"LLM\\\",\\n    \\\"Time Series\\\",\\n    \\\"SQL\\\",\\n    \\\"NoSQL\\\",\\n    \\\"MongoDB\\\",\\n    \\\"Qlik\\\",\\n    \\\"Tableau\\\",\\n    \\\"PowerBI\\\",\\n    \\\"OpenCV\\\",\\n    \\\"YOLO\\\",\\n    \\\"Azure\\\",\\n    \\\"AWS\\\",\\n    \\\"Fabric\\\",\\n    \\\"Git/Agile methodology\\\",\\n    \\\"Python\\\",\\n    \\\"R\\\",\\n    \\\"Java\\\",\\n    \\\"PySpark\\\",\\n    \\\"JavaScript\\\",\\n    \\\"PHP\\\",\\n    \\\"Gen AI\\\"\\n  ],\\n  \\\"Experiences\\\": [\\n    {\\n      \\\"domaine_activite\\\": [],\\n      \\\"poste_occupe\\\": \\\"Vice-President\\\",\\n      \\\"duree\\\": \\\"2023 \\u2013 present\\\"\\n    },\\n    {\\n      \\\"domaine_activite\\\": [],\\n      \\\"poste_occupe\\\": \\\"Buddy System\\\",\\n      \\\"duree\\\": \\\"2023 \\u2013 present\\\"\\n    },\\n    {\\n      \\\"domaine_activite\\\": [\\\"Data Science\\\"],\\n      \\\"poste_occupe\\\": \\\"Student Job\\\",\\n      \\\"duree\\\": \\\"present\\\"\\n    },\\n    {\\n      \\\"domaine_activite\\\": [\\\"Data Analysis\\\"],\\n      \\\"poste_occupe\\\": \\\"Internship Data Analyst\\\",\\n      \\\"duree\\\": \\\"Dashboarding & Analytics: KPI derivation from Google Analytics data and interactive dashboards with Power BI.\\\"\\n    }\\n  ],\\n  \\\"Profil\\\": {\\n    \\\"titre\\\": \\\"Currently seeking an internship in Data Science\\\",\\n    \\\"disponibilite\\\": \\\"starting in March 2025 for a duration of 4 to 6 months.\\\"\\n  }\\n}\", \"refusal\": null, \"role\": \"assistant\", \"annotations\": null, \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1741819177, \"model\": \"mistral-medium\", \"object\": \"chat.completion\", \"service_tier\": null, \"system_fingerprint\": null, \"usage\": {\"completion_tokens\": 499, \"prompt_tokens\": 1656, \"total_tokens\": 2155, \"completion_tokens_details\": null, \"prompt_tokens_details\": null}}\n",
      "\n",
      "\n",
      "\u001b[92m23:39:47 - LiteLLM:INFO\u001b[0m: utils.py:1143 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m23:39:47 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:576 - completion_response _select_model_name_for_cost_calc: mistral/mistral-medium\n",
      "\u001b[92m23:39:47 - LiteLLM:DEBUG\u001b[0m: utils.py:4270 - checking potential_model_names in litellm.model_cost: {'split_model': 'mistral-medium', 'combined_model_name': 'mistral/mistral-medium', 'stripped_model_name': 'mistral-medium', 'combined_stripped_model_name': 'mistral/mistral-medium', 'custom_llm_provider': 'mistral'}\n",
      "\u001b[92m23:39:47 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:339 - Returned custom cost for model=mistral/mistral-medium - prompt_tokens_cost_usd_dollar: 0.0044712, completion_tokens_cost_usd_dollar: 0.0040419\n",
      "\u001b[92m23:39:47 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:911 - response_cost: 0.0085131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Diplome\": [\n",
      "    {\n",
      "      \"niveau_etudes\": \"Master\",\n",
      "      \"domaine_etudes\": [\"Data Science\"]\n",
      "    }\n",
      "  ],\n",
      "  \"Competences\": [\n",
      "    \"ML\",\n",
      "    \"NLP\",\n",
      "    \"TensorFlow\",\n",
      "    \"Scikit-learn\",\n",
      "    \"MLFlow\",\n",
      "    \"Transformers\",\n",
      "    \"LLM\",\n",
      "    \"Time Series\",\n",
      "    \"SQL\",\n",
      "    \"NoSQL\",\n",
      "    \"MongoDB\",\n",
      "    \"Qlik\",\n",
      "    \"Tableau\",\n",
      "    \"PowerBI\",\n",
      "    \"OpenCV\",\n",
      "    \"YOLO\",\n",
      "    \"Azure\",\n",
      "    \"AWS\",\n",
      "    \"Fabric\",\n",
      "    \"Git/Agile methodology\",\n",
      "    \"Python\",\n",
      "    \"R\",\n",
      "    \"Java\",\n",
      "    \"PySpark\",\n",
      "    \"JavaScript\",\n",
      "    \"PHP\",\n",
      "    \"Gen AI\"\n",
      "  ],\n",
      "  \"Experiences\": [\n",
      "    {\n",
      "      \"domaine_activite\": [],\n",
      "      \"poste_occupe\": \"Vice-President\",\n",
      "      \"duree\": \"2023 – present\"\n",
      "    },\n",
      "    {\n",
      "      \"domaine_activite\": [],\n",
      "      \"poste_occupe\": \"Buddy System\",\n",
      "      \"duree\": \"2023 – present\"\n",
      "    },\n",
      "    {\n",
      "      \"domaine_activite\": [\"Data Science\"],\n",
      "      \"poste_occupe\": \"Student Job\",\n",
      "      \"duree\": \"present\"\n",
      "    },\n",
      "    {\n",
      "      \"domaine_activite\": [\"Data Analysis\"],\n",
      "      \"poste_occupe\": \"Internship Data Analyst\",\n",
      "      \"duree\": \"Dashboarding & Analytics: KPI derivation from Google Analytics data and interactive dashboards with Power BI.\"\n",
      "    }\n",
      "  ],\n",
      "  \"Profil\": {\n",
      "    \"titre\": \"Currently seeking an internship in Data Science\",\n",
      "    \"disponibilite\": \"starting in March 2025 for a duration of 4 to 6 months.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "CV_reformuler = analyze_cv(text_brut)\n",
    "print(CV_reformuler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matching CV et offre :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Example job offer\n",
    "job_offer = \"\"\"\n",
    "  Titre : Data scientist (H/F) SALON TAF Toulouse 2025\n",
    "  Entreprise : AOSIS CONSULTING\n",
    "  Contrat : CDI\n",
    "  Localisation : 31 - TOULOUSE\n",
    "  Description :\n",
    "  Concrètement qu'est-ce qu'on fait ?\n",
    "  Nous proposons des Services, des Logiciels et de la Formation dans le domaine de la Business Intelligence, de la Data Science, de la Gouvernance et de la Visualisation de la donnée. L'Infrastructure et le Développement font également partie du panel de nos compétences.\n",
    "  Notre leitmotiv ? Citoyenneté, écologie et sport avec des experts de la donnée.\n",
    "  Notre objectif ? Porter encore plus haut et plus fort nos valeurs de sport, d'écologie et de citoyenneté et accompagner nos consultants dans leur montée en compétence.\n",
    "\n",
    "  Le poste\n",
    "  Dans le cadre d'une ouverture de poste, nous sommes à la recherche d'un.e Data Scientist pour l'un de nos clients.\n",
    "  Un.e data scientist senior (5 ans d'expérience) très autonome dans ses analyses et explorations, expérimenté dans l'industrialisation des modèles dans des environnements cloud.\n",
    "\n",
    "  Vous interviendrez sur toutes les étapes du projet, vous devrez :\n",
    "\n",
    "  Identifier leurs difficultés et proposer des solutions\n",
    "  Evaluer la qualité des données, les nettoyer, les agréger, et mener des études adhoc\n",
    "  Concevoir, implémenter et comparer différents algorithmes et méthodes statistiques\n",
    "  Concevoir et mener des protocoles de test en conditions réelles (magasins, entrepôts, .)\n",
    "  Développer des outils de visualisation des données\n",
    "  Mettre en production, maintenir et itérer sur les solutions\n",
    "\n",
    "  Environnement technique: Python, SQL, Terraform, Bitbucket, Jenkins, Airflow, Docker, Kubernetes, GCP (BigQuery, Spark DataProc)\n",
    "\n",
    "  Profil recherché\n",
    "  Vous êtes issu.e d'un Master en informatique ou mathématiques appliquées.\n",
    "  Vous avez à minima 5 années d'expériences en Data Science et maitrisez les algorithmes d'apprentissage statistique.\n",
    "  Vous maîtrisez Python et SQL\n",
    "  Vous avez une expérience dans le développement logiciel agile avec multiples contributeurs\n",
    "  Vous avez une expérience du cloud, idéalement GCP\n",
    "\n",
    "  Pourquoi nous rejoindre ?\n",
    "  Parce que nous sommes une société à taille humaine\n",
    "  Parce que nous nous engageons (réellement) dans des enjeux importants : l'écologie, la citoyenneté et le sport\n",
    "  Mais aussi parce que nous aimons réaliser tout un tas d'activités : des jeux, des afterworks, des restaurants, ... et plein d'autres choses encore :)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Transformation de l'offre d'emploi au même format que le CV\n",
    "def analyze_cv_offre_emploi(offre: str, temperature: float = 0.01, max_tokens: int = 1500) -> str:\n",
    "    \"\"\"\n",
    "    Analyse une offre d'emploi en format texte et retourne les informations structurées en JSON.\n",
    "\n",
    "    Args:\n",
    "        text_brut (str): Texte brut del'offre à analyser\n",
    "        temperature (float, optional): Paramètre de créativité du modèle. Defaults to 0.2.\n",
    "        max_tokens (int, optional): Nombre maximum de tokens pour la réponse. Defaults to 1500.\n",
    "\n",
    "    Returns:\n",
    "        str: Informations en string(réponse du LLM) structurées du CV au format JSON\n",
    "\n",
    "    Raises:\n",
    "        Exception: En cas d'erreur d'API ou de parsing JSON\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reformulation_prompt = f\"\"\"\n",
    "        À partir de cette offre d'emploi, extrais les informations suivantes au format JSON. \n",
    "        Si une information n'est pas explicitement mentionnée dans le texte, retourne `null` ou une liste vide.\n",
    "        Ne devine pas les informations manquantes et ne retourne que ce qui est clairement présent dans le texte.\n",
    "\n",
    "        Format JSON attendu :\n",
    "        {{\n",
    "            \"Formation\": [\n",
    "                {{\n",
    "                    \"niveau_etudes\": \"str\",  // Ex: \"Licence\", \"Master\", \"Doctorat\"\n",
    "                    \"domaine_etudes\": [\"str\"]  // Ex: [\"Informatique\", \"Mathématiques\"]\n",
    "                }}\n",
    "            ],\n",
    "            \"Competences\": [\"str\"],  // Ex: [\"Python\", \"Gestion de projet\"]\n",
    "            \"Experiences\": [\n",
    "                {{\n",
    "                    \"domaine_activite\": [\"str\"],  // Ex: [\"Tech\", \"Finance\"]\n",
    "                    \"poste_occupe\": \"str\",  // Ex: \"Développeur Python\"\n",
    "                    \"duree\": \"str\"  // Ex: \"2 ans\"\n",
    "                }}\n",
    "            ],\n",
    "            \"Profil\": {{\n",
    "                \"titre\": \"str\",  // Ex: \"Développeur Full-Stack\"\n",
    "                \"disponibilite\": \"str\"  // Ex: \"Immédiate\"\n",
    "            }}\n",
    "        }}\n",
    "\n",
    "        Texte de l'offre d'emploi :\n",
    "        \"{offre}\"\n",
    "\n",
    "        Ne retourne que le JSON, sans commentaires supplémentaires.\n",
    "        \"\"\"\n",
    "\n",
    "        offre_reformuler = litellm.completion(\n",
    "            model=\"mistral/mistral-medium\",\n",
    "            messages=[{\"role\": \"user\", \"content\": reformulation_prompt}],\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            api_key=os.getenv(\"MISTRAL_API_KEY\"),\n",
    "        )\n",
    "\n",
    "        # Extraire et parser le JSON de la réponse\n",
    "        resultat = offre_reformuler[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        return resultat\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Erreur lors de l'analyse du CV: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m00:01:40 - LiteLLM:DEBUG\u001b[0m: utils.py:308 - \n",
      "\n",
      "\u001b[92m00:01:40 - LiteLLM:DEBUG\u001b[0m: utils.py:308 - \u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92m00:01:40 - LiteLLM:DEBUG\u001b[0m: utils.py:308 - \u001b[92mlitellm.completion(model='mistral/mistral-medium', messages=[{'role': 'user', 'content': '\\n        À partir de cette offre d\\'emploi, extrais les informations suivantes au format JSON. \\n        Si une information n\\'est pas explicitement mentionnée dans le texte, retourne `null` ou une liste vide.\\n        Ne devine pas les informations manquantes et ne retourne que ce qui est clairement présent dans le texte.\\n\\n        Format JSON attendu :\\n        {\\n            \"Formation\": [\\n                {\\n                    \"niveau_etudes\": \"str\",  // Ex: \"Licence\", \"Master\", \"Doctorat\"\\n                    \"domaine_etudes\": [\"str\"]  // Ex: [\"Informatique\", \"Mathématiques\"]\\n                }\\n            ],\\n            \"Competences\": [\"str\"],  // Ex: [\"Python\", \"Gestion de projet\"]\\n            \"Experiences\": [\\n                {\\n                    \"domaine_activite\": [\"str\"],  // Ex: [\"Tech\", \"Finance\"]\\n                    \"poste_occupe\": \"str\",  // Ex: \"Développeur Python\"\\n                    \"duree\": \"str\"  // Ex: \"2 ans\"\\n                }\\n            ],\\n            \"Profil\": {\\n                \"titre\": \"str\",  // Ex: \"Développeur Full-Stack\"\\n                \"disponibilite\": \"str\"  // Ex: \"Immédiate\"\\n            }\\n        }\\n\\n        Texte de l\\'offre d\\'emploi :\\n        \"\\n  Titre : Data scientist (H/F) SALON TAF Toulouse 2025\\n  Entreprise : AOSIS CONSULTING\\n  Contrat : CDI\\n  Localisation : 31 - TOULOUSE\\n  Description :\\n  Concrètement qu\\'est-ce qu\\'on fait ?\\n  Nous proposons des Services, des Logiciels et de la Formation dans le domaine de la Business Intelligence, de la Data Science, de la Gouvernance et de la Visualisation de la donnée. L\\'Infrastructure et le Développement font également partie du panel de nos compétences.\\n  Notre leitmotiv ? Citoyenneté, écologie et sport avec des experts de la donnée.\\n  Notre objectif ? Porter encore plus haut et plus fort nos valeurs de sport, d\\'écologie et de citoyenneté et accompagner nos consultants dans leur montée en compétence.\\n\\n  Le poste\\n  Dans le cadre d\\'une ouverture de poste, nous sommes à la recherche d\\'un.e Data Scientist pour l\\'un de nos clients.\\n  Un.e data scientist senior (5 ans d\\'expérience) très autonome dans ses analyses et explorations, expérimenté dans l\\'industrialisation des modèles dans des environnements cloud.\\n\\n  Vous interviendrez sur toutes les étapes du projet, vous devrez :\\n\\n  Identifier leurs difficultés et proposer des solutions\\n  Evaluer la qualité des données, les nettoyer, les agréger, et mener des études adhoc\\n  Concevoir, implémenter et comparer différents algorithmes et méthodes statistiques\\n  Concevoir et mener des protocoles de test en conditions réelles (magasins, entrepôts, .)\\n  Développer des outils de visualisation des données\\n  Mettre en production, maintenir et itérer sur les solutions\\n\\n  Environnement technique: Python, SQL, Terraform, Bitbucket, Jenkins, Airflow, Docker, Kubernetes, GCP (BigQuery, Spark DataProc)\\n\\n  Profil recherché\\n  Vous êtes issu.e d\\'un Master en informatique ou mathématiques appliquées.\\n  Vous avez à minima 5 années d\\'expériences en Data Science et maitrisez les algorithmes d\\'apprentissage statistique.\\n  Vous maîtrisez Python et SQL\\n  Vous avez une expérience dans le développement logiciel agile avec multiples contributeurs\\n  Vous avez une expérience du cloud, idéalement GCP\\n\\n  Pourquoi nous rejoindre ?\\n  Parce que nous sommes une société à taille humaine\\n  Parce que nous nous engageons (réellement) dans des enjeux importants : l\\'écologie, la citoyenneté et le sport\\n  Mais aussi parce que nous aimons réaliser tout un tas d\\'activités : des jeux, des afterworks, des restaurants, ... et plein d\\'autres choses encore :)\\n\"\\n\\n        Ne retourne que le JSON, sans commentaires supplémentaires.\\n        '}], max_tokens=1500, temperature=0.01, api_key='dkMKu81kFgJeP7HmIqjztosQTxyiynW6')\u001b[0m\n",
      "\u001b[92m00:01:40 - LiteLLM:DEBUG\u001b[0m: utils.py:308 - \n",
      "\n",
      "\u001b[92m00:01:40 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:386 - self.optional_params: {}\n",
      "\u001b[92m00:01:40 - LiteLLM:DEBUG\u001b[0m: utils.py:308 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "\u001b[92m00:01:40 - LiteLLM:INFO\u001b[0m: utils.py:2974 - \n",
      "LiteLLM completion() model= mistral-medium; provider = mistral\n",
      "\u001b[92m00:01:40 - LiteLLM:DEBUG\u001b[0m: utils.py:2977 - \n",
      "LiteLLM: Params passed to completion() {'model': 'mistral-medium', 'functions': None, 'function_call': None, 'temperature': 0.01, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 1500, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'mistral', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'user', 'content': '\\n        À partir de cette offre d\\'emploi, extrais les informations suivantes au format JSON. \\n        Si une information n\\'est pas explicitement mentionnée dans le texte, retourne `null` ou une liste vide.\\n        Ne devine pas les informations manquantes et ne retourne que ce qui est clairement présent dans le texte.\\n\\n        Format JSON attendu :\\n        {\\n            \"Formation\": [\\n                {\\n                    \"niveau_etudes\": \"str\",  // Ex: \"Licence\", \"Master\", \"Doctorat\"\\n                    \"domaine_etudes\": [\"str\"]  // Ex: [\"Informatique\", \"Mathématiques\"]\\n                }\\n            ],\\n            \"Competences\": [\"str\"],  // Ex: [\"Python\", \"Gestion de projet\"]\\n            \"Experiences\": [\\n                {\\n                    \"domaine_activite\": [\"str\"],  // Ex: [\"Tech\", \"Finance\"]\\n                    \"poste_occupe\": \"str\",  // Ex: \"Développeur Python\"\\n                    \"duree\": \"str\"  // Ex: \"2 ans\"\\n                }\\n            ],\\n            \"Profil\": {\\n                \"titre\": \"str\",  // Ex: \"Développeur Full-Stack\"\\n                \"disponibilite\": \"str\"  // Ex: \"Immédiate\"\\n            }\\n        }\\n\\n        Texte de l\\'offre d\\'emploi :\\n        \"\\n  Titre : Data scientist (H/F) SALON TAF Toulouse 2025\\n  Entreprise : AOSIS CONSULTING\\n  Contrat : CDI\\n  Localisation : 31 - TOULOUSE\\n  Description :\\n  Concrètement qu\\'est-ce qu\\'on fait ?\\n  Nous proposons des Services, des Logiciels et de la Formation dans le domaine de la Business Intelligence, de la Data Science, de la Gouvernance et de la Visualisation de la donnée. L\\'Infrastructure et le Développement font également partie du panel de nos compétences.\\n  Notre leitmotiv ? Citoyenneté, écologie et sport avec des experts de la donnée.\\n  Notre objectif ? Porter encore plus haut et plus fort nos valeurs de sport, d\\'écologie et de citoyenneté et accompagner nos consultants dans leur montée en compétence.\\n\\n  Le poste\\n  Dans le cadre d\\'une ouverture de poste, nous sommes à la recherche d\\'un.e Data Scientist pour l\\'un de nos clients.\\n  Un.e data scientist senior (5 ans d\\'expérience) très autonome dans ses analyses et explorations, expérimenté dans l\\'industrialisation des modèles dans des environnements cloud.\\n\\n  Vous interviendrez sur toutes les étapes du projet, vous devrez :\\n\\n  Identifier leurs difficultés et proposer des solutions\\n  Evaluer la qualité des données, les nettoyer, les agréger, et mener des études adhoc\\n  Concevoir, implémenter et comparer différents algorithmes et méthodes statistiques\\n  Concevoir et mener des protocoles de test en conditions réelles (magasins, entrepôts, .)\\n  Développer des outils de visualisation des données\\n  Mettre en production, maintenir et itérer sur les solutions\\n\\n  Environnement technique: Python, SQL, Terraform, Bitbucket, Jenkins, Airflow, Docker, Kubernetes, GCP (BigQuery, Spark DataProc)\\n\\n  Profil recherché\\n  Vous êtes issu.e d\\'un Master en informatique ou mathématiques appliquées.\\n  Vous avez à minima 5 années d\\'expériences en Data Science et maitrisez les algorithmes d\\'apprentissage statistique.\\n  Vous maîtrisez Python et SQL\\n  Vous avez une expérience dans le développement logiciel agile avec multiples contributeurs\\n  Vous avez une expérience du cloud, idéalement GCP\\n\\n  Pourquoi nous rejoindre ?\\n  Parce que nous sommes une société à taille humaine\\n  Parce que nous nous engageons (réellement) dans des enjeux importants : l\\'écologie, la citoyenneté et le sport\\n  Mais aussi parce que nous aimons réaliser tout un tas d\\'activités : des jeux, des afterworks, des restaurants, ... et plein d\\'autres choses encore :)\\n\"\\n\\n        Ne retourne que le JSON, sans commentaires supplémentaires.\\n        '}], 'thinking': None}\n",
      "\u001b[92m00:01:40 - LiteLLM:DEBUG\u001b[0m: utils.py:2980 - \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.01, 'max_tokens': 1500}\n",
      "\u001b[92m00:01:40 - LiteLLM:DEBUG\u001b[0m: utils.py:308 - Final returned optional params: {'temperature': 0.01, 'max_tokens': 1500, 'extra_body': {}}\n",
      "\u001b[92m00:01:40 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:386 - self.optional_params: {'temperature': 0.01, 'max_tokens': 1500, 'extra_body': {}}\n",
      "\u001b[92m00:01:40 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:682 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://api.mistral.ai/v1/ \\\n",
      "-d '{'model': 'mistral-medium', 'messages': [{'role': 'user', 'content': '\\n        À partir de cette offre d\\'emploi, extrais les informations suivantes au format JSON. \\n        Si une information n\\'est pas explicitement mentionnée dans le texte, retourne `null` ou une liste vide.\\n        Ne devine pas les informations manquantes et ne retourne que ce qui est clairement présent dans le texte.\\n\\n        Format JSON attendu :\\n        {\\n            \"Formation\": [\\n                {\\n                    \"niveau_etudes\": \"str\",  // Ex: \"Licence\", \"Master\", \"Doctorat\"\\n                    \"domaine_etudes\": [\"str\"]  // Ex: [\"Informatique\", \"Mathématiques\"]\\n                }\\n            ],\\n            \"Competences\": [\"str\"],  // Ex: [\"Python\", \"Gestion de projet\"]\\n            \"Experiences\": [\\n                {\\n                    \"domaine_activite\": [\"str\"],  // Ex: [\"Tech\", \"Finance\"]\\n                    \"poste_occupe\": \"str\",  // Ex: \"Développeur Python\"\\n                    \"duree\": \"str\"  // Ex: \"2 ans\"\\n                }\\n            ],\\n            \"Profil\": {\\n                \"titre\": \"str\",  // Ex: \"Développeur Full-Stack\"\\n                \"disponibilite\": \"str\"  // Ex: \"Immédiate\"\\n            }\\n        }\\n\\n        Texte de l\\'offre d\\'emploi :\\n        \"\\n  Titre : Data scientist (H/F) SALON TAF Toulouse 2025\\n  Entreprise : AOSIS CONSULTING\\n  Contrat : CDI\\n  Localisation : 31 - TOULOUSE\\n  Description :\\n  Concrètement qu\\'est-ce qu\\'on fait ?\\n  Nous proposons des Services, des Logiciels et de la Formation dans le domaine de la Business Intelligence, de la Data Science, de la Gouvernance et de la Visualisation de la donnée. L\\'Infrastructure et le Développement font également partie du panel de nos compétences.\\n  Notre leitmotiv ? Citoyenneté, écologie et sport avec des experts de la donnée.\\n  Notre objectif ? Porter encore plus haut et plus fort nos valeurs de sport, d\\'écologie et de citoyenneté et accompagner nos consultants dans leur montée en compétence.\\n\\n  Le poste\\n  Dans le cadre d\\'une ouverture de poste, nous sommes à la recherche d\\'un.e Data Scientist pour l\\'un de nos clients.\\n  Un.e data scientist senior (5 ans d\\'expérience) très autonome dans ses analyses et explorations, expérimenté dans l\\'industrialisation des modèles dans des environnements cloud.\\n\\n  Vous interviendrez sur toutes les étapes du projet, vous devrez :\\n\\n  Identifier leurs difficultés et proposer des solutions\\n  Evaluer la qualité des données, les nettoyer, les agréger, et mener des études adhoc\\n  Concevoir, implémenter et comparer différents algorithmes et méthodes statistiques\\n  Concevoir et mener des protocoles de test en conditions réelles (magasins, entrepôts, .)\\n  Développer des outils de visualisation des données\\n  Mettre en production, maintenir et itérer sur les solutions\\n\\n  Environnement technique: Python, SQL, Terraform, Bitbucket, Jenkins, Airflow, Docker, Kubernetes, GCP (BigQuery, Spark DataProc)\\n\\n  Profil recherché\\n  Vous êtes issu.e d\\'un Master en informatique ou mathématiques appliquées.\\n  Vous avez à minima 5 années d\\'expériences en Data Science et maitrisez les algorithmes d\\'apprentissage statistique.\\n  Vous maîtrisez Python et SQL\\n  Vous avez une expérience dans le développement logiciel agile avec multiples contributeurs\\n  Vous avez une expérience du cloud, idéalement GCP\\n\\n  Pourquoi nous rejoindre ?\\n  Parce que nous sommes une société à taille humaine\\n  Parce que nous nous engageons (réellement) dans des enjeux importants : l\\'écologie, la citoyenneté et le sport\\n  Mais aussi parce que nous aimons réaliser tout un tas d\\'activités : des jeux, des afterworks, des restaurants, ... et plein d\\'autres choses encore :)\\n\"\\n\\n        Ne retourne que le JSON, sans commentaires supplémentaires.\\n        '}], 'temperature': 0.01, 'max_tokens': 1500, 'extra_body': {}}'\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[92m00:01:46 - LiteLLM:DEBUG\u001b[0m: utils.py:308 - RAW RESPONSE:\n",
      "{\"id\": \"b85908262ddd4a3bbf7172a2bae51910\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\n  \\\"Formation\\\": [\\n    {\\n      \\\"niveau_etudes\\\": \\\"Master\\\",\\n      \\\"domaine_etudes\\\": [\\\"Informatique\\\", \\\"Math\\u00e9matiques appliqu\\u00e9es\\\"]\\n    }\\n  ],\\n  \\\"Competences\\\": [\\\"Python\\\", \\\"SQL\\\", \\\"Terraform\\\", \\\"Bitbucket\\\", \\\"Jenkins\\\", \\\"Airflow\\\", \\\"Docker\\\", \\\"Kubernetes\\\", \\\"GCP (BigQuery, Spark DataProc)\\\", \\\"Apprentissage statistique\\\", \\\"D\\u00e9veloppement logiciel agile\\\"],\\n  \\\"Experiences\\\": [\\n    {\\n      \\\"domaine_activite\\\": [\\\"Data Science\\\"],\\n      \\\"poste_occupe\\\": \\\"Data Scientist\\\",\\n      \\\"duree\\\": \\\"5 ans\\\"\\n    }\\n  ],\\n  \\\"Profil\\\": {\\n    \\\"titre\\\": \\\"Data Scientist\\\",\\n    \\\"disponibilite\\\": null\\n  }\\n}\", \"refusal\": null, \"role\": \"assistant\", \"annotations\": null, \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1741820502, \"model\": \"mistral-medium\", \"object\": \"chat.completion\", \"service_tier\": null, \"system_fingerprint\": null, \"usage\": {\"completion_tokens\": 209, \"prompt_tokens\": 1104, \"total_tokens\": 1313, \"completion_tokens_details\": null, \"prompt_tokens_details\": null}}\n",
      "\n",
      "\n",
      "\u001b[92m00:01:46 - LiteLLM:INFO\u001b[0m: utils.py:1143 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m00:01:46 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:576 - completion_response _select_model_name_for_cost_calc: mistral/mistral-medium\n",
      "\u001b[92m00:01:46 - LiteLLM:DEBUG\u001b[0m: utils.py:4270 - checking potential_model_names in litellm.model_cost: {'split_model': 'mistral-medium', 'combined_model_name': 'mistral/mistral-medium', 'stripped_model_name': 'mistral-medium', 'combined_stripped_model_name': 'mistral/mistral-medium', 'custom_llm_provider': 'mistral'}\n",
      "\u001b[92m00:01:46 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:339 - Returned custom cost for model=mistral/mistral-medium - prompt_tokens_cost_usd_dollar: 0.0029808, completion_tokens_cost_usd_dollar: 0.0016929\n",
      "\u001b[92m00:01:46 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:911 - response_cost: 0.0046737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Formation\": [\n",
      "    {\n",
      "      \"niveau_etudes\": \"Master\",\n",
      "      \"domaine_etudes\": [\"Informatique\", \"Mathématiques appliquées\"]\n",
      "    }\n",
      "  ],\n",
      "  \"Competences\": [\"Python\", \"SQL\", \"Terraform\", \"Bitbucket\", \"Jenkins\", \"Airflow\", \"Docker\", \"Kubernetes\", \"GCP (BigQuery, Spark DataProc)\", \"Apprentissage statistique\", \"Développement logiciel agile\"],\n",
      "  \"Experiences\": [\n",
      "    {\n",
      "      \"domaine_activite\": [\"Data Science\"],\n",
      "      \"poste_occupe\": \"Data Scientist\",\n",
      "      \"duree\": \"5 ans\"\n",
      "    }\n",
      "  ],\n",
      "  \"Profil\": {\n",
      "    \"titre\": \"Data Scientist\",\n",
      "    \"disponibilite\": null\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "job_offer_reforumer = analyze_cv_offre_emploi(job_offer)\n",
    "print(job_offer_reforumer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarité globale entre le CV et l'offre d'emploi: 0.8539\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "\n",
    "# Charger un modèle Sentence-BERT pré-entraîné\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "def calculate_similarity(text1: str, text2: str) -> float:\n",
    "    \"\"\"\n",
    "    Calcule la similarité cosinus entre deux textes en utilisant Sentence-BERT.\n",
    "    \n",
    "    Args:\n",
    "        text1 (str): Premier texte.\n",
    "        text2 (str): Deuxième texte.\n",
    "    \n",
    "    Returns:\n",
    "        float: Score de similarité cosinus entre les deux textes.\n",
    "    \"\"\"\n",
    "    # Encoder les textes en embeddings\n",
    "    embedding1 = model.encode(text1, convert_to_tensor=True)\n",
    "    embedding2 = model.encode(text2, convert_to_tensor=True)\n",
    "    \n",
    "    # Calculer la similarité cosinus\n",
    "    similarity = util.cos_sim(embedding1, embedding2)\n",
    "    return similarity.item()\n",
    "\n",
    "# Calculer la similarité entre le CV et l'offre d'emploi\n",
    "similarity_score = calculate_similarity(CV_reformuler, job_offer_reforumer)\n",
    "print(f\"Similarité globale entre le CV et l'offre d'emploi: {similarity_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calcul de la similarité entre chaque partie du CV et l'offre d'emploi\n",
    "# Diviser le CV reformulé en json en plusieurs parties\n",
    "cv_json = json.loads(CV_reformuler)\n",
    "# print(cv_json)\n",
    "# convert job_offer to json\n",
    "job_offer_json = json.dumps(job_offer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"title\": \"Offre n\\u00b0 189KKQRD\\u00e9veloppeur Full Stack .Net  (H/F)\", \"skills\": [\"C#\", \"ASP.Net\", \"Javascript\", \"FrontEnd\", \"BackEnd\", \"Agile\", \"Scrum\"], \"description\": \"\\n    Rejoignez une \\u00e9quipe sympathique et dynamique, dans un groupe en forte croissance !\\n\\n    POSTE et MISSION\\n\\n    Au sein du p\\u00f4le \\u00abD\\u00e9veloppement et R&D\\u00bb, vous serez int\\u00e9gr\\u00e9-e \\u00e0 l'\\u00e9quipe charg\\u00e9e du d\\u00e9veloppement de nos Suites logicielles de gestion des risques Qualit\\u00e9, S\\u00e9curit\\u00e9, Environnement. A ce titre, vous travaillerez sur la conception et le d\\u00e9veloppement de nos logiciels (algorithmes, IHM, API, persistance, Front End, Back End, etc) :\\n\\n    - Int\\u00e9grez une petite \\u00e9quipe d'ing\\u00e9nieurs, stable, qui travaille en \\u00e9troite collaboration avec les autres services (notamment m\\u00e9tier), selon la m\\u00e9thode Agile (Scrum), sur des projets durables,\\n\\n    - A partir de sp\\u00e9cifications fonctionnelles, vous concevez et d\\u00e9veloppez les \\u00e9volutions et nouvelles fonctionnalit\\u00e9s de nos applications web en ASP.Net MVC (C#, Javascript, frontEnd) et de notre moteur m\\u00e9tier (en C#, C++, backEnd),\\n\\n    - Vous pr\\u00e9parez avec l'\\u00e9quipe, la prochaine g\\u00e9n\\u00e9ration de notre application (technologies, langages, frameworks, processus seront \\u00e0 d\\u00e9finir). Vos exp\\u00e9riences sont des atouts !\\n\\n    - Vous contribuez \\u00e0 la veille technologique, \\u00e0 la strat\\u00e9gie de tests, et \\u00e0 la hotline de 2\\u00e8me niveau (en soutien \\u00e0 l'\\u00e9quipe Hotline)\\n\\n    - Travail en \\u00e9quipe, autonomie, rigueur, souplesse et sens du service client sont indispensables\\n\\n    Nous utilisons actuellement Visual Studio 2022, GIT, Jira, Azure DevOps, N8N (Middleware). Nous nous appuyons sur une base de donn\\u00e9es objet propri\\u00e9taire et SQL Server. Nous g\\u00e9rons les \\u00e9volutions de nos solutions en client lourd, Web h\\u00e9berg\\u00e9 - Saas et responsive.\\n\\n    Lieu de travail et t\\u00e9l\\u00e9travail \\u00e0 convenir, en France m\\u00e9tropolitaine\\n\\n    R\\u00e9mun\\u00e9ration \\u00e0 convenir (35 \\u00e0 50 K\\u20ac selon parcours). Mutuelle avantageuse, ch\\u00e8ques-d\\u00e9jeuner, avantages CSE. Id\\u00e9alement temps plein. Horaires de bureau, pas d'astreinte. Opportunit\\u00e9s de carri\\u00e8res, mobilit\\u00e9 \\u00e0 l'International.\\n    \"}\n"
     ]
    }
   ],
   "source": [
    "print(job_offer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(CV_reformuler))\n",
    "print(type(job_offer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "challengeIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
