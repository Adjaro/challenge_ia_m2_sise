{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read PDF\n",
    "\n",
    "# from dotenv import load_dotenv\n",
    "# Charger les variables d'environnement\n",
    "# load_dotenv()\n",
    "# Faire lettre motivation automatique\n",
    "from datetime import datetime\n",
    "import locale\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def read_pdf(file_path: str) -> str:\n",
    "    \"\"\"Lit et extrait le texte d'un CV au format PDF d'une seule page.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Chemin d'accès vers le fichier PDF à lire\n",
    "\n",
    "    Returns:\n",
    "        str: Texte brut extrait du PDF\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: Si le fichier PDF n'existe pas\n",
    "        IndexError: Si le PDF est vide\n",
    "        Exception: Pour toute autre erreur lors de la lecture du PDF\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reader = PdfReader(file_path)\n",
    "        if len(reader.pages) == 0:\n",
    "            raise IndexError(\"Le PDF est vide\")\n",
    "        \n",
    "        page = reader.pages[0]  # Lecture de la première page uniquement\n",
    "        text_brut = page.extract_text()\n",
    "        \n",
    "        if not text_brut:\n",
    "            raise Exception(\"Aucun texte n'a pu être extrait du PDF\")\n",
    "            \n",
    "        return text_brut\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Le fichier {file_path} n'existe pas\")\n",
    "    except IndexError as e:\n",
    "        raise IndexError(str(e))\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Erreur lors de la lecture du PDF: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quentin Lim  \n",
      "Last year Student in \n",
      "Data Science\n",
      "quentinlim 384@ gm ail.com\n",
      "+33782885515\n",
      "linkedin.com /in/quentin-lim-\n",
      "978746250\n",
      "github.com /QL2111\n",
      "Profile\n",
      "Currently seeking an internship in \n",
      "Data Science starting in March \n",
      "2025 for a duration of 4 to 6 \n",
      "months.\n",
      "Skills\n",
      "M L, NLP, TensorFlow; Scikit-learn, \n",
      "M LFlow, Transform ers, LLM , Tim e \n",
      "Series.\n",
      "SQL, NoSQL, M ongoDB\n",
      "Qlik, Tableau, PowerBI\n",
      "OpenCV, YOLO\n",
      "Azure, AW S, Fabric\n",
      "Git/Agile m ethodology\n",
      "Python/R/Java/PySpark/JavaScript/\n",
      "PHP\n",
      "Gen AI\n",
      "Interests\n",
      "Board Games: Casual boarding\n",
      "gam es and Chess club\n",
      "Gaming: Played in competitives\n",
      "tournam ents, peaked GrandMaster\n",
      "in League of Legends\n",
      "Sailing: M em ber of the sailing club\n",
      "at La Rochelle Université\n",
      "Basket ball: Sports association\n",
      "during M iddle School, teamwork\n",
      "and fast decision making.\n",
      "Volunteering\n",
      "ESN Cosmolyon\n",
      "2023 – present\n",
      "Vice-President, holdings Culturals \n",
      "Event for internationals and local \n",
      "student(Board gam es/Day \n",
      "trips/Spanish dinner)\n",
      "Alter-ego Lyon 2\n",
      "2023 – present\n",
      "Buddy System  with Lyon 2 \n",
      "UniversityEducation\n",
      "Master in Data Science, Université Lyon 2 Lumière\n",
      "09/2023 – present\n",
      "•Expertise in advanced data analysis: ANOVA, time series, biostatistics, NLP/LLM, \n",
      "Computer Vision, and Deep Learning.\n",
      "•Proficiency in Big Data and MLOps: web scraping, data warehouses, model \n",
      "deployment, and pipelines.\n",
      "•Specialized in predictive analytics, focusing on the use of advanced statistical \n",
      "models and machine learning algorithms for forecasting and decision making.\n",
      "International Exchange Program, National Central University\n",
      "Taoyuan, Taïwan\n",
      "•GPA: 3.8 | Experience in data mining for biological data: autism classification, \n",
      "sentiment analysis and Graph Neural Networks presentation on Reddit data.\n",
      "•Research & Publications: Conducted a literature review on feature selection \n",
      "techniques and co-authored \"A Review of Feature Selection Techniques in Education\". \n",
      "Explored Transformer models for advanced data analysis.\n",
      "Erasmus + Mobility, South East Technological University\n",
      "Waterford, Ireland\n",
      "•First Class Honours | EDA & predictive modeling on Titanic and Tips datasets with \n",
      "up to 90% accuracy, NoSQL database creation for TFI bikes in Waterford, and data \n",
      "visualization in R with NYC flights data.\n",
      "•DevOps on AWS: EC2 instances, S3 buckets, configuration, and achieved \n",
      "automation with Python scripts.\n",
      "Professional Experience\n",
      "University Informatics Department, Lyon 2\n",
      "present\n",
      "Student Job at the IT department of the university, help desk, loan of computer and \n",
      "professional audiovisual equiment, teamwork.\n",
      "Internship Data Analyst, SYSBLOCK\n",
      "Paris, France\n",
      "•Dashboarding & Analytics: KPI derivation from Google Analytics data and \n",
      "interactive dashboards with Power BI.\n",
      "•Web Development & Blockchain: Experience with Next.js for web development and \n",
      "introduction to blockchain technologies.\n",
      "Projects\n",
      "Creation of a Logistic Regression R package\n",
      "•Logistic regression package from scratch :Implemented various optimizers \n",
      "(Adam, mini-batch, SGD) and applied regularization techniques (L1, L2, ElasticNet). \n",
      "•Successfully tested on classification tasks : achieved up to 90% accuracy on \n",
      "StudentPerformance, Creditcard,  datasets and achieved similar performance to \n",
      "scikit-learn..\n",
      "Projet NLP Analysis of TripAdvisor review\n",
      "•Web Scraping & Sentiment Analysis: Collected TripAdvisor data with \n",
      "BeautifulSoup and performed sentiment analysis on user reviews. Aggregated \n",
      "comments using clustering techniques.\n",
      "•End-to-End Application: Integrated a SQLite database and connected it to a \n",
      "Streamlit app for enhanced visualization. Deployed as a Docker image.\n",
      "•LLM & RAG for Summarization: Leveraged a Large Language Model (LLM) with \n",
      "Retrieval-Augmented Generation (RAG) to summarize user reviews effectively.\n",
      "Project AWS Cloud\n",
      "•AWS Deployment & Scaling: Successfully deployed a template website on EC2 \n",
      "instances with a connected relational database on AWS.\n",
      "•High Availability & Monitoring: Implemented an Auto Scaling Group with a Load \n",
      "Balancer and set up monitoring using custom CloudWatch metrics.\n",
      "Languages/References\n",
      "Languages: French - Native/Bilingual   English C1 - Fluent  Mandarin -\n",
      "Conversational\n",
      "References: Bernard Butler, Pr, SETU  bernard.butler@setu.ie   Liam Doyle, Pr,\n",
      "SETU  liam.doyle@setu.ie\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "<class 'str'>\n",
      "4231\n"
     ]
    }
   ],
   "source": [
    "reader = PdfReader(\"CV_V4_EN.pdf\")\n",
    "page = reader.pages[0] # 1 seule page\n",
    "text_brut = page.extract_text()\n",
    "print(text_brut)\n",
    "print(type(text_brut))\n",
    "print(len(text_brut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(read_pdf(\"CV_V4_EN.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Mistral Mini -> Reformulation Texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Formulation du prompt (CV texte brut + )\n",
    "# Ajouter les suivis de prix + impact ecologique ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import litellm\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA partir d\\'un texte brut venant d\\'un CV, extrait les informations suivantes au format JSON :\\n{\\n    \"Diplome\": [\\n      {\\n          \"niveau_etudes\": \"int\",\\n          \"domaine_etudes\": [\"str\"]\\n      }\\n    ],\\n\\n    \"Competences\": [\"str\"],\\n    \"Experiences\": [\\n        {\\n            \"domaine_activite\": [\"str\"],\\n            \"poste_occupe\": \"str\",\\n            \"duree\": \"int\"\\n        }\\n    ],\\n    \"Profil\": {\\n        \"titre\": \"str\",\\n        \"disponibilite\": \"str\"\\n    }\\n}\\n\\nTexte du CV :\\n\"Quentin Lim  \\nLast year Student in \\nData Science\\nquentinlim 384@ gm ail.com\\n+33782885515\\nlinkedin.com /in/quentin-lim-\\n978746250\\ngithub.com /QL2111\\nProfile\\nCurrently seeking an internship in \\nData Science starting in March \\n2025 for a duration of 4 to 6 \\nmonths.\\nSkills\\nM L, NLP, TensorFlow; Scikit-learn, \\nM LFlow, Transform ers, LLM , Tim e \\nSeries.\\nSQL, NoSQL, M ongoDB\\nQlik, Tableau, PowerBI\\nOpenCV, YOLO\\nAzure, AW S, Fabric\\nGit/Agile m ethodology\\nPython/R/Java/PySpark/JavaScript/\\nPHP\\nGen AI\\nInterests\\nBoard Games:\\xa0Casual boarding\\ngam es and Chess club\\nGaming:\\xa0Played in competitives\\ntournam ents, peaked GrandMaster\\nin League of Legends\\nSailing:\\xa0M em ber of the sailing club\\nat La Rochelle Université\\nBasket ball:\\xa0Sports association\\nduring M iddle School, teamwork\\nand fast decision making.\\nVolunteering\\nESN Cosmolyon\\n2023 – present\\nVice-President, holdings Culturals \\nEvent for internationals and local \\nstudent(Board gam es/Day \\ntrips/Spanish dinner)\\nAlter-ego Lyon 2\\n2023 – present\\nBuddy System  with Lyon 2 \\nUniversityEducation\\nMaster in Data Science, Université Lyon 2 Lumière\\n09/2023 – present\\n•Expertise in advanced data analysis: ANOVA, time series, biostatistics, NLP/LLM, \\nComputer Vision, and Deep Learning.\\n•Proficiency in Big Data and MLOps: web scraping, data warehouses, model \\ndeployment, and pipelines.\\n•Specialized in predictive analytics, focusing on the use of advanced statistical \\nmodels and machine learning algorithms for forecasting and decision making.\\nInternational Exchange Program, National Central University\\nTaoyuan, Taïwan\\n•GPA: 3.8 | Experience in data mining for biological data: autism classification, \\nsentiment analysis and Graph Neural Networks presentation on Reddit data.\\n•Research & Publications: Conducted a literature review on feature selection \\ntechniques and co-authored \"A Review of Feature Selection Techniques in Education\". \\nExplored Transformer models for advanced data analysis.\\nErasmus + Mobility, South East Technological University\\nWaterford, Ireland\\n•First Class Honours | EDA & predictive modeling on Titanic and Tips datasets with \\nup to 90% accuracy, NoSQL database creation for TFI bikes in Waterford, and data \\nvisualization in R with NYC flights data.\\n•DevOps on AWS: EC2 instances, S3 buckets, configuration, and achieved \\nautomation with Python scripts.\\nProfessional Experience\\nUniversity Informatics Department, Lyon 2\\npresent\\nStudent Job at the IT department of the university, help desk, loan of computer and \\nprofessional audiovisual equiment, teamwork.\\nInternship Data Analyst, SYSBLOCK\\nParis, France\\n•Dashboarding & Analytics: KPI derivation from Google Analytics data and \\ninteractive dashboards with Power BI.\\n•Web Development & Blockchain: Experience with Next.js for web development and \\nintroduction to blockchain technologies.\\nProjects\\nCreation of a Logistic Regression R package\\n•Logistic regression package from scratch :Implemented various optimizers \\n(Adam, mini-batch, SGD) and applied regularization techniques (L1, L2, ElasticNet). \\n•Successfully tested on classification tasks : achieved up to 90% accuracy on \\nStudentPerformance, Creditcard,  datasets and achieved similar performance to \\nscikit-learn..\\nProjet NLP Analysis of TripAdvisor review\\n•Web Scraping & Sentiment Analysis: Collected TripAdvisor data with \\nBeautifulSoup and performed sentiment analysis on user reviews. Aggregated \\ncomments using clustering techniques.\\n•End-to-End Application: Integrated a SQLite database and connected it to a \\nStreamlit app for enhanced visualization. Deployed as a Docker image.\\n•LLM & RAG for Summarization: Leveraged a Large Language Model (LLM) with \\nRetrieval-Augmented Generation (RAG) to summarize user reviews effectively.\\nProject AWS Cloud\\n•AWS Deployment & Scaling: Successfully deployed a template website on EC2 \\ninstances with a connected relational database on AWS.\\n•High Availability & Monitoring: Implemented an Auto Scaling Group with a Load \\nBalancer and set up monitoring using custom CloudWatch metrics.\\nLanguages/References\\nLanguages:\\xa0French - Native/Bilingual \\xa0\\xa0English C1 - Fluent\\xa0\\xa0Mandarin -\\nConversational\\nReferences:\\xa0Bernard Butler, Pr, SETU\\xa0\\xa0bernard.butler@setu.ie \\xa0\\xa0Liam Doyle, Pr,\\nSETU\\xa0\\xa0liam.doyle@setu.ie\\n|\\n|\\n|\\n|\\n|\"\\n\\nNe retourne que le JSON\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reformulation_prompt = f\"\"\"\n",
    "A partir d'un texte brut venant d'un CV, extrait les informations suivantes au format JSON :\n",
    "{{\n",
    "    \"Diplome\": [\n",
    "      {{\n",
    "          \"niveau_etudes\": \"int\",\n",
    "          \"domaine_etudes\": [\"str\"]\n",
    "      }}\n",
    "    ],\n",
    "\n",
    "    \"Competences\": [\"str\"],\n",
    "    \"Experiences\": [\n",
    "        {{\n",
    "            \"domaine_activite\": [\"str\"],\n",
    "            \"poste_occupe\": \"str\",\n",
    "            \"duree\": \"int\"\n",
    "        }}\n",
    "    ],\n",
    "    \"Profil\": {{\n",
    "        \"titre\": \"str\",\n",
    "        \"disponibilite\": \"str\"\n",
    "    }}\n",
    "}}\n",
    "\n",
    "Texte du CV :\n",
    "\"{text_brut}\"\n",
    "\n",
    "Ne retourne que le JSON\n",
    "\"\"\"\n",
    "reformulation_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification de la clé API\n",
    "#  api_key=os.getenv(\"MISTRAL_API_KEY\")\n",
    "# api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# litellm._turn_on_debug()\n",
    "# Température, plus c'est proche de 1, plus c'est créatif\n",
    "# On cherche à savoir combien de token on devrait mettre\n",
    "\n",
    "CV_reformuler = litellm.completion(\n",
    "            model=\"mistral/ministral-3b-latest\",  # Choix d'un modèle petit\n",
    "            messages=[{\"role\": \"user\", \"content\": reformulation_prompt}],\n",
    "            max_tokens=1500,\n",
    "            temperature=0.3,\n",
    "            api_key=os.getenv(\"MISTRAL_API_KEY\"),\n",
    "        )\n",
    "\n",
    "resultat = CV_reformuler[\"choices\"][0][\"message\"][\n",
    "            \"content\"\n",
    "        ].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Diplome\": [\n",
      "        {\n",
      "            \"niveau_etudes\": \"Master\",\n",
      "            \"domaine_etudes\": [\"Data Science\"]\n",
      "        }\n",
      "    ],\n",
      "    \"Competences\": [\n",
      "        \"M L, NLP, TensorFlow; Scikit-learn, M LFlow, Transform ers, LLM , Tim e Series.\",\n",
      "        \"SQL, NoSQL, M ongoDB\",\n",
      "        \"Qlik, Tableau, PowerBI\",\n",
      "        \"OpenCV, YOLO\",\n",
      "        \"Azure, AW S, Fabric\",\n",
      "        \"Git/Agile m ethodology\",\n",
      "        \"Python/R/Java/PySpark/JavaScript/\",\n",
      "        \"PHP\",\n",
      "        \"Gen AI\"\n",
      "    ],\n",
      "    \"Experiences\": [\n",
      "        {\n",
      "            \"domaine_activite\": [\"Data Science\"],\n",
      "            \"poste_occupe\": \"Student Job at the IT department of the university\",\n",
      "            \"duree\": 1\n",
      "        },\n",
      "        {\n",
      "            \"domaine_activite\": [\"Data Science\"],\n",
      "            \"poste_occupe\": \"Internship Data Analyst\",\n",
      "            \"duree\": 1\n",
      "        }\n",
      "    ],\n",
      "    \"Profil\": {\n",
      "        \"titre\": \"Currently seeking an internship in Data Science starting in March 2025 for a duration of 4 to 6 months.\",\n",
      "        \"disponibilite\": \"March 2025\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "1032\n"
     ]
    }
   ],
   "source": [
    "# Le CV fait 4231 en len\n",
    "# len de 1863 pour 500 max tokens\n",
    "# len de 4429 pour 1500 max tokens -> C'est OK, on essaye avec 1000 max tokens\n",
    "print(resultat)\n",
    "print(len(resultat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_cv(text_brut: str, temperature: float = 0.01, max_tokens: int = 1500) -> str:\n",
    "    \"\"\"\n",
    "    Analyse un CV en format texte et retourne les informations structurées en JSON.\n",
    "\n",
    "    Args:\n",
    "        text_brut (str): Texte brut du CV à analyser\n",
    "        temperature (float, optional): Paramètre de créativité du modèle. Defaults to 0.2.\n",
    "        max_tokens (int, optional): Nombre maximum de tokens pour la réponse. Defaults to 1500.\n",
    "\n",
    "    Returns:\n",
    "        str: Informations en string(réponse du LLM) structurées du CV au format JSON\n",
    "\n",
    "    Raises:\n",
    "        Exception: En cas d'erreur d'API ou de parsing JSON\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reformulation_prompt = f\"\"\"\n",
    "        À partir du texte brut d'un CV, extrais les informations suivantes au format JSON. \n",
    "        Si une information n'est pas explicitement mentionnée dans le texte, retourne `null` ou une liste vide.\n",
    "        Ne devine pas les informations manquantes et ne retourne que ce qui est clairement présent dans le texte.\n",
    "\n",
    "        Format JSON attendu :\n",
    "        {{\n",
    "            \"Formation\": [\n",
    "                {{\n",
    "                    \"niveau_etudes\": \"str\",  // Ex: \"Licence\", \"Master\", \"Doctorat\"\n",
    "                    \"domaine_etudes\": [\"str\"]  // Ex: [\"Informatique\", \"Mathématiques\"]\n",
    "                }}\n",
    "            ],\n",
    "            \"Competences\": [\"str\"],  // Ex: [\"Python\", \"Gestion de projet\"]\n",
    "            \"Experiences\": [\n",
    "                {{\n",
    "                    \"domaine_activite\": [\"str\"],  // Ex: [\"Tech\", \"Finance\"]\n",
    "                    \"poste_occupe\": \"str\",  // Ex: \"Développeur Python\"\n",
    "                    \"duree\": \"str\"  // Ex: \"2 ans\"\n",
    "                }}\n",
    "            ],\n",
    "            \"Profil\": {{\n",
    "                \"titre\": \"str\",  // Ex: \"Développeur Full-Stack\"\n",
    "                \"disponibilite\": \"str\"  // Ex: \"dd-mm-yyyy\"\n",
    "            }}\n",
    "        }}\n",
    "\n",
    "        Texte du CV :\n",
    "        \"{text_brut}\"\n",
    "\n",
    "        Ne retourne que le JSON, sans commentaires supplémentaires.\n",
    "        \"\"\"\n",
    "\n",
    "        CV_reformuler = litellm.completion(\n",
    "            model=\"mistral/mistral-medium\",\n",
    "            messages=[{\"role\": \"user\", \"content\": reformulation_prompt}],\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            api_key=os.getenv(\"MISTRAL_API_KEY\"),\n",
    "        )\n",
    "\n",
    "        # Extraire et parser le JSON de la réponse\n",
    "        resultat = CV_reformuler[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        return resultat\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Erreur lors de l'analyse du CV: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Formation\": [\n",
      "    {\n",
      "      \"niveau_etudes\": \"Master\",\n",
      "      \"domaine_etudes\": [\"Data Science\"]\n",
      "    }\n",
      "  ],\n",
      "  \"Competences\": [\n",
      "    \"ML\",\n",
      "    \"NLP\",\n",
      "    \"TensorFlow\",\n",
      "    \"Scikit-learn\",\n",
      "    \"MLFlow\",\n",
      "    \"Transformers\",\n",
      "    \"LLM\",\n",
      "    \"Time Series\",\n",
      "    \"SQL\",\n",
      "    \"NoSQL\",\n",
      "    \"MongoDB\",\n",
      "    \"Qlik\",\n",
      "    \"Tableau\",\n",
      "    \"PowerBI\",\n",
      "    \"OpenCV\",\n",
      "    \"YOLO\",\n",
      "    \"Azure\",\n",
      "    \"AWS\",\n",
      "    \"Fabric\",\n",
      "    \"Git/Agile methodology\",\n",
      "    \"Python\",\n",
      "    \"R\",\n",
      "    \"Java\",\n",
      "    \"PySpark\",\n",
      "    \"JavaScript\",\n",
      "    \"PHP\",\n",
      "    \"Gen AI\"\n",
      "  ],\n",
      "  \"Experiences\": [\n",
      "    {\n",
      "      \"domaine_activite\": [],\n",
      "      \"poste_occupe\": \"Vice-President, holdings Culturals Events for internationals and local students\",\n",
      "      \"duree\": \"2023 – present\"\n",
      "    },\n",
      "    {\n",
      "      \"domaine_activite\": [],\n",
      "      \"poste_occupe\": \"Buddy System with Lyon 2 University\",\n",
      "      \"duree\": \"2023 – present\"\n",
      "    },\n",
      "    {\n",
      "      \"domaine_activite\": [\"Data Science\"],\n",
      "      \"poste_occupe\": \"Student Job at the IT department of the university, help desk, loan of computer and professional audiovisual equipment, teamwork\",\n",
      "      \"duree\": \"present\"\n",
      "    },\n",
      "    {\n",
      "      \"domaine_activite\": [\"Data Science\"],\n",
      "      \"poste_occupe\": \"Dashboarding & Analytics: KPI derivation from Google Analytics data and interactive dashboards with Power BI.\",\n",
      "      \"duree\": \"Internship Data Analyst, SYSBLOCK\"\n",
      "    },\n",
      "    {\n",
      "      \"domaine_activite\": [\"Web Development\", \"Blockchain\"],\n",
      "      \"poste_occupe\": \"Web Development & Blockchain: Experience with Next.js for web development and introduction to blockchain technologies.\",\n",
      "      \"duree\": \"Internship Data Analyst, SYSBLOCK\"\n",
      "    }\n",
      "  ],\n",
      "  \"Profil\": {\n",
      "    \"titre\": \"Currently seeking an internship in Data Science starting in March 2025 for a duration of 4 to 6 months.\",\n",
      "    \"disponibilite\": \"March 2025\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "CV_reformuler = analyze_cv(text_brut)\n",
    "print(CV_reformuler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matching CV et offre :\n",
    "\n",
    "- Obtention du string job offer par le scrapping\n",
    "- Transformation via un LLM de l'offre à un format similaire au CV_reformuler\n",
    "- Embedding + calcul de la similarité cosinus globale\n",
    "- Transformation en JSON du CV_reformuler et job_offer_reforumuler pour pouvoir effectuer une similarité par partie(clef communes car passé tout les deux par un LLM)\n",
    "- Calcul des similarité par parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Example job offer\n",
    "job_offer = \"\"\"\n",
    "  Titre : Data scientist (H/F) SALON TAF Toulouse 2025\n",
    "  Entreprise : AOSIS CONSULTING\n",
    "  Contrat : CDI\n",
    "  Localisation : 31 - TOULOUSE\n",
    "  Description :\n",
    "  Concrètement qu'est-ce qu'on fait ?\n",
    "  Nous proposons des Services, des Logiciels et de la Formation dans le domaine de la Business Intelligence, de la Data Science, de la Gouvernance et de la Visualisation de la donnée. L'Infrastructure et le Développement font également partie du panel de nos compétences.\n",
    "  Notre leitmotiv ? Citoyenneté, écologie et sport avec des experts de la donnée.\n",
    "  Notre objectif ? Porter encore plus haut et plus fort nos valeurs de sport, d'écologie et de citoyenneté et accompagner nos consultants dans leur montée en compétence.\n",
    "\n",
    "  Le poste\n",
    "  Dans le cadre d'une ouverture de poste, nous sommes à la recherche d'un.e Data Scientist pour l'un de nos clients.\n",
    "  Un.e data scientist senior (5 ans d'expérience) très autonome dans ses analyses et explorations, expérimenté dans l'industrialisation des modèles dans des environnements cloud.\n",
    "\n",
    "  Vous interviendrez sur toutes les étapes du projet, vous devrez :\n",
    "\n",
    "  Identifier leurs difficultés et proposer des solutions\n",
    "  Evaluer la qualité des données, les nettoyer, les agréger, et mener des études adhoc\n",
    "  Concevoir, implémenter et comparer différents algorithmes et méthodes statistiques\n",
    "  Concevoir et mener des protocoles de test en conditions réelles (magasins, entrepôts, .)\n",
    "  Développer des outils de visualisation des données\n",
    "  Mettre en production, maintenir et itérer sur les solutions\n",
    "\n",
    "  Environnement technique: Python, SQL, Terraform, Bitbucket, Jenkins, Airflow, Docker, Kubernetes, GCP (BigQuery, Spark DataProc)\n",
    "\n",
    "  Profil recherché\n",
    "  Vous êtes issu.e d'un Master en informatique ou mathématiques appliquées.\n",
    "  Vous avez à minima 5 années d'expériences en Data Science et maitrisez les algorithmes d'apprentissage statistique.\n",
    "  Vous maîtrisez Python et SQL\n",
    "  Vous avez une expérience dans le développement logiciel agile avec multiples contributeurs\n",
    "  Vous avez une expérience du cloud, idéalement GCP\n",
    "\n",
    "  Pourquoi nous rejoindre ?\n",
    "  Parce que nous sommes une société à taille humaine\n",
    "  Parce que nous nous engageons (réellement) dans des enjeux importants : l'écologie, la citoyenneté et le sport\n",
    "  Mais aussi parce que nous aimons réaliser tout un tas d'activités : des jeux, des afterworks, des restaurants, ... et plein d'autres choses encore :)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reformulation de l'offre d'emploi :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Transformation de l'offre d'emploi au même format que le CV\n",
    "def analyze_offre_emploi(offre: str, temperature: float = 0.01, max_tokens: int = 1500) -> str:\n",
    "    \"\"\"\n",
    "    Analyse une offre d'emploi en format texte et retourne les informations structurées en JSON.\n",
    "\n",
    "    Args:\n",
    "        text_brut (str): Texte brut del'offre à analyser\n",
    "        temperature (float, optional): Paramètre de créativité du modèle. Defaults to 0.2.\n",
    "        max_tokens (int, optional): Nombre maximum de tokens pour la réponse. Defaults to 1500.\n",
    "\n",
    "    Returns:\n",
    "        str: Informations en string(réponse du LLM) structurées du CV au format JSON\n",
    "\n",
    "    Raises:\n",
    "        Exception: En cas d'erreur d'API ou de parsing JSON\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reformulation_prompt = f\"\"\"\n",
    "        À partir de cette offre d'emploi, extrais les informations suivantes au format JSON. \n",
    "        Si une information n'est pas explicitement mentionnée dans le texte, retourne `null` ou une liste vide.\n",
    "        De plus la disponibilité correspond à la date de début du poste.\n",
    "        Ne devine pas les informations manquantes et ne retourne que ce qui est clairement présent dans le texte.\n",
    "        \n",
    "        Format JSON attendu :\n",
    "        {{\n",
    "            \"Formation\": [\n",
    "                {{\n",
    "                    \"niveau_etudes\": \"str\",  // Ex: \"Licence\", \"Master\", \"Doctorat\"\n",
    "                    \"domaine_etudes\": [\"str\"]  // Ex: [\"Informatique\", \"Mathématiques\"]\n",
    "                }}\n",
    "            ],\n",
    "            \"Competences\": [\"str\"],  // Ex: [\"Python\", \"Gestion de projet\"]\n",
    "            \"Experiences\": [\n",
    "                {{\n",
    "                    \"domaine_activite\": [\"str\"],  // Ex: [\"Tech\", \"Finance\"]\n",
    "                    \"poste_occupe\": \"str\",  // Ex: \"Développeur Python\"\n",
    "                    \"duree\": \"str\"  // Ex: \"2 ans\"\n",
    "                }}\n",
    "            ],\n",
    "            \"Profil\": {{\n",
    "                \"titre\": \"str\",  // Ex: \"Développeur Full-Stack\"\n",
    "                \"disponibilite\": \"str\"  // Ex: \"dd-mm-yyyy\"\n",
    "            }}\n",
    "        }}\n",
    "\n",
    "        Texte de l'offre d'emploi :\n",
    "        \"{offre}\"\n",
    "\n",
    "        Ne retourne que le JSON, sans commentaires supplémentaires.\n",
    "        \"\"\"\n",
    "\n",
    "        offre_reformuler = litellm.completion(\n",
    "            model=\"mistral/mistral-medium\",\n",
    "            messages=[{\"role\": \"user\", \"content\": reformulation_prompt}],\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            api_key=os.getenv(\"MISTRAL_API_KEY\"),\n",
    "        )\n",
    "\n",
    "        # Extraire et parser le JSON de la réponse\n",
    "        resultat = offre_reformuler[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        return resultat\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Erreur lors de l'analyse du CV: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Formation\": [\n",
      "    {\n",
      "      \"niveau_etudes\": \"Master\",\n",
      "      \"domaine_etudes\": [\"Informatique\", \"Mathématiques appliquées\"]\n",
      "    }\n",
      "  ],\n",
      "  \"Competences\": [\n",
      "    \"Python\",\n",
      "    \"SQL\",\n",
      "    \"Terraform\",\n",
      "    \"Bitbucket\",\n",
      "    \"Jenkins\",\n",
      "    \"Airflow\",\n",
      "    \"Docker\",\n",
      "    \"Kubernetes\",\n",
      "    \"GCP (BigQuery, Spark DataProc)\",\n",
      "    \"Développement logiciel agile\",\n",
      "    \"Algorithmes d'apprentissage statistique\"\n",
      "  ],\n",
      "  \"Experiences\": [\n",
      "    {\n",
      "      \"domaine_activite\": [\"Data Science\"],\n",
      "      \"poste_occupe\": \"Data Scientist\",\n",
      "      \"duree\": \"5 ans\"\n",
      "    }\n",
      "  ],\n",
      "  \"Profil\": {\n",
      "    \"titre\": \"Data Scientist\",\n",
      "    \"disponibilite\": null\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "job_offer_reforumer = analyze_offre_emploi(job_offer)\n",
    "print(job_offer_reforumer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarité cosinus globale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Token d'API Hugging Face\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "API_URL = \"https://api-inference.huggingface.co/pipeline/feature-extraction/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "\n",
    "def get_embedding(text: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Envoie une requête à l'API Hugging Face pour obtenir l'embedding d'un texte.\n",
    "\n",
    "    Args:\n",
    "        text (str): Texte à encoder.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Embedding du texte.\n",
    "    \"\"\"\n",
    "    headers = {\"Authorization\": f\"Bearer {os.getenv(\"HF_TOKEN\")}\"}\n",
    "    response = requests.post(\n",
    "        \"https://api-inference.huggingface.co/pipeline/feature-extraction/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "        headers=headers,\n",
    "        json={\"inputs\": text, \"options\": {\"wait_for_model\": True}},\n",
    "    )\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Erreur API : {response.status_code}, {response.text}\")\n",
    "    return np.array(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarité globale entre le CV et l'offre d'emploi: 0.9063\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_similarity(text1: str, text2: str) -> float:\n",
    "    \"\"\"\n",
    "    Calcule la similarité cosinus entre deux textes en utilisant l'API Hugging Face.\n",
    "    \n",
    "    Args:\n",
    "        text1 (str): Premier texte.\n",
    "        text2 (str): Deuxième texte.\n",
    "    \n",
    "    Returns:\n",
    "        float: Score de similarité cosinus entre les deux textes.\n",
    "    \"\"\"\n",
    "    # Obtenir les embeddings des textes\n",
    "    embedding1 = get_embedding(text1)\n",
    "    embedding2 = get_embedding(text2)\n",
    "    \n",
    "    # Calculer la similarité cosinus\n",
    "    similarity = cosine_similarity([embedding1], [embedding2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "# Calculer la similarité entre le CV et l'offre d'emploi\n",
    "similarity_score = calculate_similarity(CV_reformuler, job_offer_reforumer)\n",
    "print(f\"Similarité globale entre le CV et l'offre d'emploi: {similarity_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversion en JSON-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calcul de la similarité entre chaque partie du CV et l'offre d'emploi\n",
    "# Diviser le CV reformulé en json en plusieurs parties\n",
    "cv_json = json.loads(CV_reformuler)\n",
    "# print(cv_json)\n",
    "# convert job_offer to json\n",
    "job_offer_json = json.loads(job_offer_reforumer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Formation': [{'niveau_etudes': 'Master', 'domaine_etudes': ['Informatique', 'Mathématiques appliquées']}], 'Competences': ['Python', 'SQL', 'Terraform', 'Bitbucket', 'Jenkins', 'Airflow', 'Docker', 'Kubernetes', 'GCP (BigQuery, Spark DataProc)', 'Développement logiciel agile', \"Algorithmes d'apprentissage statistique\"], 'Experiences': [{'domaine_activite': ['Data Science'], 'poste_occupe': 'Data Scientist', 'duree': '5 ans'}], 'Profil': {'titre': 'Data Scientist', 'disponibilite': None}}\n"
     ]
    }
   ],
   "source": [
    "print(job_offer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(cv_json)) # Les données sont en string JSON like\n",
    "print(type(job_offer_json)) # Les données sont en string JSON like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul des similarités cosinus par parties :\n",
    "\n",
    "- Formation\n",
    "- Competences\n",
    "- Experiences\n",
    "- Profil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarité entre les deux json like\n",
    "\n",
    "# Similarité Formation\n",
    "# print(cv_json.get(\"Formation\"))\n",
    "# print(job_offer_json.get(\"Formation\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarité entre Formation attendu et Formation du CV: 0.7965\n",
      "Similarité entre Compétences attendu et Compétences du CV: 0.8096\n",
      "Similarité entre Experiences attendu et Experiences du CV: 0.5714\n",
      "{'titre': 'Currently seeking an internship in Data Science starting in March 2025 for a duration of 4 to 6 months.', 'disponibilite': 'March 2025'}\n",
      "{'titre': 'Data Scientist', 'disponibilite': None}\n",
      "Similarité entre Profil attendu et Profil du CV: 0.5046\n"
     ]
    }
   ],
   "source": [
    "# Similarité entre Formation attendu et Formation du CV\n",
    "formation_candidat = cv_json.get(\"Formation\")\n",
    "formation_attendu = job_offer_json.get(\"Formation\")\n",
    "\n",
    "similarite_formation = calculate_similarity(str(formation_candidat), str(formation_attendu))\n",
    "print(f\"Similarité entre Formation attendu et Formation du CV: {similarite_formation:.4f}\")\n",
    "\n",
    "\n",
    "# Similarité entre Compétences attendu et Compétences du CV\n",
    "competences_candidat = cv_json.get(\"Competences\")\n",
    "# print(competences_candidat)\n",
    "competences_attendu = job_offer_json.get(\"Competences\")\n",
    "# print(competences_attendu)\n",
    "\n",
    "similarite_competences = calculate_similarity(str(competences_candidat), str(competences_attendu))\n",
    "print(f\"Similarité entre Compétences attendu et Compétences du CV: {similarite_competences:.4f}\")\n",
    "\n",
    "\n",
    "# Similarité entre Experiences attendu et Experiences du CV\n",
    "experiences_candidat = cv_json.get(\"Experiences\")\n",
    "# print(experiences_candidat)\n",
    "experiences_attendu = job_offer_json.get(\"Experiences\")\n",
    "# print(experiences_attendu)\n",
    "\n",
    "similarite_experiences = calculate_similarity(str(experiences_candidat), str(experiences_attendu))\n",
    "print(f\"Similarité entre Experiences attendu et Experiences du CV: {similarite_experiences:.4f}\")\n",
    "\n",
    "\n",
    "# Similarité entre Profil attendu et Profil du CV\n",
    "profil_candidat = cv_json.get(\"Profil\")\n",
    "print(profil_candidat)\n",
    "profil_attendu = job_offer_json.get(\"Profil\")\n",
    "print(profil_attendu)\n",
    "\n",
    "similarite_profil = calculate_similarity(str(profil_candidat), str(profil_attendu))\n",
    "print(f\"Similarité entre Profil attendu et Profil du CV: {similarite_profil:.4f}\")\n",
    "\n",
    "###################### Voir si on ne peut pas faire mieux (check if any au lieu d'une simalarité globale) ######################\n",
    "### Au lieu d'installer sentence transformers, utiliser une API huggingface avec pipeline et requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_section_similarity(cv_reformule: str, offre_emploi_reformule: str) -> dict:\n",
    "    \"\"\"\n",
    "    Calcule les similarités détaillées entre les différentes sections d'un CV et une offre d'emploi.\n",
    "    \n",
    "    Args:\n",
    "        cv_reformule (str): Informations du CV au format JSON string\n",
    "        offre_emploi_reformule (str): Informations de l'offre d'emploi au format JSON string\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionnaire contenant les scores de similarité pour chaque section\n",
    "        \n",
    "    Exemple:\n",
    "        {\n",
    "            'formation': float,\n",
    "            'competences': float,\n",
    "            'experiences': float,\n",
    "            'profil': float,\n",
    "        }\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Conversion des chaînes JSON en dictionnaires\n",
    "        cv_json = json.loads(cv_reformule)\n",
    "        offre_emploi_json = json.loads(offre_emploi_reformule)\n",
    "        \n",
    "        # Calcul des similarités pour chaque section\n",
    "        similarites = {}\n",
    "        \n",
    "        # Similarité de formation\n",
    "        formation_candidat = cv_json.get(\"Formation\", \"\")\n",
    "        formation_attendue = offre_emploi_json.get(\"Formation\", \"\")\n",
    "        similarites['formation'] = calculate_similarity(\n",
    "            str(formation_candidat), \n",
    "            str(formation_attendue)\n",
    "        )\n",
    "        \n",
    "        # Similarité des compétences\n",
    "        competences_candidat = cv_json.get(\"Competences\", [])\n",
    "        competences_attendues = offre_emploi_json.get(\"Competences\", [])\n",
    "        similarites['competences'] = calculate_similarity(\n",
    "            str(competences_candidat), \n",
    "            str(competences_attendues)\n",
    "        )\n",
    "        \n",
    "        # Similarité des expériences\n",
    "        experiences_candidat = cv_json.get(\"Experiences\", [])\n",
    "        experiences_attendues = offre_emploi_json.get(\"Experiences\", [])\n",
    "        similarites['experiences'] = calculate_similarity(\n",
    "            str(experiences_candidat), \n",
    "            str(experiences_attendues)\n",
    "        )\n",
    "        \n",
    "        # Similarité du profil\n",
    "        profil_candidat = cv_json.get(\"Profil\", {})\n",
    "        profil_attendu = offre_emploi_json.get(\"Profil\", {})\n",
    "        similarites['profil'] = calculate_similarity(\n",
    "            str(profil_candidat), \n",
    "            str(profil_attendu)\n",
    "        )\n",
    "        \n",
    "        return similarites\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(f\"Erreur lors du parsing JSON : {str(e)}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Erreur lors du calcul des similarités : {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7964798257238572\n"
     ]
    }
   ],
   "source": [
    "calculate_section_similarity(CV_reformuler, job_offer_reforumer)\n",
    "\n",
    "print(calculate_section_similarity(CV_reformuler, job_offer_reforumer)['formation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création d'une lettre de motivation à partir du CV et de l'offre\n",
    "\n",
    "- Utilisation du CV brut car on a perdu des informations qu'on peut mettre en avant ici (bénévélot etc..)\n",
    "- Même chose pour l'offre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quentin Lim  \n",
      "Last year Student in \n",
      "Data Science\n",
      "quentinlim 384@ gm ail.com\n",
      "+33782885515\n",
      "linkedin.com /in/quentin-lim-\n",
      "978746250\n",
      "github.com /QL2111\n",
      "Profile\n",
      "Currently seeking an internship in \n",
      "Data Science starting in March \n",
      "2025 for a duration of 4 to 6 \n",
      "months.\n",
      "Skills\n",
      "M L, NLP, TensorFlow; Scikit-learn, \n",
      "M LFlow, Transform ers, LLM , Tim e \n",
      "Series.\n",
      "SQL, NoSQL, M ongoDB\n",
      "Qlik, Tableau, PowerBI\n",
      "OpenCV, YOLO\n",
      "Azure, AW S, Fabric\n",
      "Git/Agile m ethodology\n",
      "Python/R/Java/PySpark/JavaScript/\n",
      "PHP\n",
      "Gen AI\n",
      "Interests\n",
      "Board Games: Casual boarding\n",
      "gam es and Chess club\n",
      "Gaming: Played in competitives\n",
      "tournam ents, peaked GrandMaster\n",
      "in League of Legends\n",
      "Sailing: M em ber of the sailing club\n",
      "at La Rochelle Université\n",
      "Basket ball: Sports association\n",
      "during M iddle School, teamwork\n",
      "and fast decision making.\n",
      "Volunteering\n",
      "ESN Cosmolyon\n",
      "2023 – present\n",
      "Vice-President, holdings Culturals \n",
      "Event for internationals and local \n",
      "student(Board gam es/Day \n",
      "trips/Spanish dinner)\n",
      "Alter-ego Lyon 2\n",
      "2023 – present\n",
      "Buddy System  with Lyon 2 \n",
      "UniversityEducation\n",
      "Master in Data Science, Université Lyon 2 Lumière\n",
      "09/2023 – present\n",
      "•Expertise in advanced data analysis: ANOVA, time series, biostatistics, NLP/LLM, \n",
      "Computer Vision, and Deep Learning.\n",
      "•Proficiency in Big Data and MLOps: web scraping, data warehouses, model \n",
      "deployment, and pipelines.\n",
      "•Specialized in predictive analytics, focusing on the use of advanced statistical \n",
      "models and machine learning algorithms for forecasting and decision making.\n",
      "International Exchange Program, National Central University\n",
      "Taoyuan, Taïwan\n",
      "•GPA: 3.8 | Experience in data mining for biological data: autism classification, \n",
      "sentiment analysis and Graph Neural Networks presentation on Reddit data.\n",
      "•Research & Publications: Conducted a literature review on feature selection \n",
      "techniques and co-authored \"A Review of Feature Selection Techniques in Education\". \n",
      "Explored Transformer models for advanced data analysis.\n",
      "Erasmus + Mobility, South East Technological University\n",
      "Waterford, Ireland\n",
      "•First Class Honours | EDA & predictive modeling on Titanic and Tips datasets with \n",
      "up to 90% accuracy, NoSQL database creation for TFI bikes in Waterford, and data \n",
      "visualization in R with NYC flights data.\n",
      "•DevOps on AWS: EC2 instances, S3 buckets, configuration, and achieved \n",
      "automation with Python scripts.\n",
      "Professional Experience\n",
      "University Informatics Department, Lyon 2\n",
      "present\n",
      "Student Job at the IT department of the university, help desk, loan of computer and \n",
      "professional audiovisual equiment, teamwork.\n",
      "Internship Data Analyst, SYSBLOCK\n",
      "Paris, France\n",
      "•Dashboarding & Analytics: KPI derivation from Google Analytics data and \n",
      "interactive dashboards with Power BI.\n",
      "•Web Development & Blockchain: Experience with Next.js for web development and \n",
      "introduction to blockchain technologies.\n",
      "Projects\n",
      "Creation of a Logistic Regression R package\n",
      "•Logistic regression package from scratch :Implemented various optimizers \n",
      "(Adam, mini-batch, SGD) and applied regularization techniques (L1, L2, ElasticNet). \n",
      "•Successfully tested on classification tasks : achieved up to 90% accuracy on \n",
      "StudentPerformance, Creditcard,  datasets and achieved similar performance to \n",
      "scikit-learn..\n",
      "Projet NLP Analysis of TripAdvisor review\n",
      "•Web Scraping & Sentiment Analysis: Collected TripAdvisor data with \n",
      "BeautifulSoup and performed sentiment analysis on user reviews. Aggregated \n",
      "comments using clustering techniques.\n",
      "•End-to-End Application: Integrated a SQLite database and connected it to a \n",
      "Streamlit app for enhanced visualization. Deployed as a Docker image.\n",
      "•LLM & RAG for Summarization: Leveraged a Large Language Model (LLM) with \n",
      "Retrieval-Augmented Generation (RAG) to summarize user reviews effectively.\n",
      "Project AWS Cloud\n",
      "•AWS Deployment & Scaling: Successfully deployed a template website on EC2 \n",
      "instances with a connected relational database on AWS.\n",
      "•High Availability & Monitoring: Implemented an Auto Scaling Group with a Load \n",
      "Balancer and set up monitoring using custom CloudWatch metrics.\n",
      "Languages/References\n",
      "Languages: French - Native/Bilingual   English C1 - Fluent  Mandarin -\n",
      "Conversational\n",
      "References: Bernard Butler, Pr, SETU  bernard.butler@setu.ie   Liam Doyle, Pr,\n",
      "SETU  liam.doyle@setu.ie\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n"
     ]
    }
   ],
   "source": [
    "# LLM pour la lettre de motivation\n",
    "print(text_brut)\n",
    "# job_offer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extractions info perso avec un LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_extraction_info_perso = f\"\"\"\n",
    "    Extrait les informations personnelles suivantes du texte brut d'un CV et retourne-les au format JSON :\n",
    "    - Nom et prénom\n",
    "    - Email\n",
    "    - Numéro de téléphone\n",
    "    - Adresse\n",
    "\n",
    "    Si une information est manquante, retourne `Non réseigner` pour cette clé.\n",
    "\n",
    "    Texte brut du CV :\n",
    "    \"{text_brut}\"\n",
    "\n",
    "    Format JSON attendu :\n",
    "    {{\n",
    "        \"nom_prenom\": \"str\",\n",
    "        \"email\": \"str\",\n",
    "        \"telephone\": \"str\",\n",
    "        \"adresse\": \"str\"\n",
    "    }}\n",
    "\n",
    "    Ne retourne que le JSON, sans commentaires supplémentaires.\n",
    "    \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resultat_extraction_info_perso = litellm.completion(\n",
    "            model=\"mistral/mistral-tiny\",  \n",
    "            messages=[{\"role\": \"user\", \"content\": prompt_extraction_info_perso}],\n",
    "            max_tokens=50,\n",
    "            temperature=0.1,\n",
    "            api_key=os.getenv(\"MISTRAL_API_KEY\"),\n",
    "        )\n",
    "\n",
    "resultat_extraction_info_perso_content = resultat_extraction_info_perso[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction_info_perso(text_brut: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrait les informations personnelles d'un CV en format texte brut.\n",
    "\n",
    "    Args:\n",
    "        text_brut (str): Texte brut du CV à analyser\n",
    "\n",
    "    Returns:\n",
    "        str: Informations personnelles extraites du CV en format JSON like\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_extraction_info_perso = f\"\"\"\n",
    "    Extrait les informations personnelles suivantes du texte brut d'un CV et retourne-les au format JSON :\n",
    "    - Nom et prénom\n",
    "    - Email\n",
    "    - Numéro de téléphone\n",
    "    - Adresse\n",
    "\n",
    "    Si une information est manquante, retourne `Non réseigner` pour cette clé.\n",
    "\n",
    "    Texte brut du CV :\n",
    "    \"{text_brut}\"\n",
    "\n",
    "    Format JSON attendu :\n",
    "    {{\n",
    "        \"nom_prenom\": \"str\",\n",
    "        \"email\": \"str\",\n",
    "        \"telephone\": \"str\",\n",
    "        \"adresse\": \"str\"\n",
    "    }}\n",
    "\n",
    "    Ne retourne que le JSON, sans commentaires supplémentaires.\n",
    "    \"\"\"\n",
    "    resultat_extraction_info_perso = litellm.completion(\n",
    "                model=\"mistral/mistral-tiny\",  \n",
    "                messages=[{\"role\": \"user\", \"content\": prompt_extraction_info_perso}],\n",
    "                max_tokens=50,\n",
    "                temperature=0.1,\n",
    "                api_key=os.getenv(\"MISTRAL_API_KEY\"),\n",
    "            )\n",
    "    \n",
    "    return resultat_extraction_info_perso[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"nom_prenom\": \"Quentin Lim\",\\n    \"email\": \"quentinlim384@gm ail.com\",\\n    \"telephone\": \"+33782885515\",\\n    \"adresse\": \"Non réseigner\"\\n}'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_info_perso(text_brut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Unterminated string starting at: line 4 column 18 (char 93)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(resultat_extraction_info_perso_content))\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# convertir en json like\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m resultat_extraction_info_perso_json = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresultat_extraction_info_perso_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(resultat_extraction_info_perso_json)\n\u001b[32m      6\u001b[39m nom = resultat_extraction_info_perso_json.get(\u001b[33m\"\u001b[39m\u001b[33mnom_prenom\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\challengeIA\\Lib\\json\\__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\challengeIA\\Lib\\json\\decoder.py:338\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    334\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    335\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    336\u001b[39m \n\u001b[32m    337\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m     end = _w(s, end).end()\n\u001b[32m    340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\challengeIA\\Lib\\json\\decoder.py:354\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    345\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[33;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[32m    347\u001b[39m \u001b[33;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    351\u001b[39m \n\u001b[32m    352\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    356\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Unterminated string starting at: line 4 column 18 (char 93)"
     ]
    }
   ],
   "source": [
    "print(type(resultat_extraction_info_perso_content))\n",
    "# convertir en json like\n",
    "resultat_extraction_info_perso_json = json.loads(resultat_extraction_info_perso_content)\n",
    "print(resultat_extraction_info_perso_json)\n",
    "\n",
    "nom = resultat_extraction_info_perso_json.get(\"nom_prenom\")\n",
    "print(nom)\n",
    "email = resultat_extraction_info_perso_json.get(\"email\", \"\").strip()\n",
    "# Remove all spaces from email\n",
    "email = \"\".join(email.split())\n",
    "print(email)  # Will print: quentinlim384@gmail.com\n",
    "telephone = resultat_extraction_info_perso_json.get(\"telephone\")\n",
    "print(telephone)\n",
    "adresse = resultat_extraction_info_perso_json.get(\"adresse\")\n",
    "print(adresse)\n",
    "\n",
    "\n",
    "# Set French locale\n",
    "try:\n",
    "    locale.setlocale(locale.LC_TIME, 'fr_FR.UTF-8')  # Linux/Mac\n",
    "except:\n",
    "    locale.setlocale(locale.LC_TIME, 'fra_fra')  # Windows\n",
    "\n",
    "# Get date in French format\n",
    "date = datetime.now().strftime(\"%d %B %Y\")\n",
    "print(date)  # Output: 13 mars 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_lettre_motivation = f\"\"\"\n",
    "Tu es un assistant qui rédige des lettres de motivation personnalisées et professionnelles. Voici les informations nécessaires :\n",
    "\n",
    "**Informations du candidat :**\n",
    "- Nom : {nom}\n",
    "- Email : {email}\n",
    "- Téléphone : {telephone}\n",
    "- Adresse : {adresse}\n",
    "- Date : {date}\n",
    "\n",
    "**Texte brut du CV :**\n",
    "{text_brut}\n",
    "\n",
    "**Offre d'emploi :**\n",
    "{job_offer}\n",
    "\n",
    "**Instructions :**\n",
    "1. Rédige une lettre de motivation au format A4, bien structurée et professionnelle.\n",
    "2. Mets en avant les compétences et expériences du candidat qui correspondent aux exigences du poste.\n",
    "3. Mentionne des éléments spécifiques de l'entreprise ou du poste pour montrer que la candidature est personnalisée.\n",
    "4. Explique pourquoi le candidat est motivé pour rejoindre cette entreprise en particulier.\n",
    "5. Utilise un ton professionnel et évite les phrases génériques.\n",
    "6. Ne laisse pas de champs vides et ne devine pas les informations manquantes.\n",
    "\n",
    "**Format de la lettre :**\n",
    "- En-tête : Nom, prénom, adresse, email, téléphone, date.\n",
    "- Introduction : Présentation du candidat et motivation pour le poste.\n",
    "- Corps : Compétences et expériences en lien avec le poste.\n",
    "- Conclusion : Expression de l'enthousiasme et disponibilité pour un entretien.\n",
    "\n",
    "**Exemple de structure :**\n",
    "{nom}\n",
    "{email}\n",
    "{telephone}\n",
    "{adresse}\n",
    "{date}\n",
    "\n",
    "Madame, Monsieur,\n",
    "Je me permets de vous adresser ma candidature pour le poste de [poste] au sein de [entreprise]. [Motivation personnalisée].\n",
    "\n",
    "Avec mon expérience en [domaine] et mes compétences en [compétences], je suis convaincu de pouvoir contribuer à [objectif de l'entreprise]. [Détail des expériences et compétences pertinentes].\n",
    "\n",
    "Je serais ravi de discuter de ma candidature lors d'un entretien. Je reste à votre disposition pour toute information complémentaire.\n",
    "\n",
    "Veuillez agréer, Madame, Monsieur, mes salutations distinguées.\n",
    "{nom}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Lettre_motiv_genere = litellm.completion(\n",
    "            model=\"mistral/ministral-3b-latest\",  \n",
    "            messages=[{\"role\": \"user\", \"content\": prompt_lettre_motivation}],\n",
    "            max_tokens=1500,\n",
    "            temperature=0.3,\n",
    "            api_key=os.getenv(\"MISTRAL_API_KEY\"),\n",
    "        )\n",
    "\n",
    "resultat = Lettre_motiv_genere[\"choices\"][0][\"message\"][\n",
    "            \"content\"\n",
    "        ].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Quentin Lim**\n",
      "12 rue de la Paix, 75000 Paris\n",
      "quentinlim384@gmail.com | +33782885515\n",
      "13 mars 2025\n",
      "\n",
      "Madame, Monsieur,\n",
      "\n",
      "Je me permets de vous adresser ma candidature pour le poste de Data Scientist au sein de AOSIS CONSULTING. Fort de mon parcours académique et professionnel en Data Science, je suis convaincu de pouvoir apporter une contribution significative à votre équipe.\n",
      "\n",
      "Actuellement en master en Data Science à l'Université Lyon 2 Lumière, j'ai acquis une expertise avancée en analyse de données, en machine learning et en développement de modèles. Mon expérience inclut la réalisation de projets complexes tels que l'analyse de données biologiques, la création de packages R pour la régression logistique, et la mise en œuvre de solutions de visualisation des données avec Power BI et Tableau.\n",
      "\n",
      "Au cours de mon stage en tant que Data Analyst chez SYSBLOCK, j'ai développé des compétences en dashboarding et en web development, ainsi qu'une expérience dans l'utilisation de technologies cloud comme AWS. J'ai également travaillé sur des projets de scraping web et d'analyse de sentiments, ce qui m'a permis de renforcer mes compétences en NLP et en traitement de données.\n",
      "\n",
      "Ce qui m'attire particulièrement chez AOSIS CONSULTING, c'est votre engagement envers des valeurs telles que la citoyenneté, l'écologie et le sport. Ces enjeux sont profondément enracinés dans ma propre vision de la contribution professionnelle, et je suis motivé par l'opportunité de travailler dans un environnement où ces valeurs sont mises en pratique.\n",
      "\n",
      "Je suis particulièrement attiré par le poste de Data Scientist en raison de votre expertise dans l'industrialisation des modèles dans des environnements cloud. Mon expérience avec Python, SQL, et les technologies cloud comme GCP, ainsi que ma capacité à développer des outils de visualisation des données, me permettent de répondre aux exigences de ce poste.\n",
      "\n",
      "Je suis convaincu que mon profil correspond aux attentes de votre entreprise et que je pourrais apporter une valeur ajoutée à votre équipe. Je serais ravi de discuter plus en détail de ma candidature lors d'un entretien.\n",
      "\n",
      "Je vous remercie par avance pour l'attention que vous porterez à ma candidature et reste à votre disposition pour toute information complémentaire.\n",
      "\n",
      "Veuillez agréer, Madame, Monsieur, l'expression de mes salutations distinguées.\n",
      "\n",
      "Quentin Lim\n"
     ]
    }
   ],
   "source": [
    "print(resultat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lettre_motivation(text_brut: str, job_offer:str) ->str:\n",
    "    \"\"\"\n",
    "    Génère une lettre de motivation personnalisée en fonction des informations extraites du CV et de l'offre d'emploi.\n",
    "    \n",
    "    Args:\n",
    "        text_brut (str): Texte brut extrait du CV du candidat\n",
    "        job_offer (str): Description de l'offre d'emploi\n",
    "        \n",
    "    Returns:\n",
    "        str: Lettre de motivation générée au format texte\n",
    "    \n",
    "    \"\"\"\n",
    "    information_perso = extraction_info_perso(text_brut)\n",
    "    resultat_extraction_info_perso_json = json.loads(information_perso)\n",
    "\n",
    "    nom = resultat_extraction_info_perso_json.get(\"nom_prenom\")\n",
    "    email = resultat_extraction_info_perso_json.get(\"email\", \"\").strip()\n",
    "    # Remove all spaces from email\n",
    "    email = \"\".join(email.split())\n",
    "    telephone = resultat_extraction_info_perso_json.get(\"telephone\")\n",
    "    adresse = resultat_extraction_info_perso_json.get(\"adresse\")\n",
    "\n",
    "\n",
    "    # Set French locale\n",
    "    try:\n",
    "        locale.setlocale(locale.LC_TIME, 'fr_FR.UTF-8')  # Linux/Mac\n",
    "    except:\n",
    "        locale.setlocale(locale.LC_TIME, 'fra_fra')  # Windows\n",
    "\n",
    "    # Get date in French format\n",
    "    date = datetime.now().strftime(\"%d %B %Y\")\n",
    "\n",
    "    prompt_lettre_motivation = f\"\"\"\n",
    "    Tu es un assistant qui rédige des lettres de motivation personnalisées et professionnelles. Voici les informations nécessaires :\n",
    "\n",
    "    **Informations du candidat :**\n",
    "    - Nom : {nom}\n",
    "    - Email : {email}\n",
    "    - Téléphone : {telephone}\n",
    "    - Adresse : {adresse}\n",
    "    - Date : {date}\n",
    "\n",
    "    **Texte brut du CV :**\n",
    "    {text_brut}\n",
    "\n",
    "    **Offre d'emploi :**\n",
    "    {job_offer}\n",
    "\n",
    "    **Instructions :**\n",
    "    1. Rédige une lettre de motivation au format A4, bien structurée et professionnelle.\n",
    "    2. Mets en avant les compétences et expériences du candidat qui correspondent aux exigences du poste.\n",
    "    3. Mentionne des éléments spécifiques de l'entreprise ou du poste pour montrer que la candidature est personnalisée.\n",
    "    4. Explique pourquoi le candidat est motivé pour rejoindre cette entreprise en particulier.\n",
    "    5. Utilise un ton professionnel et évite les phrases génériques.\n",
    "    6. Ne laisse pas de champs vides et ne devine pas les informations manquantes.\n",
    "\n",
    "    **Format de la lettre :**\n",
    "    - En-tête : Nom, prénom, adresse, email, téléphone, date.\n",
    "    - Introduction : Présentation du candidat et motivation pour le poste.\n",
    "    - Corps : Compétences et expériences en lien avec le poste.\n",
    "    - Conclusion : Expression de l'enthousiasme et disponibilité pour un entretien.\n",
    "\n",
    "    **Exemple de structure :**\n",
    "    {nom}\n",
    "    {email}\n",
    "    {telephone}\n",
    "    {adresse}\n",
    "    {date}\n",
    "\n",
    "    Madame, Monsieur,\n",
    "    Je me permets de vous adresser ma candidature pour le poste de [poste] au sein de [entreprise]. [Motivation personnalisée].\n",
    "\n",
    "    Avec mon expérience en [domaine] et mes compétences en [compétences], je suis convaincu de pouvoir contribuer à [objectif de l'entreprise]. [Détail des expériences et compétences pertinentes].\n",
    "\n",
    "    Je serais ravi de discuter de ma candidature lors d'un entretien. Je reste à votre disposition pour toute information complémentaire.\n",
    "\n",
    "    Veuillez agréer, Madame, Monsieur, mes salutations distinguées.\n",
    "    {nom}\n",
    "    \"\"\"\n",
    "        \n",
    "    Lettre_motiv_genere = litellm.completion(\n",
    "                model=\"mistral/ministral-3b-latest\",  \n",
    "                messages=[{\"role\": \"user\", \"content\": prompt_lettre_motivation}],\n",
    "                max_tokens=1500,\n",
    "                temperature=0.3,\n",
    "                api_key=os.getenv(\"MISTRAL_API_KEY\"),\n",
    "            )\n",
    "\n",
    "    resultat = Lettre_motiv_genere[\"choices\"][0][\"message\"][\n",
    "                \"content\"\n",
    "            ].strip()\n",
    "    \n",
    "    return resultat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Quentin Lim**\n",
      "quentinlim384@gmail.com\n",
      "+33782885515\n",
      "Non réseigner\n",
      "13 mars 2025\n",
      "\n",
      "Madame, Monsieur,\n",
      "\n",
      "Je me permets de vous adresser ma candidature pour le poste de Data Scientist au sein de AOSIS CONSULTING. Fort de mon parcours académique et professionnel en Data Science, je suis convaincu de pouvoir apporter une contribution significative à votre équipe.\n",
      "\n",
      "Actuellement étudiant en Master en Data Science à l'Université Lyon 2 Lumière, j'ai acquis une expertise approfondie en analyse de données avancée, en NLP/LLM, en vision par ordinateur et en apprentissage profond. Mon expérience inclut la réalisation de projets complexes tels que la création d'un package de régression logistique en Python, l'analyse de sentiments sur les avis TripAdvisor, et la gestion de projets cloud sur AWS.\n",
      "\n",
      "Mon parcours académique et professionnel m'a permis de développer des compétences solides en Python, SQL, et en développement logiciel agile. J'ai également une expérience significative dans le développement de solutions cloud, notamment avec GCP, ce qui correspond parfaitement aux exigences de votre poste. Mon expérience en gestion de projets cloud, en développement de solutions de visualisation des données, et en mise en production de modèles est un atout majeur pour ce poste.\n",
      "\n",
      "Ce qui m'attire particulièrement chez AOSIS CONSULTING, c'est votre engagement envers des enjeux importants tels que l'écologie, la citoyenneté et le sport. Ces valeurs résonnent profondément avec moi et je suis motivé par l'opportunité de contribuer à des projets qui ont un impact positif sur la société. De plus, votre approche collaborative et votre engagement envers des activités variées font de votre entreprise un environnement de travail dynamique et enrichissant.\n",
      "\n",
      "Je suis convaincu que mon profil et mes compétences correspondent parfaitement aux exigences de ce poste. Je serais ravi de discuter plus en détail de ma candidature lors d'un entretien et de vous démontrer comment je peux contribuer à la réussite de vos projets.\n",
      "\n",
      "Je vous remercie par avance pour l'attention que vous porterez à ma candidature et reste à votre disposition pour toute information complémentaire.\n",
      "\n",
      "Veuillez agréer, Madame, Monsieur, l'expression de mes salutations distinguées.\n",
      "\n",
      "Quentin Lim\n"
     ]
    }
   ],
   "source": [
    "print(generate_lettre_motivation(text_brut, job_offer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[Votre Nom]\\n[Votre Adresse]\\n[Code Postal, Ville]\\n[Votre Email]\\n[Votre Numéro de Téléphone]\\n[Date]\\n\\nAOSIS CONSULTING\\n[Adresse de l'entreprise]\\n31 - Toulouse\\n\\nObjet : Candidature au poste de Data Scientist (H/F)\\n\\nMadame, Monsieur,\\n\\nJe me permets de vous adresser ma candidature pour le poste de Data Scientist au sein de votre entreprise, tel que publié sur votre site. Actuellement étudiant en Data Science à l'Université Lumière Lyon 2, je suis à la recherche d'une opportunité d'internship pour débuter ma carrière dans ce domaine passionnant.\\n\\nMon parcours académique et professionnel m'a permis de développer une solide expertise en data science, notamment en matière d'analyse avancée, de Big Data, de MLOps, et de predictive analytics. J'ai eu l'occasion de travailler sur divers projets qui m'ont permis de maîtriser des outils tels que Python, R, SQL, et des bibliothèques comme Scikit-learn, TensorFlow, et PySpark. Mon expérience inclut également la création de packages logiciels, la réalisation d'analyses NLP, et la gestion de bases de données NoSQL.\\n\\nAu cours de mon stage en tant que Data Analyst chez SYSBLOCK, j'ai eu l'opportunité de travailler sur des projets de dashboarding et d'analyse de données, ainsi que sur des projets de développement web et de blockchain. J'ai également développé des compétences en DevOps, notamment sur AWS, et j'ai une expérience significative avec des outils de visualisation comme Power BI et Tableau.\\n\\nCe qui m'attire particulièrement dans votre offre est votre engagement envers des valeurs importantes telles que la citoyenneté, l'écologie et le sport. Ces valeurs résonnent profondément avec moi et je suis convaincu que mon profil pourrait apporter une contribution significative à vos projets.\\n\\nJe suis particulièrement attiré par l'opportunité de travailler dans un environnement technique avancé, utilisant des outils tels que Python, SQL, Terraform, et des plateformes cloud comme GCP. Mon expérience en développement logiciel agile et ma maîtrise des méthodologies Git/Agile me permettent de m'intégrer rapidement et de collaborer efficacement avec des équipes multidisciplinaires.\\n\\nJe suis convaincu que mon parcours et mes compétences correspondent parfaitement aux exigences de ce poste. Je serais ravi de pouvoir discuter plus en détail de ma candidature lors d'un entretien.\\n\\nJe vous remercie par avance pour l'attention que vous porterez à ma demande et je reste à votre disposition pour toute information complémentaire.\\n\\nDans l'attente de votre réponse, je vous prie d'agréer, Madame, Monsieur, l'expression de mes salutations distinguées.\\n\\n[Votre Nom]\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"[Votre Nom]\\n[Votre Adresse]\\n[Code Postal, Ville]\\n[Votre Email]\\n[Votre Numéro de Téléphone]\\n[Date]\\n\\nAOSIS CONSULTING\\n[Adresse de l'entreprise]\\n31 - Toulouse\\n\\nObjet : Candidature au poste de Data Scientist (H/F)\\n\\nMadame, Monsieur,\\n\\nJe me permets de vous adresser ma candidature pour le poste de Data Scientist au sein de votre entreprise, tel que publié sur votre site. Actuellement étudiant en Data Science à l'Université Lumière Lyon 2, je suis à la recherche d'une opportunité d'internship pour débuter ma carrière dans ce domaine passionnant.\\n\\nMon parcours académique et professionnel m'a permis de développer une solide expertise en data science, notamment en matière d'analyse avancée, de Big Data, de MLOps, et de predictive analytics. J'ai eu l'occasion de travailler sur divers projets qui m'ont permis de maîtriser des outils tels que Python, R, SQL, et des bibliothèques comme Scikit-learn, TensorFlow, et PySpark. Mon expérience inclut également la création de packages logiciels, la réalisation d'analyses NLP, et la gestion de bases de données NoSQL.\\n\\nAu cours de mon stage en tant que Data Analyst chez SYSBLOCK, j'ai eu l'opportunité de travailler sur des projets de dashboarding et d'analyse de données, ainsi que sur des projets de développement web et de blockchain. J'ai également développé des compétences en DevOps, notamment sur AWS, et j'ai une expérience significative avec des outils de visualisation comme Power BI et Tableau.\\n\\nCe qui m'attire particulièrement dans votre offre est votre engagement envers des valeurs importantes telles que la citoyenneté, l'écologie et le sport. Ces valeurs résonnent profondément avec moi et je suis convaincu que mon profil pourrait apporter une contribution significative à vos projets.\\n\\nJe suis particulièrement attiré par l'opportunité de travailler dans un environnement technique avancé, utilisant des outils tels que Python, SQL, Terraform, et des plateformes cloud comme GCP. Mon expérience en développement logiciel agile et ma maîtrise des méthodologies Git/Agile me permettent de m'intégrer rapidement et de collaborer efficacement avec des équipes multidisciplinaires.\\n\\nJe suis convaincu que mon parcours et mes compétences correspondent parfaitement aux exigences de ce poste. Je serais ravi de pouvoir discuter plus en détail de ma candidature lors d'un entretien.\\n\\nJe vous remercie par avance pour l'attention que vous porterez à ma demande et je reste à votre disposition pour toute information complémentaire.\\n\\nDans l'attente de votre réponse, je vous prie d'agréer, Madame, Monsieur, l'expression de mes salutations distinguées.\\n\\n[Votre Nom]\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "challengeIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
