{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read PDF\n",
    "\n",
    "# from dotenv import load_dotenv\n",
    "# Charger les variables d'environnement\n",
    "# load_dotenv()\n",
    "# Faire lettre motivation automatique\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def read_pdf(file_path: str) -> str:\n",
    "    \"\"\"Lit et extrait le texte d'un CV au format PDF d'une seule page.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Chemin d'accès vers le fichier PDF à lire\n",
    "\n",
    "    Returns:\n",
    "        str: Texte brut extrait du PDF\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: Si le fichier PDF n'existe pas\n",
    "        IndexError: Si le PDF est vide\n",
    "        Exception: Pour toute autre erreur lors de la lecture du PDF\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reader = PdfReader(file_path)\n",
    "        if len(reader.pages) == 0:\n",
    "            raise IndexError(\"Le PDF est vide\")\n",
    "        \n",
    "        page = reader.pages[0]  # Lecture de la première page uniquement\n",
    "        text_brut = page.extract_text()\n",
    "        \n",
    "        if not text_brut:\n",
    "            raise Exception(\"Aucun texte n'a pu être extrait du PDF\")\n",
    "            \n",
    "        return text_brut\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Le fichier {file_path} n'existe pas\")\n",
    "    except IndexError as e:\n",
    "        raise IndexError(str(e))\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Erreur lors de la lecture du PDF: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quentin Lim  \n",
      "Last year Student in \n",
      "Data Science\n",
      "quentinlim 384@ gm ail.com\n",
      "+33782885515\n",
      "linkedin.com /in/quentin-lim-\n",
      "978746250\n",
      "github.com /QL2111\n",
      "Profile\n",
      "Currently seeking an internship in \n",
      "Data Science starting in March \n",
      "2025 for a duration of 4 to 6 \n",
      "months.\n",
      "Skills\n",
      "M L, NLP, TensorFlow; Scikit-learn, \n",
      "M LFlow, Transform ers, LLM , Tim e \n",
      "Series.\n",
      "SQL, NoSQL, M ongoDB\n",
      "Qlik, Tableau, PowerBI\n",
      "OpenCV, YOLO\n",
      "Azure, AW S, Fabric\n",
      "Git/Agile m ethodology\n",
      "Python/R/Java/PySpark/JavaScript/\n",
      "PHP\n",
      "Gen AI\n",
      "Interests\n",
      "Board Games: Casual boarding\n",
      "gam es and Chess club\n",
      "Gaming: Played in competitives\n",
      "tournam ents, peaked GrandMaster\n",
      "in League of Legends\n",
      "Sailing: M em ber of the sailing club\n",
      "at La Rochelle Université\n",
      "Basket ball: Sports association\n",
      "during M iddle School, teamwork\n",
      "and fast decision making.\n",
      "Volunteering\n",
      "ESN Cosmolyon\n",
      "2023 – present\n",
      "Vice-President, holdings Culturals \n",
      "Event for internationals and local \n",
      "student(Board gam es/Day \n",
      "trips/Spanish dinner)\n",
      "Alter-ego Lyon 2\n",
      "2023 – present\n",
      "Buddy System  with Lyon 2 \n",
      "UniversityEducation\n",
      "Master in Data Science, Université Lyon 2 Lumière\n",
      "09/2023 – present\n",
      "•Expertise in advanced data analysis: ANOVA, time series, biostatistics, NLP/LLM, \n",
      "Computer Vision, and Deep Learning.\n",
      "•Proficiency in Big Data and MLOps: web scraping, data warehouses, model \n",
      "deployment, and pipelines.\n",
      "•Specialized in predictive analytics, focusing on the use of advanced statistical \n",
      "models and machine learning algorithms for forecasting and decision making.\n",
      "International Exchange Program, National Central University\n",
      "Taoyuan, Taïwan\n",
      "•GPA: 3.8 | Experience in data mining for biological data: autism classification, \n",
      "sentiment analysis and Graph Neural Networks presentation on Reddit data.\n",
      "•Research & Publications: Conducted a literature review on feature selection \n",
      "techniques and co-authored \"A Review of Feature Selection Techniques in Education\". \n",
      "Explored Transformer models for advanced data analysis.\n",
      "Erasmus + Mobility, South East Technological University\n",
      "Waterford, Ireland\n",
      "•First Class Honours | EDA & predictive modeling on Titanic and Tips datasets with \n",
      "up to 90% accuracy, NoSQL database creation for TFI bikes in Waterford, and data \n",
      "visualization in R with NYC flights data.\n",
      "•DevOps on AWS: EC2 instances, S3 buckets, configuration, and achieved \n",
      "automation with Python scripts.\n",
      "Professional Experience\n",
      "University Informatics Department, Lyon 2\n",
      "present\n",
      "Student Job at the IT department of the university, help desk, loan of computer and \n",
      "professional audiovisual equiment, teamwork.\n",
      "Internship Data Analyst, SYSBLOCK\n",
      "Paris, France\n",
      "•Dashboarding & Analytics: KPI derivation from Google Analytics data and \n",
      "interactive dashboards with Power BI.\n",
      "•Web Development & Blockchain: Experience with Next.js for web development and \n",
      "introduction to blockchain technologies.\n",
      "Projects\n",
      "Creation of a Logistic Regression R package\n",
      "•Logistic regression package from scratch :Implemented various optimizers \n",
      "(Adam, mini-batch, SGD) and applied regularization techniques (L1, L2, ElasticNet). \n",
      "•Successfully tested on classification tasks : achieved up to 90% accuracy on \n",
      "StudentPerformance, Creditcard,  datasets and achieved similar performance to \n",
      "scikit-learn..\n",
      "Projet NLP Analysis of TripAdvisor review\n",
      "•Web Scraping & Sentiment Analysis: Collected TripAdvisor data with \n",
      "BeautifulSoup and performed sentiment analysis on user reviews. Aggregated \n",
      "comments using clustering techniques.\n",
      "•End-to-End Application: Integrated a SQLite database and connected it to a \n",
      "Streamlit app for enhanced visualization. Deployed as a Docker image.\n",
      "•LLM & RAG for Summarization: Leveraged a Large Language Model (LLM) with \n",
      "Retrieval-Augmented Generation (RAG) to summarize user reviews effectively.\n",
      "Project AWS Cloud\n",
      "•AWS Deployment & Scaling: Successfully deployed a template website on EC2 \n",
      "instances with a connected relational database on AWS.\n",
      "•High Availability & Monitoring: Implemented an Auto Scaling Group with a Load \n",
      "Balancer and set up monitoring using custom CloudWatch metrics.\n",
      "Languages/References\n",
      "Languages: French - Native/Bilingual   English C1 - Fluent  Mandarin -\n",
      "Conversational\n",
      "References: Bernard Butler, Pr, SETU  bernard.butler@setu.ie   Liam Doyle, Pr,\n",
      "SETU  liam.doyle@setu.ie\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "<class 'str'>\n",
      "4231\n"
     ]
    }
   ],
   "source": [
    "reader = PdfReader(\"CV_V4_EN.pdf\")\n",
    "page = reader.pages[0] # 1 seule page\n",
    "text_brut = page.extract_text()\n",
    "print(text_brut)\n",
    "print(type(text_brut))\n",
    "print(len(text_brut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(read_pdf(\"CV_V4_EN.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Mistral Mini -> Reformulation Texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Formulation du prompt (CV texte brut + )\n",
    "# Ajouter les suivis de prix + impact ecologique ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import litellm\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA partir d\\'un texte brut venant d\\'un CV, extrait les informations suivantes au format JSON :\\n{\\n    \"Diplome\": [\\n      {\\n          \"niveau_etudes\": \"int\",\\n          \"domaine_etudes\": [\"str\"]\\n      }\\n    ],\\n\\n    \"Competences\": [\"str\"],\\n    \"Experiences\": [\\n        {\\n            \"domaine_activite\": [\"str\"],\\n            \"poste_occupe\": \"str\",\\n            \"duree\": \"int\"\\n        }\\n    ],\\n    \"Profil\": {\\n        \"titre\": \"str\",\\n        \"disponibilite\": \"str\"\\n    }\\n}\\n\\nTexte du CV :\\n\"Quentin Lim  \\nLast year Student in \\nData Science\\nquentinlim 384@ gm ail.com\\n+33782885515\\nlinkedin.com /in/quentin-lim-\\n978746250\\ngithub.com /QL2111\\nProfile\\nCurrently seeking an internship in \\nData Science starting in March \\n2025 for a duration of 4 to 6 \\nmonths.\\nSkills\\nM L, NLP, TensorFlow; Scikit-learn, \\nM LFlow, Transform ers, LLM , Tim e \\nSeries.\\nSQL, NoSQL, M ongoDB\\nQlik, Tableau, PowerBI\\nOpenCV, YOLO\\nAzure, AW S, Fabric\\nGit/Agile m ethodology\\nPython/R/Java/PySpark/JavaScript/\\nPHP\\nGen AI\\nInterests\\nBoard Games:\\xa0Casual boarding\\ngam es and Chess club\\nGaming:\\xa0Played in competitives\\ntournam ents, peaked GrandMaster\\nin League of Legends\\nSailing:\\xa0M em ber of the sailing club\\nat La Rochelle Université\\nBasket ball:\\xa0Sports association\\nduring M iddle School, teamwork\\nand fast decision making.\\nVolunteering\\nESN Cosmolyon\\n2023 – present\\nVice-President, holdings Culturals \\nEvent for internationals and local \\nstudent(Board gam es/Day \\ntrips/Spanish dinner)\\nAlter-ego Lyon 2\\n2023 – present\\nBuddy System  with Lyon 2 \\nUniversityEducation\\nMaster in Data Science, Université Lyon 2 Lumière\\n09/2023 – present\\n•Expertise in advanced data analysis: ANOVA, time series, biostatistics, NLP/LLM, \\nComputer Vision, and Deep Learning.\\n•Proficiency in Big Data and MLOps: web scraping, data warehouses, model \\ndeployment, and pipelines.\\n•Specialized in predictive analytics, focusing on the use of advanced statistical \\nmodels and machine learning algorithms for forecasting and decision making.\\nInternational Exchange Program, National Central University\\nTaoyuan, Taïwan\\n•GPA: 3.8 | Experience in data mining for biological data: autism classification, \\nsentiment analysis and Graph Neural Networks presentation on Reddit data.\\n•Research & Publications: Conducted a literature review on feature selection \\ntechniques and co-authored \"A Review of Feature Selection Techniques in Education\". \\nExplored Transformer models for advanced data analysis.\\nErasmus + Mobility, South East Technological University\\nWaterford, Ireland\\n•First Class Honours | EDA & predictive modeling on Titanic and Tips datasets with \\nup to 90% accuracy, NoSQL database creation for TFI bikes in Waterford, and data \\nvisualization in R with NYC flights data.\\n•DevOps on AWS: EC2 instances, S3 buckets, configuration, and achieved \\nautomation with Python scripts.\\nProfessional Experience\\nUniversity Informatics Department, Lyon 2\\npresent\\nStudent Job at the IT department of the university, help desk, loan of computer and \\nprofessional audiovisual equiment, teamwork.\\nInternship Data Analyst, SYSBLOCK\\nParis, France\\n•Dashboarding & Analytics: KPI derivation from Google Analytics data and \\ninteractive dashboards with Power BI.\\n•Web Development & Blockchain: Experience with Next.js for web development and \\nintroduction to blockchain technologies.\\nProjects\\nCreation of a Logistic Regression R package\\n•Logistic regression package from scratch :Implemented various optimizers \\n(Adam, mini-batch, SGD) and applied regularization techniques (L1, L2, ElasticNet). \\n•Successfully tested on classification tasks : achieved up to 90% accuracy on \\nStudentPerformance, Creditcard,  datasets and achieved similar performance to \\nscikit-learn..\\nProjet NLP Analysis of TripAdvisor review\\n•Web Scraping & Sentiment Analysis: Collected TripAdvisor data with \\nBeautifulSoup and performed sentiment analysis on user reviews. Aggregated \\ncomments using clustering techniques.\\n•End-to-End Application: Integrated a SQLite database and connected it to a \\nStreamlit app for enhanced visualization. Deployed as a Docker image.\\n•LLM & RAG for Summarization: Leveraged a Large Language Model (LLM) with \\nRetrieval-Augmented Generation (RAG) to summarize user reviews effectively.\\nProject AWS Cloud\\n•AWS Deployment & Scaling: Successfully deployed a template website on EC2 \\ninstances with a connected relational database on AWS.\\n•High Availability & Monitoring: Implemented an Auto Scaling Group with a Load \\nBalancer and set up monitoring using custom CloudWatch metrics.\\nLanguages/References\\nLanguages:\\xa0French - Native/Bilingual \\xa0\\xa0English C1 - Fluent\\xa0\\xa0Mandarin -\\nConversational\\nReferences:\\xa0Bernard Butler, Pr, SETU\\xa0\\xa0bernard.butler@setu.ie \\xa0\\xa0Liam Doyle, Pr,\\nSETU\\xa0\\xa0liam.doyle@setu.ie\\n|\\n|\\n|\\n|\\n|\"\\n\\nNe retourne que le JSON\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reformulation_prompt = f\"\"\"\n",
    "A partir d'un texte brut venant d'un CV, extrait les informations suivantes au format JSON :\n",
    "{{\n",
    "    \"Diplome\": [\n",
    "      {{\n",
    "          \"niveau_etudes\": \"int\",\n",
    "          \"domaine_etudes\": [\"str\"]\n",
    "      }}\n",
    "    ],\n",
    "\n",
    "    \"Competences\": [\"str\"],\n",
    "    \"Experiences\": [\n",
    "        {{\n",
    "            \"domaine_activite\": [\"str\"],\n",
    "            \"poste_occupe\": \"str\",\n",
    "            \"duree\": \"int\"\n",
    "        }}\n",
    "    ],\n",
    "    \"Profil\": {{\n",
    "        \"titre\": \"str\",\n",
    "        \"disponibilite\": \"str\"\n",
    "    }}\n",
    "}}\n",
    "\n",
    "Texte du CV :\n",
    "\"{text_brut}\"\n",
    "\n",
    "Ne retourne que le JSON\n",
    "\"\"\"\n",
    "reformulation_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification de la clé API\n",
    "#  api_key=os.getenv(\"MISTRAL_API_KEY\")\n",
    "# api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# litellm._turn_on_debug()\n",
    "# Température, plus c'est proche de 1, plus c'est créatif\n",
    "# On cherche à savoir combien de token on devrait mettre\n",
    "\n",
    "CV_reformuler = litellm.completion(\n",
    "            model=\"mistral/ministral-3b-latest\",  # Choix d'un modèle petit\n",
    "            messages=[{\"role\": \"user\", \"content\": reformulation_prompt}],\n",
    "            max_tokens=1500,\n",
    "            temperature=0.3,\n",
    "            api_key=os.getenv(\"MISTRAL_API_KEY\"),\n",
    "        )\n",
    "\n",
    "resultat = CV_reformuler[\"choices\"][0][\"message\"][\n",
    "            \"content\"\n",
    "        ].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Diplome\": [\n",
      "        {\n",
      "            \"niveau_etudes\": \"Master\",\n",
      "            \"domaine_etudes\": [\"Data Science\"]\n",
      "        }\n",
      "    ],\n",
      "    \"Competences\": [\n",
      "        \"M L\", \"NLP\", \"TensorFlow\", \"Scikit-learn\", \"M LFlow\", \"Transformers\", \"LLM\", \"Time Series\",\n",
      "        \"SQL\", \"NoSQL\", \"MongoDB\", \"Qlik\", \"Tableau\", \"PowerBI\", \"OpenCV\", \"YOLO\", \"Azure\", \"AWS\", \"Fabric\",\n",
      "        \"Git\", \"Agile methodology\", \"Python\", \"R\", \"Java\", \"PySpark\", \"JavaScript\", \"PHP\", \"Gen AI\"\n",
      "    ],\n",
      "    \"Experiences\": [\n",
      "        {\n",
      "            \"domaine_activite\": [\"Data Science\"],\n",
      "            \"poste_occupe\": \"Student Job at the IT department of the university\",\n",
      "            \"duree\": 1\n",
      "        },\n",
      "        {\n",
      "            \"domaine_activite\": [\"Data Science\"],\n",
      "            \"poste_occupe\": \"Internship Data Analyst\",\n",
      "            \"duree\": 1\n",
      "        }\n",
      "    ],\n",
      "    \"Profil\": {\n",
      "        \"titre\": \"Currently seeking an internship in Data Science starting in March 2025 for a duration of 4 to 6 months.\",\n",
      "        \"disponibilite\": \"March 2025\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "1019\n"
     ]
    }
   ],
   "source": [
    "# Le CV fait 4231 en len\n",
    "# len de 1863 pour 500 max tokens\n",
    "# len de 4429 pour 1500 max tokens -> C'est OK, on essaye avec 1000 max tokens\n",
    "print(resultat)\n",
    "print(len(resultat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_cv(text_brut: str, temperature: float = 0.01, max_tokens: int = 1500) -> str:\n",
    "    \"\"\"\n",
    "    Analyse un CV en format texte et retourne les informations structurées en JSON.\n",
    "\n",
    "    Args:\n",
    "        text_brut (str): Texte brut du CV à analyser\n",
    "        temperature (float, optional): Paramètre de créativité du modèle. Defaults to 0.2.\n",
    "        max_tokens (int, optional): Nombre maximum de tokens pour la réponse. Defaults to 1500.\n",
    "\n",
    "    Returns:\n",
    "        str: Informations en string(réponse du LLM) structurées du CV au format JSON\n",
    "\n",
    "    Raises:\n",
    "        Exception: En cas d'erreur d'API ou de parsing JSON\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reformulation_prompt = f\"\"\"\n",
    "        À partir du texte brut d'un CV, extrais les informations suivantes au format JSON. \n",
    "        Si une information n'est pas explicitement mentionnée dans le texte, retourne `null` ou une liste vide.\n",
    "        Ne devine pas les informations manquantes et ne retourne que ce qui est clairement présent dans le texte.\n",
    "\n",
    "        Format JSON attendu :\n",
    "        {{\n",
    "            \"Formation\": [\n",
    "                {{\n",
    "                    \"niveau_etudes\": \"str\",  // Ex: \"Licence\", \"Master\", \"Doctorat\"\n",
    "                    \"domaine_etudes\": [\"str\"]  // Ex: [\"Informatique\", \"Mathématiques\"]\n",
    "                }}\n",
    "            ],\n",
    "            \"Competences\": [\"str\"],  // Ex: [\"Python\", \"Gestion de projet\"]\n",
    "            \"Experiences\": [\n",
    "                {{\n",
    "                    \"domaine_activite\": [\"str\"],  // Ex: [\"Tech\", \"Finance\"]\n",
    "                    \"poste_occupe\": \"str\",  // Ex: \"Développeur Python\"\n",
    "                    \"duree\": \"str\"  // Ex: \"2 ans\"\n",
    "                }}\n",
    "            ],\n",
    "            \"Profil\": {{\n",
    "                \"titre\": \"str\",  // Ex: \"Développeur Full-Stack\"\n",
    "                \"disponibilite\": \"str\"  // Ex: \"dd-mm-yyyy\"\n",
    "            }}\n",
    "        }}\n",
    "\n",
    "        Texte du CV :\n",
    "        \"{text_brut}\"\n",
    "\n",
    "        Ne retourne que le JSON, sans commentaires supplémentaires.\n",
    "        \"\"\"\n",
    "\n",
    "        CV_reformuler = litellm.completion(\n",
    "            model=\"mistral/mistral-medium\",\n",
    "            messages=[{\"role\": \"user\", \"content\": reformulation_prompt}],\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            api_key=os.getenv(\"MISTRAL_API_KEY\"),\n",
    "        )\n",
    "\n",
    "        # Extraire et parser le JSON de la réponse\n",
    "        resultat = CV_reformuler[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        return resultat\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Erreur lors de l'analyse du CV: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Formation\": [\n",
      "    {\n",
      "      \"niveau_etudes\": \"Master\",\n",
      "      \"domaine_etudes\": [\"Data Science\"]\n",
      "    }\n",
      "  ],\n",
      "  \"Competences\": [\n",
      "    \"ML\",\n",
      "    \"NLP\",\n",
      "    \"TensorFlow\",\n",
      "    \"Scikit-learn\",\n",
      "    \"MLFlow\",\n",
      "    \"Transformers\",\n",
      "    \"LLM\",\n",
      "    \"Time Series\",\n",
      "    \"SQL\",\n",
      "    \"NoSQL\",\n",
      "    \"MongoDB\",\n",
      "    \"Qlik\",\n",
      "    \"Tableau\",\n",
      "    \"PowerBI\",\n",
      "    \"OpenCV\",\n",
      "    \"YOLO\",\n",
      "    \"Azure\",\n",
      "    \"AWS\",\n",
      "    \"Fabric\",\n",
      "    \"Git/Agile methodology\",\n",
      "    \"Python\",\n",
      "    \"R\",\n",
      "    \"Java\",\n",
      "    \"PySpark\",\n",
      "    \"JavaScript\",\n",
      "    \"PHP\",\n",
      "    \"Gen AI\"\n",
      "  ],\n",
      "  \"Experiences\": [\n",
      "    {\n",
      "      \"domaine_activite\": [],\n",
      "      \"poste_occupe\": \"Vice-President, holdings Culturals Events for internationals and local students\",\n",
      "      \"duree\": \"2023 – present\"\n",
      "    },\n",
      "    {\n",
      "      \"domaine_activite\": [],\n",
      "      \"poste_occupe\": \"Buddy System with Lyon 2 University\",\n",
      "      \"duree\": \"2023 – present\"\n",
      "    },\n",
      "    {\n",
      "      \"domaine_activite\": [\"Data Science\"],\n",
      "      \"poste_occupe\": \"Student Job at the IT department of the university, help desk, loan of computer and professional audiovisual equipment, teamwork\",\n",
      "      \"duree\": \"present\"\n",
      "    },\n",
      "    {\n",
      "      \"domaine_activite\": [\"Data Science\"],\n",
      "      \"poste_occupe\": \"Dashboarding & Analytics: KPI derivation from Google Analytics data and interactive dashboards with Power BI.\",\n",
      "      \"duree\": \"Internship Data Analyst, SYSBLOCK\"\n",
      "    },\n",
      "    {\n",
      "      \"domaine_activite\": [\"Web Development\", \"Blockchain\"],\n",
      "      \"poste_occupe\": \"Web Development & Blockchain: Experience with Next.js for web development and introduction to blockchain technologies.\",\n",
      "      \"duree\": \"Internship Data Analyst, SYSBLOCK\"\n",
      "    }\n",
      "  ],\n",
      "  \"Profil\": {\n",
      "    \"titre\": \"Currently seeking an internship in Data Science starting in March 2025 for a duration of 4 to 6 months.\",\n",
      "    \"disponibilite\": \"March 2025\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "CV_reformuler = analyze_cv(text_brut)\n",
    "print(CV_reformuler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matching CV et offre :\n",
    "\n",
    "- Obtention du string job offer par le scrapping\n",
    "- Transformation via un LLM de l'offre à un format similaire au CV_reformuler\n",
    "- Embedding + calcul de la similarité cosinus globale\n",
    "- Transformation en JSON du CV_reformuler et job_offer_reforumuler pour pouvoir effectuer une similarité par partie(clef communes car passé tout les deux par un LLM)\n",
    "- Calcul des similarité par parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Example job offer\n",
    "job_offer = \"\"\"\n",
    "  Titre : Data scientist (H/F) SALON TAF Toulouse 2025\n",
    "  Entreprise : AOSIS CONSULTING\n",
    "  Contrat : CDI\n",
    "  Localisation : 31 - TOULOUSE\n",
    "  Description :\n",
    "  Concrètement qu'est-ce qu'on fait ?\n",
    "  Nous proposons des Services, des Logiciels et de la Formation dans le domaine de la Business Intelligence, de la Data Science, de la Gouvernance et de la Visualisation de la donnée. L'Infrastructure et le Développement font également partie du panel de nos compétences.\n",
    "  Notre leitmotiv ? Citoyenneté, écologie et sport avec des experts de la donnée.\n",
    "  Notre objectif ? Porter encore plus haut et plus fort nos valeurs de sport, d'écologie et de citoyenneté et accompagner nos consultants dans leur montée en compétence.\n",
    "\n",
    "  Le poste\n",
    "  Dans le cadre d'une ouverture de poste, nous sommes à la recherche d'un.e Data Scientist pour l'un de nos clients.\n",
    "  Un.e data scientist senior (5 ans d'expérience) très autonome dans ses analyses et explorations, expérimenté dans l'industrialisation des modèles dans des environnements cloud.\n",
    "\n",
    "  Vous interviendrez sur toutes les étapes du projet, vous devrez :\n",
    "\n",
    "  Identifier leurs difficultés et proposer des solutions\n",
    "  Evaluer la qualité des données, les nettoyer, les agréger, et mener des études adhoc\n",
    "  Concevoir, implémenter et comparer différents algorithmes et méthodes statistiques\n",
    "  Concevoir et mener des protocoles de test en conditions réelles (magasins, entrepôts, .)\n",
    "  Développer des outils de visualisation des données\n",
    "  Mettre en production, maintenir et itérer sur les solutions\n",
    "\n",
    "  Environnement technique: Python, SQL, Terraform, Bitbucket, Jenkins, Airflow, Docker, Kubernetes, GCP (BigQuery, Spark DataProc)\n",
    "\n",
    "  Profil recherché\n",
    "  Vous êtes issu.e d'un Master en informatique ou mathématiques appliquées.\n",
    "  Vous avez à minima 5 années d'expériences en Data Science et maitrisez les algorithmes d'apprentissage statistique.\n",
    "  Vous maîtrisez Python et SQL\n",
    "  Vous avez une expérience dans le développement logiciel agile avec multiples contributeurs\n",
    "  Vous avez une expérience du cloud, idéalement GCP\n",
    "\n",
    "  Pourquoi nous rejoindre ?\n",
    "  Parce que nous sommes une société à taille humaine\n",
    "  Parce que nous nous engageons (réellement) dans des enjeux importants : l'écologie, la citoyenneté et le sport\n",
    "  Mais aussi parce que nous aimons réaliser tout un tas d'activités : des jeux, des afterworks, des restaurants, ... et plein d'autres choses encore :)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reformulation de l'offre d'emploi :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Transformation de l'offre d'emploi au même format que le CV\n",
    "def analyze_offre_emploi(offre: str, temperature: float = 0.01, max_tokens: int = 1500) -> str:\n",
    "    \"\"\"\n",
    "    Analyse une offre d'emploi en format texte et retourne les informations structurées en JSON.\n",
    "\n",
    "    Args:\n",
    "        text_brut (str): Texte brut del'offre à analyser\n",
    "        temperature (float, optional): Paramètre de créativité du modèle. Defaults to 0.2.\n",
    "        max_tokens (int, optional): Nombre maximum de tokens pour la réponse. Defaults to 1500.\n",
    "\n",
    "    Returns:\n",
    "        str: Informations en string(réponse du LLM) structurées du CV au format JSON\n",
    "\n",
    "    Raises:\n",
    "        Exception: En cas d'erreur d'API ou de parsing JSON\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reformulation_prompt = f\"\"\"\n",
    "        À partir de cette offre d'emploi, extrais les informations suivantes au format JSON. \n",
    "        Si une information n'est pas explicitement mentionnée dans le texte, retourne `null` ou une liste vide.\n",
    "        De plus la disponibilité correspond à la date de début du poste.\n",
    "        Ne devine pas les informations manquantes et ne retourne que ce qui est clairement présent dans le texte.\n",
    "        \n",
    "        Format JSON attendu :\n",
    "        {{\n",
    "            \"Formation\": [\n",
    "                {{\n",
    "                    \"niveau_etudes\": \"str\",  // Ex: \"Licence\", \"Master\", \"Doctorat\"\n",
    "                    \"domaine_etudes\": [\"str\"]  // Ex: [\"Informatique\", \"Mathématiques\"]\n",
    "                }}\n",
    "            ],\n",
    "            \"Competences\": [\"str\"],  // Ex: [\"Python\", \"Gestion de projet\"]\n",
    "            \"Experiences\": [\n",
    "                {{\n",
    "                    \"domaine_activite\": [\"str\"],  // Ex: [\"Tech\", \"Finance\"]\n",
    "                    \"poste_occupe\": \"str\",  // Ex: \"Développeur Python\"\n",
    "                    \"duree\": \"str\"  // Ex: \"2 ans\"\n",
    "                }}\n",
    "            ],\n",
    "            \"Profil\": {{\n",
    "                \"titre\": \"str\",  // Ex: \"Développeur Full-Stack\"\n",
    "                \"disponibilite\": \"str\"  // Ex: \"dd-mm-yyyy\"\n",
    "            }}\n",
    "        }}\n",
    "\n",
    "        Texte de l'offre d'emploi :\n",
    "        \"{offre}\"\n",
    "\n",
    "        Ne retourne que le JSON, sans commentaires supplémentaires.\n",
    "        \"\"\"\n",
    "\n",
    "        offre_reformuler = litellm.completion(\n",
    "            model=\"mistral/mistral-medium\",\n",
    "            messages=[{\"role\": \"user\", \"content\": reformulation_prompt}],\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            api_key=os.getenv(\"MISTRAL_API_KEY\"),\n",
    "        )\n",
    "\n",
    "        # Extraire et parser le JSON de la réponse\n",
    "        resultat = offre_reformuler[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        return resultat\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Erreur lors de l'analyse du CV: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Formation\": [\n",
      "    {\n",
      "      \"niveau_etudes\": \"Master\",\n",
      "      \"domaine_etudes\": [\"Informatique\", \"Mathématiques appliquées\"]\n",
      "    }\n",
      "  ],\n",
      "  \"Competences\": [\n",
      "    \"Python\",\n",
      "    \"SQL\",\n",
      "    \"Terraform\",\n",
      "    \"Bitbucket\",\n",
      "    \"Jenkins\",\n",
      "    \"Airflow\",\n",
      "    \"Docker\",\n",
      "    \"Kubernetes\",\n",
      "    \"GCP (BigQuery, Spark DataProc)\",\n",
      "    \"Développement logiciel agile\",\n",
      "    \"Algorithmes d'apprentissage statistique\"\n",
      "  ],\n",
      "  \"Experiences\": [\n",
      "    {\n",
      "      \"domaine_activite\": [\"Data Science\"],\n",
      "      \"poste_occupe\": \"Data Scientist\",\n",
      "      \"duree\": \"5 ans\"\n",
      "    }\n",
      "  ],\n",
      "  \"Profil\": {\n",
      "    \"titre\": \"Data Scientist\",\n",
      "    \"disponibilite\": null\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "job_offer_reforumer = analyze_offre_emploi(job_offer)\n",
    "print(job_offer_reforumer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarité cosinus globale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Token d'API Hugging Face\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "API_URL = \"https://api-inference.huggingface.co/pipeline/feature-extraction/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "\n",
    "def get_embedding(text: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Envoie une requête à l'API Hugging Face pour obtenir l'embedding d'un texte.\n",
    "\n",
    "    Args:\n",
    "        text (str): Texte à encoder.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Embedding du texte.\n",
    "    \"\"\"\n",
    "    headers = {\"Authorization\": f\"Bearer {os.getenv(\"HF_TOKEN\")}\"}\n",
    "    response = requests.post(\n",
    "        \"https://api-inference.huggingface.co/pipeline/feature-extraction/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "        headers=headers,\n",
    "        json={\"inputs\": text, \"options\": {\"wait_for_model\": True}},\n",
    "    )\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Erreur API : {response.status_code}, {response.text}\")\n",
    "    return np.array(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarité globale entre le CV et l'offre d'emploi: 0.9063\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_similarity(text1: str, text2: str) -> float:\n",
    "    \"\"\"\n",
    "    Calcule la similarité cosinus entre deux textes en utilisant l'API Hugging Face.\n",
    "    \n",
    "    Args:\n",
    "        text1 (str): Premier texte.\n",
    "        text2 (str): Deuxième texte.\n",
    "    \n",
    "    Returns:\n",
    "        float: Score de similarité cosinus entre les deux textes.\n",
    "    \"\"\"\n",
    "    # Obtenir les embeddings des textes\n",
    "    embedding1 = get_embedding(text1)\n",
    "    embedding2 = get_embedding(text2)\n",
    "    \n",
    "    # Calculer la similarité cosinus\n",
    "    similarity = cosine_similarity([embedding1], [embedding2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "# Calculer la similarité entre le CV et l'offre d'emploi\n",
    "similarity_score = calculate_similarity(CV_reformuler, job_offer_reforumer)\n",
    "print(f\"Similarité globale entre le CV et l'offre d'emploi: {similarity_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversion en JSON-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calcul de la similarité entre chaque partie du CV et l'offre d'emploi\n",
    "# Diviser le CV reformulé en json en plusieurs parties\n",
    "cv_json = json.loads(CV_reformuler)\n",
    "# print(cv_json)\n",
    "# convert job_offer to json\n",
    "job_offer_json = json.loads(job_offer_reforumer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Formation': [{'niveau_etudes': 'Master', 'domaine_etudes': ['Informatique', 'Mathématiques appliquées']}], 'Competences': ['Python', 'SQL', 'Terraform', 'Bitbucket', 'Jenkins', 'Airflow', 'Docker', 'Kubernetes', 'GCP (BigQuery, Spark DataProc)', 'Développement logiciel agile', \"Algorithmes d'apprentissage statistique\"], 'Experiences': [{'domaine_activite': ['Data Science'], 'poste_occupe': 'Data Scientist', 'duree': '5 ans'}], 'Profil': {'titre': 'Data Scientist', 'disponibilite': None}}\n"
     ]
    }
   ],
   "source": [
    "print(job_offer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(cv_json)) # Les données sont en string JSON like\n",
    "print(type(job_offer_json)) # Les données sont en string JSON like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul des similarités cosinus par parties :\n",
    "\n",
    "- Formation\n",
    "- Competences\n",
    "- Experiences\n",
    "- Profil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarité entre les deux json like\n",
    "\n",
    "# Similarité Formation\n",
    "# print(cv_json.get(\"Formation\"))\n",
    "# print(job_offer_json.get(\"Formation\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarité entre Formation attendu et Formation du CV: 0.7965\n",
      "Similarité entre Compétences attendu et Compétences du CV: 0.8096\n",
      "Similarité entre Experiences attendu et Experiences du CV: 0.5714\n",
      "{'titre': 'Currently seeking an internship in Data Science starting in March 2025 for a duration of 4 to 6 months.', 'disponibilite': 'March 2025'}\n",
      "{'titre': 'Data Scientist', 'disponibilite': None}\n",
      "Similarité entre Profil attendu et Profil du CV: 0.5046\n"
     ]
    }
   ],
   "source": [
    "# Similarité entre Formation attendu et Formation du CV\n",
    "formation_candidat = cv_json.get(\"Formation\")\n",
    "formation_attendu = job_offer_json.get(\"Formation\")\n",
    "\n",
    "similarite_formation = calculate_similarity(str(formation_candidat), str(formation_attendu))\n",
    "print(f\"Similarité entre Formation attendu et Formation du CV: {similarite_formation:.4f}\")\n",
    "\n",
    "\n",
    "# Similarité entre Compétences attendu et Compétences du CV\n",
    "competences_candidat = cv_json.get(\"Competences\")\n",
    "# print(competences_candidat)\n",
    "competences_attendu = job_offer_json.get(\"Competences\")\n",
    "# print(competences_attendu)\n",
    "\n",
    "similarite_competences = calculate_similarity(str(competences_candidat), str(competences_attendu))\n",
    "print(f\"Similarité entre Compétences attendu et Compétences du CV: {similarite_competences:.4f}\")\n",
    "\n",
    "\n",
    "# Similarité entre Experiences attendu et Experiences du CV\n",
    "experiences_candidat = cv_json.get(\"Experiences\")\n",
    "# print(experiences_candidat)\n",
    "experiences_attendu = job_offer_json.get(\"Experiences\")\n",
    "# print(experiences_attendu)\n",
    "\n",
    "similarite_experiences = calculate_similarity(str(experiences_candidat), str(experiences_attendu))\n",
    "print(f\"Similarité entre Experiences attendu et Experiences du CV: {similarite_experiences:.4f}\")\n",
    "\n",
    "\n",
    "# Similarité entre Profil attendu et Profil du CV\n",
    "profil_candidat = cv_json.get(\"Profil\")\n",
    "print(profil_candidat)\n",
    "profil_attendu = job_offer_json.get(\"Profil\")\n",
    "print(profil_attendu)\n",
    "\n",
    "similarite_profil = calculate_similarity(str(profil_candidat), str(profil_attendu))\n",
    "print(f\"Similarité entre Profil attendu et Profil du CV: {similarite_profil:.4f}\")\n",
    "\n",
    "###################### Voir si on ne peut pas faire mieux (check if any au lieu d'une simalarité globale) ######################\n",
    "### Au lieu d'installer sentence transformers, utiliser une API huggingface avec pipeline et requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_section_similarity(cv_reformule: str, offre_emploi_reformule: str) -> dict:\n",
    "    \"\"\"\n",
    "    Calcule les similarités détaillées entre les différentes sections d'un CV et une offre d'emploi.\n",
    "    \n",
    "    Args:\n",
    "        cv_reformule (str): Informations du CV au format JSON string\n",
    "        offre_emploi_reformule (str): Informations de l'offre d'emploi au format JSON string\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionnaire contenant les scores de similarité pour chaque section\n",
    "        \n",
    "    Exemple:\n",
    "        {\n",
    "            'formation': float,\n",
    "            'competences': float,\n",
    "            'experiences': float,\n",
    "            'profil': float,\n",
    "        }\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Conversion des chaînes JSON en dictionnaires\n",
    "        cv_json = json.loads(cv_reformule)\n",
    "        offre_emploi_json = json.loads(offre_emploi_reformule)\n",
    "        \n",
    "        # Calcul des similarités pour chaque section\n",
    "        similarites = {}\n",
    "        \n",
    "        # Similarité de formation\n",
    "        formation_candidat = cv_json.get(\"Formation\", \"\")\n",
    "        formation_attendue = offre_emploi_json.get(\"Formation\", \"\")\n",
    "        similarites['formation'] = calculate_similarity(\n",
    "            str(formation_candidat), \n",
    "            str(formation_attendue)\n",
    "        )\n",
    "        \n",
    "        # Similarité des compétences\n",
    "        competences_candidat = cv_json.get(\"Competences\", [])\n",
    "        competences_attendues = offre_emploi_json.get(\"Competences\", [])\n",
    "        similarites['competences'] = calculate_similarity(\n",
    "            str(competences_candidat), \n",
    "            str(competences_attendues)\n",
    "        )\n",
    "        \n",
    "        # Similarité des expériences\n",
    "        experiences_candidat = cv_json.get(\"Experiences\", [])\n",
    "        experiences_attendues = offre_emploi_json.get(\"Experiences\", [])\n",
    "        similarites['experiences'] = calculate_similarity(\n",
    "            str(experiences_candidat), \n",
    "            str(experiences_attendues)\n",
    "        )\n",
    "        \n",
    "        # Similarité du profil\n",
    "        profil_candidat = cv_json.get(\"Profil\", {})\n",
    "        profil_attendu = offre_emploi_json.get(\"Profil\", {})\n",
    "        similarites['profil'] = calculate_similarity(\n",
    "            str(profil_candidat), \n",
    "            str(profil_attendu)\n",
    "        )\n",
    "        \n",
    "        return similarites\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(f\"Erreur lors du parsing JSON : {str(e)}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Erreur lors du calcul des similarités : {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7964798257238572\n"
     ]
    }
   ],
   "source": [
    "calculate_section_similarity(CV_reformuler, job_offer_reforumer)\n",
    "\n",
    "print(calculate_section_similarity(CV_reformuler, job_offer_reforumer)['formation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création d'une lettre de motivation à partir du CV et de l'offre\n",
    "\n",
    "- Utilisation du CV brut car on a perdu des informations qu'on peut mettre en avant ici (bénévélot etc..)\n",
    "- Même chose pour l'offre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n  Titre : Data scientist (H/F) SALON TAF Toulouse 2025\\n  Entreprise : AOSIS CONSULTING\\n  Contrat : CDI\\n  Localisation : 31 - TOULOUSE\\n  Description :\\n  Concrètement qu'est-ce qu'on fait ?\\n  Nous proposons des Services, des Logiciels et de la Formation dans le domaine de la Business Intelligence, de la Data Science, de la Gouvernance et de la Visualisation de la donnée. L'Infrastructure et le Développement font également partie du panel de nos compétences.\\n  Notre leitmotiv ? Citoyenneté, écologie et sport avec des experts de la donnée.\\n  Notre objectif ? Porter encore plus haut et plus fort nos valeurs de sport, d'écologie et de citoyenneté et accompagner nos consultants dans leur montée en compétence.\\n\\n  Le poste\\n  Dans le cadre d'une ouverture de poste, nous sommes à la recherche d'un.e Data Scientist pour l'un de nos clients.\\n  Un.e data scientist senior (5 ans d'expérience) très autonome dans ses analyses et explorations, expérimenté dans l'industrialisation des modèles dans des environnements cloud.\\n\\n  Vous interviendrez sur toutes les étapes du projet, vous devrez :\\n\\n  Identifier leurs difficultés et proposer des solutions\\n  Evaluer la qualité des données, les nettoyer, les agréger, et mener des études adhoc\\n  Concevoir, implémenter et comparer différents algorithmes et méthodes statistiques\\n  Concevoir et mener des protocoles de test en conditions réelles (magasins, entrepôts, .)\\n  Développer des outils de visualisation des données\\n  Mettre en production, maintenir et itérer sur les solutions\\n\\n  Environnement technique: Python, SQL, Terraform, Bitbucket, Jenkins, Airflow, Docker, Kubernetes, GCP (BigQuery, Spark DataProc)\\n\\n  Profil recherché\\n  Vous êtes issu.e d'un Master en informatique ou mathématiques appliquées.\\n  Vous avez à minima 5 années d'expériences en Data Science et maitrisez les algorithmes d'apprentissage statistique.\\n  Vous maîtrisez Python et SQL\\n  Vous avez une expérience dans le développement logiciel agile avec multiples contributeurs\\n  Vous avez une expérience du cloud, idéalement GCP\\n\\n  Pourquoi nous rejoindre ?\\n  Parce que nous sommes une société à taille humaine\\n  Parce que nous nous engageons (réellement) dans des enjeux importants : l'écologie, la citoyenneté et le sport\\n  Mais aussi parce que nous aimons réaliser tout un tas d'activités : des jeux, des afterworks, des restaurants, ... et plein d'autres choses encore :)\\n\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM pour la lettre de motivation\n",
    "text_brut\n",
    "job_offer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_lettre_motivation = f\"\"\"\n",
    "Tu es un assistant qui rédige des lettres de motivation personnalisées et professionnelles. Voici les informations nécessaires :\n",
    "\n",
    "**Informations du candidat :**\n",
    "- Nom : Quentin Lim\n",
    "- Email : quentin@gmail.com\n",
    "- Téléphone : 0601020304\n",
    "- Adresse : 12 rue de la Paix, 75000 Paris\n",
    "- Date : 13/09/2025\n",
    "\n",
    "**Texte brut du CV :**\n",
    "{text_brut}\n",
    "\n",
    "**Offre d'emploi :**\n",
    "{job_offer}\n",
    "\n",
    "**Instructions :**\n",
    "1. Rédige une lettre de motivation au format A4, bien structurée et professionnelle.\n",
    "2. Mets en avant les compétences et expériences du candidat qui correspondent aux exigences du poste.\n",
    "3. Mentionne des éléments spécifiques de l'entreprise ou du poste pour montrer que la candidature est personnalisée.\n",
    "4. Explique pourquoi le candidat est motivé pour rejoindre cette entreprise en particulier.\n",
    "5. Utilise un ton professionnel et évite les phrases génériques.\n",
    "6. Ne laisse pas de champs vides et ne devine pas les informations manquantes.\n",
    "\n",
    "**Format de la lettre :**\n",
    "- En-tête : Nom, prénom, adresse, email, téléphone, date.\n",
    "- Introduction : Présentation du candidat et motivation pour le poste.\n",
    "- Corps : Compétences et expériences en lien avec le poste.\n",
    "- Conclusion : Expression de l'enthousiasme et disponibilité pour un entretien.\n",
    "\n",
    "**Exemple de structure :**\n",
    "[En-tête]\n",
    "Quentin Lim\n",
    "12 rue de la Paix, 75000 Paris\n",
    "quentin@gmail.com | 0601020304\n",
    "13/09/2025\n",
    "\n",
    "[Introduction]\n",
    "Madame, Monsieur,\n",
    "Je me permets de vous adresser ma candidature pour le poste de [poste] au sein de [entreprise]. [Motivation personnalisée].\n",
    "\n",
    "[Corps]\n",
    "Avec mon expérience en [domaine] et mes compétences en [compétences], je suis convaincu de pouvoir contribuer à [objectif de l'entreprise]. [Détail des expériences et compétences pertinentes].\n",
    "\n",
    "[Conclusion]\n",
    "Je serais ravi de discuter de ma candidature lors d'un entretien. Je reste à votre disposition pour toute information complémentaire.\n",
    "\n",
    "Veuillez agréer, Madame, Monsieur, mes salutations distinguées.\n",
    "Quentin Lim\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Lettre_motiv_genere = litellm.completion(\n",
    "            model=\"mistral/ministral-3b-latest\",  \n",
    "            messages=[{\"role\": \"user\", \"content\": prompt_lettre_motivation}],\n",
    "            max_tokens=1500,\n",
    "            temperature=0.3,\n",
    "            api_key=os.getenv(\"MISTRAL_API_KEY\"),\n",
    "        )\n",
    "\n",
    "resultat = Lettre_motiv_genere[\"choices\"][0][\"message\"][\n",
    "            \"content\"\n",
    "        ].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Votre Nom]\n",
      "[Votre Adresse]\n",
      "[Code Postal, Ville]\n",
      "[Votre Email]\n",
      "[Votre Téléphone]\n",
      "[Date]\n",
      "\n",
      "AOSIS CONSULTING\n",
      "[Adresse de l'entreprise]\n",
      "[Code Postal, Ville]\n",
      "\n",
      "Objet : Candidature au poste de Data Scientist\n",
      "\n",
      "Madame, Monsieur,\n",
      "\n",
      "Je me permets de vous adresser ma candidature pour le poste de Data Scientist au sein de votre entreprise, tel que décrit dans votre offre d'emploi. Fort de mon parcours académique et professionnel en Data Science, je suis convaincu que mes compétences et mon expérience correspondent parfaitement aux exigences de ce poste.\n",
      "\n",
      "Actuellement étudiant en Master en Data Science à l'Université Lyon 2 Lumière, j'ai acquis une solide expertise en analyse avancée de données, en Big Data et en MLOps. Mon parcours académique m'a permis de développer des compétences en ANOVA, en séries temporelles, en biostatistiques, en NLP/LLM, en vision par ordinateur et en apprentissage profond. J'ai également une expérience significative en predictive analytics, utilisant des modèles statistiques avancés et des algorithmes d'apprentissage automatique pour la prévision et la prise de décision.\n",
      "\n",
      "Mon expérience professionnelle m'a permis de travailler sur divers projets innovants. Par exemple, j'ai développé un package de régression logistique en Python, ce qui m'a permis de tester et d'optimiser différents optimisateurs et techniques de régularisation. J'ai également mené une analyse NLP de critiques de TripAdvisor, utilisant des techniques de scraping, d'analyse de sentiment et de clustering pour agréguer les commentaires. Ces projets m'ont permis de développer des compétences en développement logiciel agile et en gestion de projets, tout en utilisant des outils comme Docker et Jenkins.\n",
      "\n",
      "Je suis particulièrement attiré par AOSIS CONSULTING en raison de votre engagement envers des enjeux sociaux et environnementaux tels que l'écologie, la citoyenneté et le sport. Ces valeurs sont en parfaite alignement avec mes propres convictions et aspirations professionnelles. De plus, votre approche collaborative et votre engagement envers la formation et le développement des compétences de vos consultants sont des éléments qui me motivent à rejoindre votre équipe.\n",
      "\n",
      "Je suis également très enthousiaste à l'idée de travailler dans un environnement technique riche et diversifié, utilisant des outils tels que Python, SQL, Terraform, Bitbucket, Jenkins, Airflow, Docker, Kubernetes et GCP. Mon expérience avec ces technologies et ma capacité à les intégrer dans des projets complexes me permettent de contribuer efficacement à vos projets.\n",
      "\n",
      "Je suis convaincu que mon profil et mes compétences correspondent parfaitement aux attentes de votre entreprise. Je serais ravi de pouvoir discuter plus en détail de ma candidature lors d'un entretien. Je vous remercie par avance pour l'attention que vous porterez à ma demande et je reste à votre disposition pour toute information complémentaire.\n",
      "\n",
      "Dans l'attente de votre réponse, je vous prie d'agréer, Madame, Monsieur, l'expression de mes salutations distinguées.\n",
      "\n",
      "Quentin Lim\n",
      "[Votre Adresse]\n",
      "[Code Postal, Ville]\n",
      "[Votre Email]\n",
      "[Votre Téléphone]\n",
      "[Date]\n"
     ]
    }
   ],
   "source": [
    "print(resultat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "challengeIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
