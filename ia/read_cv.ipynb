{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read PDF\n",
    "\n",
    "# from dotenv import load_dotenv\n",
    "# Charger les variables d'environnement\n",
    "# load_dotenv()\n",
    "# Faire lettre motivation automatique\n",
    "from datetime import datetime\n",
    "import locale\n",
    "\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvironmentMetrics:\n",
    "    \"\"\"Classe pour gérer les métriques environnementales\"\"\"\n",
    "    def __init__(self):\n",
    "        self.gwp = 0.0\n",
    "        self.energy_usage = 0.0\n",
    "    \n",
    "    def update_metrics(self, new_gwp: float, new_energy: float):\n",
    "        \"\"\"Met à jour les métriques environnementales\"\"\"\n",
    "        self.gwp += new_gwp\n",
    "        self.energy_usage += new_energy\n",
    "    \n",
    "    def reset_metrics(self):\n",
    "        \"\"\"Réinitialise les métriques\"\"\"\n",
    "        self.gwp = 0.0\n",
    "        self.energy_usage = 0.0\n",
    "\n",
    "    def get_metrics(self):\n",
    "        \"\"\"Renvoie les métriques\"\"\"\n",
    "        return self.gwp, self.energy_usage\n",
    "\n",
    "# Créer une instance unique\n",
    "monitoring_environnement = EnvironmentMetrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def read_pdf(file_path: str) -> str:\n",
    "    \"\"\"Lit et extrait le texte d'un CV au format PDF d'une seule page.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Chemin d'accès vers le fichier PDF à lire\n",
    "\n",
    "    Returns:\n",
    "        str: Texte brut extrait du PDF\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: Si le fichier PDF n'existe pas\n",
    "        IndexError: Si le PDF est vide\n",
    "        Exception: Pour toute autre erreur lors de la lecture du PDF\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reader = PdfReader(file_path)\n",
    "        if len(reader.pages) == 0:\n",
    "            raise IndexError(\"Le PDF est vide\")\n",
    "        \n",
    "        page = reader.pages[0]  # Lecture de la première page uniquement\n",
    "        text_brut = page.extract_text()\n",
    "        \n",
    "        if not text_brut:\n",
    "            raise Exception(\"Aucun texte n'a pu être extrait du PDF\")\n",
    "            \n",
    "        return text_brut\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Le fichier {file_path} n'existe pas\")\n",
    "    except IndexError as e:\n",
    "        raise IndexError(str(e))\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Erreur lors de la lecture du PDF: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edina Adjaro \n",
      "Patoussi\n",
      "Étudiant en dernière \n",
      "année de Data Science\n",
      "adjaropatoussi@gmail.com\n",
      "0753234875\n",
      "lyon, France\n",
      "Profil\n",
      "Actuellement à la recherche d'un stage \n",
      "en Data Science à partir de mars 2025 \n",
      "pour une durée de 4 à 6 mois.\n",
      "Compétences\n",
      "ML, NLP, TensorFlow; Scikit-learn, \n",
      "MLFlow, Transformers, LLM, Time Series.\n",
      "SQL, NoSQL, MongoDB\n",
      "Qlik, Tableau, PowerBI\n",
      "OpenCV, YOLO\n",
      "Azure, AWS, Fabric\n",
      "Git,Agile methodology\n",
      "Python, R, Java, PySpark, JavaScript, \n",
      "PHP\n",
      "Soft Skills\n",
      "Travail d'équipe, Communication, \n",
      "Adaptabilité, Résolution de problèmes,  \n",
      "Créativité\n",
      "Centres d'Intérêt\n",
      "Bénévolat — Parrainage avec Alter-ego\n",
      "Lyon 2\n",
      "Sports: — football (travail d'équipe et\n",
      "prise de décision rapide).\n",
      "Jeux de société — échecs et passionné\n",
      "de jeux de stratégie.\n",
      "Langues\n",
      "Français\n",
      "AnglaisFormation Académique\n",
      "Master en Data Science, Université Lyon 2 Lumière\n",
      "09/2023 – aujourd'hui | lyon, France\n",
      "•Expertise en analyse de données avancée : ANOVA, séries \n",
      "temporelles, biostatistiques, NLP/LLM, Vision par ordinateur.\n",
      "•Maîtrise du Big Data et des MLOps : web scraping, entrepôts de \n",
      "données, déploiement de modèles et pipelines.\n",
      "•Spécialisation en analyse prédictive, avec un accent sur l'utilisation \n",
      "de modèles statistiques avancés et d'algorithmes de machine \n",
      "learning pour la prévision et la prise de décision.\n",
      "Master 1 en Intelligence Artificielle et Big Data, \n",
      "École Polytechnique de Lomé et UTBM\n",
      "10/2022 – 08/2023 | Lome, Togo\n",
      "• Compétences en développement et ingénierie des données : \n",
      "Programmation orientée objet avec Python, Ingénierie des données, \n",
      "Bases de données avancées, BU.\n",
      "• Maîtrise des techniques d'analyse et de modélisation : Apprentissage \n",
      "supervisé, SAS, Complexité algorithmique.\n",
      "Expérience Professionnelle\n",
      "Stage Data Scientist, Laboratoire LIRIS\n",
      "04/2024 – 08/2024 | Lyon, France\n",
      "•Vision par ordinateur : Detectron 2, annotation de données, \n",
      "augmentation de données.\n",
      "•Reconnaissance de textes : Expérimentation avec des outils \n",
      "OLR/OCR.\n",
      "•Analyse de données : Évaluation des performances des modèles, \n",
      "reporting technique.\n",
      "•Collaboration : Travail en équipe avec des chercheurs et des \n",
      "ingénieurs en IA.\n",
      "Développeur Web et Mobile, IT Innovation\n",
      "•Développement mobile et web\n",
      "•Visualisation de données : Tableaux de bord avec Chart.js.\n",
      "•Gestion de bases de données : Conception et optimisation de bases \n",
      "de données, requêtes complexes.\n",
      "•Collaboration : Travail en équipe avec des designers  \n",
      "Projets\n",
      "Création d'un package R de régression logistique\n",
      "•Package de régression logistique développé from scratch : \n",
      "Implémentation de divers optimiseurs et application de techniques \n",
      "de régularisation.\n",
      "•Tests réussis sur des tâches de classification : Atteint jusqu'à 90% \n",
      "de précision sur les datasets StudentPerformance.\n",
      "Projet d'analyse NLP des avis TripAdvisor\n",
      "•Web scraping : Collecte de données avec BeautifulSoup.\n",
      "•Analyse de sentiments : Clustering des commentaires et \n",
      "visualisation des résultats.\n",
      "•Application End-to-End : Intégration d'une base de données SQLite \n",
      "et création d'une application Streamlit déployée via Docker.\n",
      "•Synthèse automatisée : Utilisation d'un LLM avec RAG pour résumer \n",
      "efficacement les avis utilisateurs.\n",
      "Certifications\n",
      "Associate Data Scientist in Python  — DATACAMP\n",
      "Back-End Engineering  — Lyft, Forage\n",
      " — Langue Maternelle/Bilingue\n",
      " — Intermédiaire\n",
      "|\n",
      "<class 'str'>\n",
      "3285\n"
     ]
    }
   ],
   "source": [
    "# reader = PdfReader(\"CV_V4_EN.pdf\")\n",
    "reader = PdfReader(\"Edina-Adjaro-Patoussi-Resume.pdf\")\n",
    "page = reader.pages[0] # 1 seule page\n",
    "text_brut = page.extract_text()\n",
    "print(text_brut)\n",
    "print(type(text_brut))\n",
    "print(len(text_brut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(read_pdf(\"CV_V4_EN.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Mistral Mini -> Reformulation Texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Formulation du prompt (CV texte brut + )\n",
    "# Ajouter les suivis de prix + impact ecologique ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import litellm\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA partir d\\'un texte brut venant d\\'un CV, extrait les informations suivantes au format JSON :\\n{\\n    \"Diplome\": [\\n      {\\n          \"niveau_etudes\": \"int\",\\n          \"domaine_etudes\": [\"str\"]\\n      }\\n    ],\\n\\n    \"Competences\": [\"str\"],\\n    \"Experiences\": [\\n        {\\n            \"domaine_activite\": [\"str\"],\\n            \"poste_occupe\": \"str\",\\n            \"duree\": \"int\"\\n        }\\n    ],\\n    \"Profil\": {\\n        \"titre\": \"str\",\\n        \"disponibilite\": \"str\"\\n    }\\n}\\n\\nTexte du CV :\\n\"Edina Adjaro \\nPatoussi\\nÉtudiant en dernière \\nannée de Data Science\\nadjaropatoussi@gmail.com\\n0753234875\\nlyon, France\\nProfil\\nActuellement à la recherche d\\'un stage \\nen Data Science à partir de mars 2025 \\npour une durée de 4 à 6 mois.\\nCompétences\\nML, NLP, TensorFlow; Scikit-learn, \\nMLFlow, Transformers, LLM, Time Series.\\nSQL, NoSQL, MongoDB\\nQlik, Tableau, PowerBI\\nOpenCV, YOLO\\nAzure, AWS, Fabric\\nGit,Agile methodology\\nPython, R, Java, PySpark, JavaScript, \\nPHP\\nSoft Skills\\nTravail d\\'équipe, Communication, \\nAdaptabilité, Résolution de problèmes,  \\nCréativité\\nCentres d\\'Intérêt\\nBénévolat — Parrainage avec Alter-ego\\nLyon 2\\nSports: — football (travail d\\'équipe et\\nprise de décision rapide).\\nJeux de société — échecs et passionné\\nde jeux de stratégie.\\nLangues\\nFrançais\\nAnglaisFormation Académique\\nMaster en Data Science, Université Lyon 2 Lumière\\n09/2023 – aujourd\\'hui | lyon, France\\n•Expertise en analyse de données avancée : ANOVA, séries \\ntemporelles, biostatistiques, NLP/LLM, Vision par ordinateur.\\n•Maîtrise du Big Data et des MLOps : web scraping, entrepôts de \\ndonnées, déploiement de modèles et pipelines.\\n•Spécialisation en analyse prédictive, avec un accent sur l\\'utilisation \\nde modèles statistiques avancés et d\\'algorithmes de machine \\nlearning pour la prévision et la prise de décision.\\nMaster 1 en Intelligence Artificielle et Big Data, \\nÉcole Polytechnique de Lomé et UTBM\\n10/2022 – 08/2023 | Lome, Togo\\n• Compétences en développement et ingénierie des données : \\nProgrammation orientée objet avec Python, Ingénierie des données, \\nBases de données avancées, BU.\\n• Maîtrise des techniques d\\'analyse et de modélisation : Apprentissage \\nsupervisé, SAS, Complexité algorithmique.\\nExpérience Professionnelle\\nStage Data Scientist, Laboratoire LIRIS\\n04/2024 – 08/2024 | Lyon, France\\n•Vision par ordinateur : Detectron 2, annotation de données, \\naugmentation de données.\\n•Reconnaissance de textes : Expérimentation avec des outils \\nOLR/OCR.\\n•Analyse de données : Évaluation des performances des modèles, \\nreporting technique.\\n•Collaboration : Travail en équipe avec des chercheurs et des \\ningénieurs en IA.\\nDéveloppeur Web et Mobile, IT Innovation\\n•Développement mobile et web\\n•Visualisation de données : Tableaux de bord avec Chart.js.\\n•Gestion de bases de données : Conception et optimisation de bases \\nde données, requêtes complexes.\\n•Collaboration : Travail en équipe avec des designers  \\nProjets\\nCréation d\\'un package R de régression logistique\\n•Package de régression logistique développé from scratch : \\nImplémentation de divers optimiseurs et application de techniques \\nde régularisation.\\n•Tests réussis sur des tâches de classification : Atteint jusqu\\'à 90% \\nde précision sur les datasets StudentPerformance.\\nProjet d\\'analyse NLP des avis TripAdvisor\\n•Web scraping : Collecte de données avec BeautifulSoup.\\n•Analyse de sentiments : Clustering des commentaires et \\nvisualisation des résultats.\\n•Application End-to-End : Intégration d\\'une base de données SQLite \\net création d\\'une application Streamlit déployée via Docker.\\n•Synthèse automatisée : Utilisation d\\'un LLM avec RAG pour résumer \\nefficacement les avis utilisateurs.\\nCertifications\\nAssociate Data Scientist in Python  — DATACAMP\\nBack-End Engineering  — Lyft, Forage\\n — Langue Maternelle/Bilingue\\n — Intermédiaire\\n|\"\\n\\nNe retourne que le JSON\\n'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reformulation_prompt = f\"\"\"\n",
    "A partir d'un texte brut venant d'un CV, extrait les informations suivantes au format JSON :\n",
    "{{\n",
    "    \"Diplome\": [\n",
    "      {{\n",
    "          \"niveau_etudes\": \"int\",\n",
    "          \"domaine_etudes\": [\"str\"]\n",
    "      }}\n",
    "    ],\n",
    "\n",
    "    \"Competences\": [\"str\"],\n",
    "    \"Experiences\": [\n",
    "        {{\n",
    "            \"domaine_activite\": [\"str\"],\n",
    "            \"poste_occupe\": \"str\",\n",
    "            \"duree\": \"int\"\n",
    "        }}\n",
    "    ],\n",
    "    \"Profil\": {{\n",
    "        \"titre\": \"str\",\n",
    "        \"disponibilite\": \"str\"\n",
    "    }}\n",
    "}}\n",
    "\n",
    "Texte du CV :\n",
    "\"{text_brut}\"\n",
    "\n",
    "Ne retourne que le JSON\n",
    "\"\"\"\n",
    "reformulation_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification de la clé API\n",
    "#  api_key=os.getenv(\"MISTRAL_API_KEY\")\n",
    "# api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# litellm._turn_on_debug()\n",
    "# Température, plus c'est proche de 1, plus c'est créatif\n",
    "# On cherche à savoir combien de token on devrait mettre\n",
    "\n",
    "CV_reformuler = litellm.completion(\n",
    "            model=\"mistral/ministral-3b-latest\",  # Choix d'un modèle petit\n",
    "            messages=[{\"role\": \"user\", \"content\": reformulation_prompt}],\n",
    "            max_tokens=1500,\n",
    "            temperature=0.3,\n",
    "            api_key=os.getenv(\"MISTRAL_API_KEY\"),\n",
    "        )\n",
    "\n",
    "resultat = CV_reformuler[\"choices\"][0][\"message\"][\n",
    "            \"content\"\n",
    "        ].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Diplome\": [\n",
      "        {\n",
      "            \"niveau_etudes\": \"Master\",\n",
      "            \"domaine_etudes\": [\"Data Science\"]\n",
      "        }\n",
      "    ],\n",
      "    \"Competences\": [\n",
      "        \"ML\", \"NLP\", \"TensorFlow\", \"Scikit-learn\", \"MLFlow\", \"Transformers\", \"LLM\", \"Time Series\",\n",
      "        \"SQL\", \"NoSQL\", \"MongoDB\", \"Qlik\", \"Tableau\", \"PowerBI\", \"OpenCV\", \"YOLO\", \"Azure\", \"AWS\", \"Fabric\",\n",
      "        \"Git\", \"Agile methodology\", \"Python\", \"R\", \"Java\", \"PySpark\", \"JavaScript\", \"PHP\"\n",
      "    ],\n",
      "    \"Experiences\": [\n",
      "        {\n",
      "            \"domaine_activite\": [\"Data Science\"],\n",
      "            \"poste_occupe\": \"Stage Data Scientist\",\n",
      "            \"duree\": 4\n",
      "        },\n",
      "        {\n",
      "            \"domaine_activite\": [\"Développement Web et Mobile\"],\n",
      "            \"poste_occupe\": \"Développeur Web et Mobile\",\n",
      "            \"duree\": 0\n",
      "        }\n",
      "    ],\n",
      "    \"Profil\": {\n",
      "        \"titre\": \"Étudiant en dernière année de Data Science\",\n",
      "        \"disponibilite\": \"Actuellement à la recherche d'un stage en Data Science à partir de mars 2025 pour une durée de 4 à 6 mois.\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "1029\n"
     ]
    }
   ],
   "source": [
    "# Le CV fait 4231 en len\n",
    "# len de 1863 pour 500 max tokens\n",
    "# len de 4429 pour 1500 max tokens -> C'est OK, on essaye avec 1000 max tokens\n",
    "print(resultat)\n",
    "print(len(resultat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ecologits import EcoLogits\n",
    "EcoLogits.init(providers=\"litellm\", electricity_mix_zone=\"FRA\") # Require un pip install rapidfuzz\n",
    "\n",
    "def get_price_query(\n",
    "        model: str, input_token: int, output_token: int\n",
    "    ) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the price for the query based on the model and token usage.\n",
    "\n",
    "    Args:\n",
    "        model (str): The model name for which to calculate the cost.\n",
    "        input_token (int): The number of input tokens used.\n",
    "        output_token (int): The number of output tokens used.\n",
    "\n",
    "    Returns:\n",
    "        float: The total cost for the query based on token usage.\n",
    "    \"\"\"\n",
    "    dict_price = {\n",
    "        \"ministral-8b-latest\": {\"input\": 0.10, \"output\": 0.10},\n",
    "        \"ministral-3b-latest\": {\"input\": 0.04, \"output\": 0.04},\n",
    "        \"codestral-latest\": {\"input\": 0.20, \"output\": 0.60},\n",
    "        \"mistral-large-latest\": {\"input\": 2, \"output\": 6},\n",
    "    }\n",
    "    price = dict_price[model]\n",
    "    return ((price[\"input\"] / 10**6) * input_token) + (\n",
    "        (price[\"output\"] / 10**6) * output_token\n",
    "    )\n",
    "\n",
    "\n",
    "# Exemple d'utilisation\n",
    "# reformulation_response = litellm.completion(\n",
    "#     model=\"mistral/ministral-3b-latest\",  # Choix d'un modèle petit\n",
    "#     messages=[{\"role\": \"user\", \"content\": reformulation_prompt}],\n",
    "#     max_tokens=50,\n",
    "#     temperature=1.0,\n",
    "#     api_key=os.getenv(\"MISTRAL_API_KEY\"),\n",
    "# )\n",
    "# input_tokens = int(\n",
    "#     reformulation_response[\"usage\"][\"prompt_tokens\"]\n",
    "# )  # Entry tokens\n",
    "# output_tokens = int(\n",
    "#     reformulation_response[\"usage\"][\"completion_tokens\"]\n",
    "# )  # Output tokens\n",
    "\n",
    "# # Cost calculation\n",
    "# dollar_cost = self._get_price_query(\n",
    "#     model=\"ministral-3b-latest\",  # Small model\n",
    "#     input_token=input_tokens,\n",
    "#     output_token=output_tokens,\n",
    "# )\n",
    "\n",
    "\n",
    "def get_energy_usage(response: litellm.ModelResponse):\n",
    "    \"\"\"\n",
    "    Extracts energy usage and global warming potential (GWP) from the response.\n",
    "\n",
    "    Parameters:\n",
    "        response (litellm.ModelResponse): The model response containing impact data.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple (energy_usage, gwp) if impacts are present, otherwise (None, None).\n",
    "    \"\"\"\n",
    "    if hasattr(response, \"impacts\"):\n",
    "        try:\n",
    "            energy_usage = getattr(\n",
    "                response.impacts.energy.value, \"min\", response.impacts.energy.value\n",
    "            )\n",
    "        except AttributeError:\n",
    "            energy_usage = None\n",
    "\n",
    "        try:\n",
    "            gwp = getattr(\n",
    "                response.impacts.gwp.value, \"min\", response.impacts.gwp.value\n",
    "            )\n",
    "        except AttributeError:\n",
    "            gwp = None\n",
    "\n",
    "        return energy_usage, gwp\n",
    "\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_cv(text_brut: str, temperature: float = 0.01, max_tokens: int = 1500) -> str:\n",
    "    \"\"\"\n",
    "    Analyse un CV en format texte et retourne les informations structurées en JSON.\n",
    "\n",
    "    Args:\n",
    "        text_brut (str): Texte brut du CV à analyser\n",
    "        temperature (float, optional): Paramètre de créativité du modèle. Defaults to 0.2.\n",
    "        max_tokens (int, optional): Nombre maximum de tokens pour la réponse. Defaults to 1500.\n",
    "\n",
    "    Returns:\n",
    "        str: Informations en string(réponse du LLM) structurées du CV au format JSON\n",
    "\n",
    "    Raises:\n",
    "        Exception: En cas d'erreur d'API ou de parsing JSON\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reformulation_prompt = f\"\"\"\n",
    "        À partir du texte brut d'un CV, extrais les informations suivantes au format JSON. \n",
    "        Si une information n'est pas explicitement mentionnée dans le texte, retourne `null` ou une liste vide.\n",
    "        Ne devine pas les informations manquantes et ne retourne que ce qui est clairement présent dans le texte.\n",
    "\n",
    "        Format JSON attendu :\n",
    "        {{\n",
    "            \"Formation\": [\n",
    "                {{\n",
    "                    \"niveau_etudes\": \"str\",  // Ex: \"Licence\", \"Master\", \"Doctorat\"\n",
    "                    \"domaine_etudes\": [\"str\"]  // Ex: [\"Informatique\", \"Mathématiques\"]\n",
    "                }}\n",
    "            ],\n",
    "            \"Competences\": [\"str\"],  // Ex: [\"Python\", \"Gestion de projet\"]\n",
    "            \"Experiences\": [\n",
    "                {{\n",
    "                    \"domaine_activite\": [\"str\"],  // Ex: [\"Tech\", \"Finance\"]\n",
    "                    \"poste_occupe\": \"str\",  // Ex: \"Développeur Python\"\n",
    "                    \"duree\": \"str\"  // Ex: \"2 ans\"\n",
    "                }}\n",
    "            ],\n",
    "            \"Profil\": {{\n",
    "                \"titre\": \"str\",  // Ex: \"Développeur Full-Stack\"\n",
    "                \"disponibilite\": \"str\"  // Ex: \"dd-mm-yyyy\"\n",
    "            }}\n",
    "        }}\n",
    "\n",
    "        Texte du CV :\n",
    "        \"{text_brut}\"\n",
    "\n",
    "        Ne retourne que le JSON, sans commentaires supplémentaires.\n",
    "        \"\"\"\n",
    "\n",
    "        response = litellm.completion(\n",
    "            model=\"mistral/mistral-medium\",\n",
    "            messages=[{\"role\": \"user\", \"content\": reformulation_prompt}],\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            api_key=os.getenv(\"MISTRAL_API_KEY\"),\n",
    "        )\n",
    "\n",
    "        # Extraire et parser le JSON de la réponse\n",
    "        resultat = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "        # Impact écologique\n",
    "        energy_usage, gwp = get_energy_usage(response=response)\n",
    "        \n",
    "        monitoring_environnement.update_metrics(new_gwp=gwp, new_energy=energy_usage)\n",
    "\n",
    "        # Ajout à une variable globale pour utilisation ultérieure ?\n",
    "\n",
    "        return resultat\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Erreur lors de l'analyse du CV: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Formation\": [\n",
      "    {\n",
      "      \"niveau_etudes\": \"Master\",\n",
      "      \"domaine_etudes\": [\"Data Science\"]\n",
      "    },\n",
      "    {\n",
      "      \"niveau_etudes\": \"Master 1\",\n",
      "      \"domaine_etudes\": [\"Intelligence Artificielle\", \"Big Data\"]\n",
      "    }\n",
      "  ],\n",
      "  \"Competences\": [\n",
      "    \"ML\",\n",
      "    \"NLP\",\n",
      "    \"TensorFlow\",\n",
      "    \"Scikit-learn\",\n",
      "    \"MLFlow\",\n",
      "    \"Transformers\",\n",
      "    \"LLM\",\n",
      "    \"Time Series\",\n",
      "    \"SQL\",\n",
      "    \"NoSQL\",\n",
      "    \"MongoDB\",\n",
      "    \"Qlik\",\n",
      "    \"Tableau\",\n",
      "    \"PowerBI\",\n",
      "    \"OpenCV\",\n",
      "    \"YOLO\",\n",
      "    \"Azure\",\n",
      "    \"AWS\",\n",
      "    \"Fabric\",\n",
      "    \"Git\",\n",
      "    \"Agile methodology\",\n",
      "    \"Python\",\n",
      "    \"R\",\n",
      "    \"Java\",\n",
      "    \"PySpark\",\n",
      "    \"JavaScript\",\n",
      "    \"PHP\"\n",
      "  ],\n",
      "  \"Experiences\": [\n",
      "    {\n",
      "      \"domaine_activite\": [\"Data Science\"],\n",
      "      \"poste_occupe\": \"Stage Data Scientist\",\n",
      "      \"duree\": \"4 mois\"\n",
      "    },\n",
      "    {\n",
      "      \"domaine_activite\": [\"Développement mobile et web\"],\n",
      "      \"poste_occupe\": \"Développeur Web et Mobile\",\n",
      "      \"duree\": null\n",
      "    }\n",
      "  ],\n",
      "  \"Profil\": {\n",
      "    \"titre\": \"Actuellement à la recherche d'un stage en Data Science\",\n",
      "    \"disponibilite\": \"mars 2025\"\n",
      "  }\n",
      "}\n",
      "(0.0003331530941562366, 0.0037102118966686488)\n"
     ]
    }
   ],
   "source": [
    "CV_reformuler = analyze_cv(text_brut)\n",
    "print(CV_reformuler)\n",
    "print(monitoring_environnement.get_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matching CV et offre :\n",
    "\n",
    "- Obtention du string job offer par le scrapping\n",
    "- Transformation via un LLM de l'offre à un format similaire au CV_reformuler\n",
    "- Embedding + calcul de la similarité cosinus globale\n",
    "- Transformation en JSON du CV_reformuler et job_offer_reforumuler pour pouvoir effectuer une similarité par partie(clef communes car passé tout les deux par un LLM)\n",
    "- Calcul des similarité par parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Example job offer\n",
    "job_offer = \"\"\"\n",
    "  Titre : Data scientist (H/F) SALON TAF Toulouse 2025\n",
    "  Entreprise : AOSIS CONSULTING\n",
    "  Contrat : CDI\n",
    "  Localisation : 31 - TOULOUSE\n",
    "  Description :\n",
    "  Concrètement qu'est-ce qu'on fait ?\n",
    "  Nous proposons des Services, des Logiciels et de la Formation dans le domaine de la Business Intelligence, de la Data Science, de la Gouvernance et de la Visualisation de la donnée. L'Infrastructure et le Développement font également partie du panel de nos compétences.\n",
    "  Notre leitmotiv ? Citoyenneté, écologie et sport avec des experts de la donnée.\n",
    "  Notre objectif ? Porter encore plus haut et plus fort nos valeurs de sport, d'écologie et de citoyenneté et accompagner nos consultants dans leur montée en compétence.\n",
    "\n",
    "  Le poste\n",
    "  Dans le cadre d'une ouverture de poste, nous sommes à la recherche d'un.e Data Scientist pour l'un de nos clients.\n",
    "  Un.e data scientist senior (5 ans d'expérience) très autonome dans ses analyses et explorations, expérimenté dans l'industrialisation des modèles dans des environnements cloud.\n",
    "\n",
    "  Vous interviendrez sur toutes les étapes du projet, vous devrez :\n",
    "\n",
    "  Identifier leurs difficultés et proposer des solutions\n",
    "  Evaluer la qualité des données, les nettoyer, les agréger, et mener des études adhoc\n",
    "  Concevoir, implémenter et comparer différents algorithmes et méthodes statistiques\n",
    "  Concevoir et mener des protocoles de test en conditions réelles (magasins, entrepôts, .)\n",
    "  Développer des outils de visualisation des données\n",
    "  Mettre en production, maintenir et itérer sur les solutions\n",
    "\n",
    "  Environnement technique: Python, SQL, Terraform, Bitbucket, Jenkins, Airflow, Docker, Kubernetes, GCP (BigQuery, Spark DataProc)\n",
    "\n",
    "  Profil recherché\n",
    "  Vous êtes issu.e d'un Master en informatique ou mathématiques appliquées.\n",
    "  Vous avez à minima 5 années d'expériences en Data Science et maitrisez les algorithmes d'apprentissage statistique.\n",
    "  Vous maîtrisez Python et SQL\n",
    "  Vous avez une expérience dans le développement logiciel agile avec multiples contributeurs\n",
    "  Vous avez une expérience du cloud, idéalement GCP\n",
    "\n",
    "  Pourquoi nous rejoindre ?\n",
    "  Parce que nous sommes une société à taille humaine\n",
    "  Parce que nous nous engageons (réellement) dans des enjeux importants : l'écologie, la citoyenneté et le sport\n",
    "  Mais aussi parce que nous aimons réaliser tout un tas d'activités : des jeux, des afterworks, des restaurants, ... et plein d'autres choses encore :)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reformulation de l'offre d'emploi :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Transformation de l'offre d'emploi au même format que le CV\n",
    "def analyze_offre_emploi(offre: str, temperature: float = 0.01, max_tokens: int = 1500) -> str:\n",
    "    \"\"\"\n",
    "    Analyse une offre d'emploi en format texte et retourne les informations structurées en JSON.\n",
    "\n",
    "    Args:\n",
    "        text_brut (str): Texte brut del'offre à analyser\n",
    "        temperature (float, optional): Paramètre de créativité du modèle. Defaults to 0.2.\n",
    "        max_tokens (int, optional): Nombre maximum de tokens pour la réponse. Defaults to 1500.\n",
    "\n",
    "    Returns:\n",
    "        str: Informations en string(réponse du LLM) structurées du CV au format JSON\n",
    "\n",
    "    Raises:\n",
    "        Exception: En cas d'erreur d'API ou de parsing JSON\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reformulation_prompt = f\"\"\"\n",
    "        À partir de cette offre d'emploi, extrais les informations suivantes au format JSON. \n",
    "        Si une information n'est pas explicitement mentionnée dans le texte, retourne `null` ou une liste vide.\n",
    "        De plus la disponibilité correspond à la date de début du poste.\n",
    "        Ne devine pas les informations manquantes et ne retourne que ce qui est clairement présent dans le texte.\n",
    "        \n",
    "        Format JSON attendu :\n",
    "        {{\n",
    "            \"Formation\": [\n",
    "                {{\n",
    "                    \"niveau_etudes\": \"str\",  // Ex: \"Licence\", \"Master\", \"Doctorat\"\n",
    "                    \"domaine_etudes\": [\"str\"]  // Ex: [\"Informatique\", \"Mathématiques\"]\n",
    "                }}\n",
    "            ],\n",
    "            \"Competences\": [\"str\"],  // Ex: [\"Python\", \"Gestion de projet\"]\n",
    "            \"Experiences\": [\n",
    "                {{\n",
    "                    \"domaine_activite\": [\"str\"],  // Ex: [\"Tech\", \"Finance\"]\n",
    "                    \"poste_occupe\": \"str\",  // Ex: \"Développeur Python\"\n",
    "                    \"duree\": \"str\"  // Ex: \"2 ans\"\n",
    "                }}\n",
    "            ],\n",
    "            \"Profil\": {{\n",
    "                \"titre\": \"str\",  // Ex: \"Développeur Full-Stack\"\n",
    "                \"disponibilite\": \"str\"  // Ex: \"dd-mm-yyyy\"\n",
    "            }}\n",
    "        }}\n",
    "\n",
    "        Texte de l'offre d'emploi :\n",
    "        \"{offre}\"\n",
    "\n",
    "        Ne retourne que le JSON, sans commentaires supplémentaires.\n",
    "        \"\"\"\n",
    "\n",
    "        offre_reformuler = litellm.completion(\n",
    "            model=\"mistral/mistral-medium\",\n",
    "            messages=[{\"role\": \"user\", \"content\": reformulation_prompt}],\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            api_key=os.getenv(\"MISTRAL_API_KEY\"),\n",
    "        )\n",
    "\n",
    "        # Extraire et parser le JSON de la réponse\n",
    "        resultat = offre_reformuler[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "        # Impact écologique\n",
    "        energy_usage, gwp = get_energy_usage(response=offre_reformuler)\n",
    "        monitoring_environnement.update_metrics(new_gwp=gwp, new_energy=energy_usage)\n",
    "\n",
    "        return resultat\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Erreur lors de l'analyse du CV: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Formation\": [\n",
      "    {\n",
      "      \"niveau_etudes\": \"Master\",\n",
      "      \"domaine_etudes\": [\"Informatique\", \"Mathématiques appliquées\"]\n",
      "    }\n",
      "  ],\n",
      "  \"Competences\": [\n",
      "    \"Python\",\n",
      "    \"SQL\",\n",
      "    \"Terraform\",\n",
      "    \"Bitbucket\",\n",
      "    \"Jenkins\",\n",
      "    \"Airflow\",\n",
      "    \"Docker\",\n",
      "    \"Kubernetes\",\n",
      "    \"GCP (BigQuery, Spark DataProc)\",\n",
      "    \"Développement logiciel agile\",\n",
      "    \"Algorithmes d'apprentissage statistique\"\n",
      "  ],\n",
      "  \"Experiences\": [\n",
      "    {\n",
      "      \"domaine_activite\": [\"Data Science\"],\n",
      "      \"poste_occupe\": \"Data Scientist\",\n",
      "      \"duree\": \"5 ans\"\n",
      "    }\n",
      "  ],\n",
      "  \"Profil\": {\n",
      "    \"titre\": \"Data Scientist\",\n",
      "    \"disponibilite\": null\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "job_offer_reforumer = analyze_offre_emploi(job_offer)\n",
    "print(job_offer_reforumer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarité cosinus globale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Token d'API Hugging Face\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "API_URL = \"https://api-inference.huggingface.co/pipeline/feature-extraction/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "\n",
    "def get_embedding(text: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Envoie une requête à l'API Hugging Face pour obtenir l'embedding d'un texte.\n",
    "\n",
    "    Args:\n",
    "        text (str): Texte à encoder.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Embedding du texte.\n",
    "    \"\"\"\n",
    "    headers = {\"Authorization\": f\"Bearer {os.getenv(\"HF_TOKEN\")}\"}\n",
    "    response = requests.post(\n",
    "        \"https://api-inference.huggingface.co/pipeline/feature-extraction/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "        headers=headers,\n",
    "        json={\"inputs\": text, \"options\": {\"wait_for_model\": True}},\n",
    "    )\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Erreur API : {response.status_code}, {response.text}\")\n",
    "    return np.array(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarité globale entre le CV et l'offre d'emploi: 0.8941\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_similarity(text1: str, text2: str) -> float:\n",
    "    \"\"\"\n",
    "    Calcule la similarité cosinus entre deux textes en utilisant l'API Hugging Face.\n",
    "    \n",
    "    Args:\n",
    "        text1 (str): Premier texte.\n",
    "        text2 (str): Deuxième texte.\n",
    "    \n",
    "    Returns:\n",
    "        float: Score de similarité cosinus entre les deux textes.\n",
    "    \"\"\"\n",
    "    # Obtenir les embeddings des textes\n",
    "    embedding1 = get_embedding(text1)\n",
    "    embedding2 = get_embedding(text2)\n",
    "    \n",
    "    # Calculer la similarité cosinus\n",
    "    similarity = cosine_similarity([embedding1], [embedding2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "# Calculer la similarité entre le CV et l'offre d'emploi\n",
    "similarity_score = calculate_similarity(CV_reformuler, job_offer_reforumer)\n",
    "print(f\"Similarité globale entre le CV et l'offre d'emploi: {similarity_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversion en JSON-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calcul de la similarité entre chaque partie du CV et l'offre d'emploi\n",
    "# Diviser le CV reformulé en json en plusieurs parties\n",
    "cv_json = json.loads(CV_reformuler)\n",
    "# print(cv_json)\n",
    "# convert job_offer to json\n",
    "job_offer_json = json.loads(job_offer_reforumer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Formation': [{'niveau_etudes': 'Master', 'domaine_etudes': ['Informatique', 'Mathématiques appliquées']}], 'Competences': ['Python', 'SQL', 'Terraform', 'Bitbucket', 'Jenkins', 'Airflow', 'Docker', 'Kubernetes', 'GCP (BigQuery, Spark DataProc)', 'Développement logiciel agile', \"Algorithmes d'apprentissage statistique\"], 'Experiences': [{'domaine_activite': ['Data Science'], 'poste_occupe': 'Data Scientist', 'duree': '5 ans'}], 'Profil': {'titre': 'Data Scientist', 'disponibilite': None}}\n"
     ]
    }
   ],
   "source": [
    "print(job_offer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(cv_json)) # Les données sont en string JSON like\n",
    "print(type(job_offer_json)) # Les données sont en string JSON like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul des similarités cosinus par parties :\n",
    "\n",
    "- Formation\n",
    "- Competences\n",
    "- Experiences\n",
    "- Profil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarité entre les deux json like\n",
    "\n",
    "# Similarité Formation\n",
    "# print(cv_json.get(\"Formation\"))\n",
    "# print(job_offer_json.get(\"Formation\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarité entre Formation attendu et Formation du CV: 0.7722\n",
      "['ML', 'NLP', 'TensorFlow', 'Scikit-learn', 'MLFlow', 'Transformers', 'LLM', 'Time Series', 'SQL', 'NoSQL', 'MongoDB', 'Qlik', 'Tableau', 'PowerBI', 'OpenCV', 'YOLO', 'Azure', 'AWS', 'Fabric', 'Git', 'Agile methodology', 'Python', 'R', 'Java', 'PySpark', 'JavaScript', 'PHP']\n",
      "['Python', 'SQL', 'Terraform', 'Bitbucket', 'Jenkins', 'Airflow', 'Docker', 'Kubernetes', 'GCP (BigQuery, Spark DataProc)', 'Développement logiciel agile', \"Algorithmes d'apprentissage statistique\"]\n",
      "Similarité entre Compétences attendu et Compétences du CV: 0.8097\n",
      "[{'domaine_activite': ['Data Science'], 'poste_occupe': 'Stage Data Scientist', 'duree': '4 mois'}, {'domaine_activite': ['Développement mobile et web'], 'poste_occupe': 'Développeur Web et Mobile', 'duree': None}]\n",
      "[{'domaine_activite': ['Data Science'], 'poste_occupe': 'Data Scientist', 'duree': '5 ans'}]\n",
      "Similarité entre Experiences attendu et Experiences du CV: 0.8239\n",
      "{'titre': \"Actuellement à la recherche d'un stage en Data Science\", 'disponibilite': 'mars 2025'}\n",
      "{'titre': 'Data Scientist', 'disponibilite': None}\n",
      "Similarité entre Profil attendu et Profil du CV: 0.6145\n"
     ]
    }
   ],
   "source": [
    "# Similarité entre Formation attendu et Formation du CV\n",
    "formation_candidat = cv_json.get(\"Formation\")\n",
    "formation_attendu = job_offer_json.get(\"Formation\")\n",
    "\n",
    "similarite_formation = calculate_similarity(str(formation_candidat), str(formation_attendu))\n",
    "print(f\"Similarité entre Formation attendu et Formation du CV: {similarite_formation:.4f}\")\n",
    "\n",
    "\n",
    "# Similarité entre Compétences attendu et Compétences du CV\n",
    "competences_candidat = cv_json.get(\"Competences\")\n",
    "print(competences_candidat)\n",
    "competences_attendu = job_offer_json.get(\"Competences\")\n",
    "print(competences_attendu)\n",
    "\n",
    "similarite_competences = calculate_similarity(str(competences_candidat), str(competences_attendu))\n",
    "print(f\"Similarité entre Compétences attendu et Compétences du CV: {similarite_competences:.4f}\")\n",
    "\n",
    "\n",
    "# Similarité entre Experiences attendu et Experiences du CV\n",
    "experiences_candidat = cv_json.get(\"Experiences\")\n",
    "print(experiences_candidat)\n",
    "experiences_attendu = job_offer_json.get(\"Experiences\")\n",
    "print(experiences_attendu)\n",
    "\n",
    "similarite_experiences = calculate_similarity(str(experiences_candidat), str(experiences_attendu))\n",
    "print(f\"Similarité entre Experiences attendu et Experiences du CV: {similarite_experiences:.4f}\")\n",
    "\n",
    "\n",
    "# Similarité entre Profil attendu et Profil du CV\n",
    "profil_candidat = cv_json.get(\"Profil\")\n",
    "print(profil_candidat)\n",
    "profil_attendu = job_offer_json.get(\"Profil\")\n",
    "print(profil_attendu)\n",
    "\n",
    "similarite_profil = calculate_similarity(str(profil_candidat), str(profil_attendu))\n",
    "print(f\"Similarité entre Profil attendu et Profil du CV: {similarite_profil:.4f}\")\n",
    "\n",
    "###################### Voir si on ne peut pas faire mieux (check if any au lieu d'une simalarité globale) ######################\n",
    "### Au lieu d'installer sentence transformers, utiliser une API huggingface avec pipeline et requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_section_similarity(cv_reformule: str, offre_emploi_reformule: str) -> dict:\n",
    "    \"\"\"\n",
    "    Calcule les similarités détaillées entre les différentes sections d'un CV et une offre d'emploi.\n",
    "    \n",
    "    Args:\n",
    "        cv_reformule (str): Informations du CV au format JSON string\n",
    "        offre_emploi_reformule (str): Informations de l'offre d'emploi au format JSON string\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionnaire contenant les scores de similarité pour chaque section\n",
    "        \n",
    "    Exemple:\n",
    "        {\n",
    "            'formation': float,\n",
    "            'competences': float,\n",
    "            'experiences': float,\n",
    "            'profil': float,\n",
    "        }\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Conversion des chaînes JSON en dictionnaires\n",
    "        cv_json = json.loads(cv_reformule)\n",
    "        offre_emploi_json = json.loads(offre_emploi_reformule)\n",
    "        \n",
    "        # Calcul des similarités pour chaque section\n",
    "        similarites = {}\n",
    "        \n",
    "        # Similarité de formation\n",
    "        formation_candidat = cv_json.get(\"Formation\", \"\")\n",
    "        formation_attendue = offre_emploi_json.get(\"Formation\", \"\")\n",
    "        similarites['formation'] = calculate_similarity(\n",
    "            str(formation_candidat), \n",
    "            str(formation_attendue)\n",
    "        )\n",
    "        \n",
    "        # Similarité des compétences\n",
    "        competences_candidat = cv_json.get(\"Competences\", [])\n",
    "        competences_attendues = offre_emploi_json.get(\"Competences\", [])\n",
    "        similarites['competences'] = calculate_similarity(\n",
    "            str(competences_candidat), \n",
    "            str(competences_attendues)\n",
    "        )\n",
    "        \n",
    "        # Similarité des expériences\n",
    "        experiences_candidat = cv_json.get(\"Experiences\", [])\n",
    "        experiences_attendues = offre_emploi_json.get(\"Experiences\", [])\n",
    "        similarites['experiences'] = calculate_similarity(\n",
    "            str(experiences_candidat), \n",
    "            str(experiences_attendues)\n",
    "        )\n",
    "        \n",
    "        # Similarité du profil\n",
    "        profil_candidat = cv_json.get(\"Profil\", {})\n",
    "        profil_attendu = offre_emploi_json.get(\"Profil\", {})\n",
    "        similarites['profil'] = calculate_similarity(\n",
    "            str(profil_candidat), \n",
    "            str(profil_attendu)\n",
    "        )\n",
    "        \n",
    "        return similarites\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(f\"Erreur lors du parsing JSON : {str(e)}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Erreur lors du calcul des similarités : {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'formation': np.float64(0.7721912791299416), 'competences': np.float64(0.8096697817781795), 'experiences': np.float64(0.823887980461006), 'profil': np.float64(0.6144781249850023)}\n",
      "0.7721912791299416\n"
     ]
    }
   ],
   "source": [
    "print(calculate_section_similarity(CV_reformuler, job_offer_reforumer))\n",
    "\n",
    "print(calculate_section_similarity(CV_reformuler, job_offer_reforumer)['formation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création d'une lettre de motivation à partir du CV et de l'offre\n",
    "\n",
    "- Utilisation du CV brut car on a perdu des informations qu'on peut mettre en avant ici (bénévélot etc..)\n",
    "- Même chose pour l'offre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edina Adjaro \n",
      "Patoussi\n",
      "Étudiant en dernière \n",
      "année de Data Science\n",
      "adjaropatoussi@gmail.com\n",
      "0753234875\n",
      "lyon, France\n",
      "Profil\n",
      "Actuellement à la recherche d'un stage \n",
      "en Data Science à partir de mars 2025 \n",
      "pour une durée de 4 à 6 mois.\n",
      "Compétences\n",
      "ML, NLP, TensorFlow; Scikit-learn, \n",
      "MLFlow, Transformers, LLM, Time Series.\n",
      "SQL, NoSQL, MongoDB\n",
      "Qlik, Tableau, PowerBI\n",
      "OpenCV, YOLO\n",
      "Azure, AWS, Fabric\n",
      "Git,Agile methodology\n",
      "Python, R, Java, PySpark, JavaScript, \n",
      "PHP\n",
      "Soft Skills\n",
      "Travail d'équipe, Communication, \n",
      "Adaptabilité, Résolution de problèmes,  \n",
      "Créativité\n",
      "Centres d'Intérêt\n",
      "Bénévolat — Parrainage avec Alter-ego\n",
      "Lyon 2\n",
      "Sports: — football (travail d'équipe et\n",
      "prise de décision rapide).\n",
      "Jeux de société — échecs et passionné\n",
      "de jeux de stratégie.\n",
      "Langues\n",
      "Français\n",
      "AnglaisFormation Académique\n",
      "Master en Data Science, Université Lyon 2 Lumière\n",
      "09/2023 – aujourd'hui | lyon, France\n",
      "•Expertise en analyse de données avancée : ANOVA, séries \n",
      "temporelles, biostatistiques, NLP/LLM, Vision par ordinateur.\n",
      "•Maîtrise du Big Data et des MLOps : web scraping, entrepôts de \n",
      "données, déploiement de modèles et pipelines.\n",
      "•Spécialisation en analyse prédictive, avec un accent sur l'utilisation \n",
      "de modèles statistiques avancés et d'algorithmes de machine \n",
      "learning pour la prévision et la prise de décision.\n",
      "Master 1 en Intelligence Artificielle et Big Data, \n",
      "École Polytechnique de Lomé et UTBM\n",
      "10/2022 – 08/2023 | Lome, Togo\n",
      "• Compétences en développement et ingénierie des données : \n",
      "Programmation orientée objet avec Python, Ingénierie des données, \n",
      "Bases de données avancées, BU.\n",
      "• Maîtrise des techniques d'analyse et de modélisation : Apprentissage \n",
      "supervisé, SAS, Complexité algorithmique.\n",
      "Expérience Professionnelle\n",
      "Stage Data Scientist, Laboratoire LIRIS\n",
      "04/2024 – 08/2024 | Lyon, France\n",
      "•Vision par ordinateur : Detectron 2, annotation de données, \n",
      "augmentation de données.\n",
      "•Reconnaissance de textes : Expérimentation avec des outils \n",
      "OLR/OCR.\n",
      "•Analyse de données : Évaluation des performances des modèles, \n",
      "reporting technique.\n",
      "•Collaboration : Travail en équipe avec des chercheurs et des \n",
      "ingénieurs en IA.\n",
      "Développeur Web et Mobile, IT Innovation\n",
      "•Développement mobile et web\n",
      "•Visualisation de données : Tableaux de bord avec Chart.js.\n",
      "•Gestion de bases de données : Conception et optimisation de bases \n",
      "de données, requêtes complexes.\n",
      "•Collaboration : Travail en équipe avec des designers  \n",
      "Projets\n",
      "Création d'un package R de régression logistique\n",
      "•Package de régression logistique développé from scratch : \n",
      "Implémentation de divers optimiseurs et application de techniques \n",
      "de régularisation.\n",
      "•Tests réussis sur des tâches de classification : Atteint jusqu'à 90% \n",
      "de précision sur les datasets StudentPerformance.\n",
      "Projet d'analyse NLP des avis TripAdvisor\n",
      "•Web scraping : Collecte de données avec BeautifulSoup.\n",
      "•Analyse de sentiments : Clustering des commentaires et \n",
      "visualisation des résultats.\n",
      "•Application End-to-End : Intégration d'une base de données SQLite \n",
      "et création d'une application Streamlit déployée via Docker.\n",
      "•Synthèse automatisée : Utilisation d'un LLM avec RAG pour résumer \n",
      "efficacement les avis utilisateurs.\n",
      "Certifications\n",
      "Associate Data Scientist in Python  — DATACAMP\n",
      "Back-End Engineering  — Lyft, Forage\n",
      " — Langue Maternelle/Bilingue\n",
      " — Intermédiaire\n",
      "|\n"
     ]
    }
   ],
   "source": [
    "# LLM pour la lettre de motivation\n",
    "print(text_brut)\n",
    "# job_offer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extractions info perso avec un LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_extraction_info_perso = f\"\"\"\n",
    "    Extrait les informations personnelles suivantes du texte brut d'un CV et retourne-les au format JSON :\n",
    "    - Nom et prénom\n",
    "    - Email\n",
    "    - Numéro de téléphone\n",
    "    - Adresse\n",
    "\n",
    "    Si une information est manquante, retourne `Non réseigner` pour cette clé.\n",
    "\n",
    "    Texte brut du CV :\n",
    "    \"{text_brut}\"\n",
    "\n",
    "    Format JSON attendu :\n",
    "    {{\n",
    "        \"nom_prenom\": \"str\",\n",
    "        \"email\": \"str\",\n",
    "        \"telephone\": \"str\",\n",
    "        \"adresse\": \"str\"\n",
    "    }}\n",
    "\n",
    "    Ne retourne que le JSON, sans commentaires supplémentaires.\n",
    "    \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resultat_extraction_info_perso = litellm.completion(\n",
    "            model=\"mistral/mistral-tiny\",  \n",
    "            messages=[{\"role\": \"user\", \"content\": prompt_extraction_info_perso}],\n",
    "            max_tokens=100,\n",
    "            temperature=0.1,\n",
    "            api_key=os.getenv(\"MISTRAL_API_KEY\"),\n",
    "        )\n",
    "\n",
    "resultat_extraction_info_perso_content = resultat_extraction_info_perso[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction_info_perso(text_brut: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrait les informations personnelles d'un CV en format texte brut.\n",
    "\n",
    "    Args:\n",
    "        text_brut (str): Texte brut du CV à analyser\n",
    "\n",
    "    Returns:\n",
    "        str: Informations personnelles extraites du CV en format JSON like\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_extraction_info_perso = f\"\"\"\n",
    "    Extrait les informations personnelles suivantes du texte brut d'un CV et retourne-les au format JSON :\n",
    "    - Nom et prénom\n",
    "    - Email\n",
    "    - Numéro de téléphone\n",
    "    - Adresse\n",
    "\n",
    "    Si une information est manquante, retourne une chaine vide \"\" pour cette clé.\n",
    "\n",
    "    Texte brut du CV :\n",
    "    \"{text_brut}\"\n",
    "\n",
    "    Format JSON attendu :\n",
    "    {{\n",
    "        \"nom_prenom\": \"str\",\n",
    "        \"email\": \"str\",\n",
    "        \"telephone\": \"str\",\n",
    "        \"adresse\": \"str\"\n",
    "    }}\n",
    "\n",
    "    Ne retourne que le JSON, sans commentaires supplémentaires.\n",
    "    \"\"\"\n",
    "    resultat_extraction_info_perso = litellm.completion(\n",
    "                model=\"mistral/mistral-tiny\",  \n",
    "                messages=[{\"role\": \"user\", \"content\": prompt_extraction_info_perso}],\n",
    "                max_tokens=100,\n",
    "                temperature=0.1,\n",
    "                api_key=os.getenv(\"MISTRAL_API_KEY\"),\n",
    "            )\n",
    "    \n",
    "    # Impact écologique\n",
    "    energy_usage, gwp = get_energy_usage(response=resultat_extraction_info_perso)\n",
    "    monitoring_environnement.update_metrics(new_gwp=gwp, new_energy=energy_usage)\n",
    "    \n",
    "    return resultat_extraction_info_perso[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"nom_prenom\": \"Edina Adjaro\",\\n    \"email\": \"adjaropatoussi@gmail.com\",\\n    \"telephone\": \"0753234875\",\\n    \"adresse\": \"lyon, France\"\\n}'"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_info_perso(text_brut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "{'nom_prenom': 'Edina Adjaro', 'email': 'adjaropatoussi@gmail.com', 'telephone': '0753234875', 'adresse': 'lyon, France'}\n",
      "Edina Adjaro\n",
      "adjaropatoussi@gmail.com\n",
      "0753234875\n",
      "lyon, France\n",
      "13 mars 2025\n"
     ]
    }
   ],
   "source": [
    "print(type(resultat_extraction_info_perso_content))\n",
    "# convertir en json like\n",
    "resultat_extraction_info_perso_json = json.loads(resultat_extraction_info_perso_content)\n",
    "print(resultat_extraction_info_perso_json)\n",
    "\n",
    "nom = resultat_extraction_info_perso_json.get(\"nom_prenom\")\n",
    "print(nom)\n",
    "email = resultat_extraction_info_perso_json.get(\"email\", \"\").strip()\n",
    "# Remove all spaces from email\n",
    "email = \"\".join(email.split())\n",
    "print(email)  # Will print: quentinlim384@gmail.com\n",
    "telephone = resultat_extraction_info_perso_json.get(\"telephone\")\n",
    "print(telephone)\n",
    "adresse = resultat_extraction_info_perso_json.get(\"adresse\")\n",
    "print(adresse)\n",
    "\n",
    "\n",
    "# Set French locale\n",
    "try:\n",
    "    locale.setlocale(locale.LC_TIME, 'fr_FR.UTF-8')  # Linux/Mac\n",
    "except:\n",
    "    locale.setlocale(locale.LC_TIME, 'fra_fra')  # Windows\n",
    "\n",
    "# Get date in French format\n",
    "date = datetime.now().strftime(\"%d %B %Y\")\n",
    "print(date)  # Output: 13 mars 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_lettre_motivation = f\"\"\"\n",
    "Tu es un assistant qui rédige des lettres de motivation personnalisées et professionnelles. Voici les informations nécessaires :\n",
    "\n",
    "**Informations du candidat :**\n",
    "- Nom : {nom}\n",
    "- Email : {email}\n",
    "- Téléphone : {telephone}\n",
    "- Adresse : {adresse}\n",
    "- Date : {date}\n",
    "\n",
    "**Texte brut du CV :**\n",
    "{text_brut}\n",
    "\n",
    "**Offre d'emploi :**\n",
    "{job_offer}\n",
    "\n",
    "**Instructions :**\n",
    "1. Rédige une lettre de motivation au format A4, bien structurée et professionnelle.\n",
    "2. Mets en avant les compétences et expériences du candidat qui correspondent aux exigences du poste.\n",
    "3. Mentionne des éléments spécifiques de l'entreprise ou du poste pour montrer que la candidature est personnalisée.\n",
    "4. Explique pourquoi le candidat est motivé pour rejoindre cette entreprise en particulier.\n",
    "5. Utilise un ton professionnel et évite les phrases génériques.\n",
    "6. Ne laisse pas de champs vides et ne devine pas les informations manquantes.\n",
    "\n",
    "**Format de la lettre :**\n",
    "- En-tête : Nom, prénom, adresse, email, téléphone, date.\n",
    "- Introduction : Présentation du candidat et motivation pour le poste.\n",
    "- Corps : Compétences et expériences en lien avec le poste.\n",
    "- Conclusion : Expression de l'enthousiasme et disponibilité pour un entretien.\n",
    "\n",
    "**Exemple de structure :**\n",
    "{nom}\n",
    "{email}\n",
    "{telephone}\n",
    "{adresse}\n",
    "{date}\n",
    "\n",
    "Madame, Monsieur,\n",
    "Je me permets de vous adresser ma candidature pour le poste de [poste] au sein de [entreprise]. [Motivation personnalisée].\n",
    "\n",
    "Avec mon expérience en [domaine] et mes compétences en [compétences], je suis convaincu de pouvoir contribuer à [objectif de l'entreprise]. [Détail des expériences et compétences pertinentes].\n",
    "\n",
    "Je serais ravi de discuter de ma candidature lors d'un entretien. Je reste à votre disposition pour toute information complémentaire.\n",
    "\n",
    "Veuillez agréer, Madame, Monsieur, mes salutations distinguées.\n",
    "{nom}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Lettre_motiv_genere = litellm.completion(\n",
    "            model=\"mistral/ministral-3b-latest\",  \n",
    "            messages=[{\"role\": \"user\", \"content\": prompt_lettre_motivation}],\n",
    "            max_tokens=1500,\n",
    "            temperature=0.3,\n",
    "            api_key=os.getenv(\"MISTRAL_API_KEY\"),\n",
    "        )\n",
    "\n",
    "resultat = Lettre_motiv_genere[\"choices\"][0][\"message\"][\n",
    "            \"content\"\n",
    "        ].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Edina Adjaro**\n",
      "adjaropatoussi@gmail.com\n",
      "0753234875\n",
      "Lyon, France\n",
      "13 mars 2025\n",
      "\n",
      "Madame, Monsieur,\n",
      "\n",
      "Je me permets de vous adresser ma candidature pour le poste de Data Scientist au sein de AOSIS CONSULTING, tel que publié sur votre site. Fort de mon parcours académique et professionnel en Data Science, je suis convaincu de pouvoir apporter une contribution significative à votre équipe.\n",
      "\n",
      "Actuellement étudiant en dernière année de Data Science à l'Université Lyon 2 Lumière, j'ai acquis une solide expertise en analyse de données avancée, en Big Data et en MLOps. Mon expérience inclut la réalisation de projets complexes tels que la création d'un package R de régression logistique et l'analyse NLP des avis TripAdvisor. Ces projets m'ont permis de développer des compétences en développement logiciel, en visualisation de données et en gestion de bases de données, compétences qui sont directement pertinentes pour le poste que vous proposez.\n",
      "\n",
      "Mon parcours académique et professionnel m'a également permis de maîtriser divers outils et technologies tels que Python, SQL, TensorFlow, Scikit-learn, et des plateformes cloud comme Azure et AWS. J'ai également une expérience significative dans le développement logiciel agile, ce qui est essentiel pour collaborer efficacement avec des équipes multiples.\n",
      "\n",
      "Ce qui m'attire particulièrement chez AOSIS CONSULTING, c'est votre engagement envers des enjeux importants tels que l'écologie, la citoyenneté et le sport. Ces valeurs résonnent profondément avec moi et je suis motivé à l'idée de contribuer à des projets qui ont un impact positif sur la société. De plus, votre approche collaborative et votre engagement envers des activités variées font de votre entreprise un lieu de travail dynamique et enrichissant.\n",
      "\n",
      "Je suis convaincu que mon profil correspond aux exigences de ce poste et que je pourrais apporter une valeur ajoutée à votre équipe. Je serais ravi de discuter plus en détail de ma candidature lors d'un entretien et de vous démontrer comment mes compétences et mon expérience peuvent répondre aux besoins de votre entreprise.\n",
      "\n",
      "Je vous remercie par avance pour l'attention que vous porterez à ma candidature et je reste à votre disposition pour toute information complémentaire.\n",
      "\n",
      "Veuillez agréer, Madame, Monsieur, l'expression de mes salutations distinguées.\n",
      "\n",
      "Edina Adjaro\n"
     ]
    }
   ],
   "source": [
    "print(resultat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lettre_motivation(text_brut: str, job_offer:str) ->str:\n",
    "    \"\"\"\n",
    "    Génère une lettre de motivation personnalisée en fonction des informations extraites du CV et de l'offre d'emploi.\n",
    "    \n",
    "    Args:\n",
    "        text_brut (str): Texte brut extrait du CV du candidat\n",
    "        job_offer (str): Description de l'offre d'emploi\n",
    "        \n",
    "    Returns:\n",
    "        str: Lettre de motivation générée au format texte\n",
    "    \n",
    "    \"\"\"\n",
    "    information_perso = extraction_info_perso(text_brut)\n",
    "    resultat_extraction_info_perso_json = json.loads(information_perso)\n",
    "\n",
    "    nom = resultat_extraction_info_perso_json.get(\"nom_prenom\")\n",
    "    email = resultat_extraction_info_perso_json.get(\"email\", \"\").strip()\n",
    "    # Remove all spaces from email\n",
    "    email = \"\".join(email.split())\n",
    "    telephone = resultat_extraction_info_perso_json.get(\"telephone\")\n",
    "    adresse = resultat_extraction_info_perso_json.get(\"adresse\")\n",
    "\n",
    "\n",
    "    # Set French locale\n",
    "    try:\n",
    "        locale.setlocale(locale.LC_TIME, 'fr_FR.UTF-8')  # Linux/Mac\n",
    "    except:\n",
    "        locale.setlocale(locale.LC_TIME, 'fra_fra')  # Windows\n",
    "\n",
    "    # Get date in French format\n",
    "    date = datetime.now().strftime(\"%d %B %Y\")\n",
    "\n",
    "    prompt_lettre_motivation = f\"\"\"\n",
    "    Tu es un assistant qui rédige des lettres de motivation personnalisées et professionnelles. Voici les informations nécessaires :\n",
    "\n",
    "    **Informations du candidat :**\n",
    "    - Nom : {nom}\n",
    "    - Email : {email}\n",
    "    - Téléphone : {telephone}\n",
    "    - Adresse : {adresse}\n",
    "    - Date : {date}\n",
    "\n",
    "    **Texte brut du CV :**\n",
    "    {text_brut}\n",
    "\n",
    "    **Offre d'emploi :**\n",
    "    {job_offer}\n",
    "\n",
    "    **Instructions :**\n",
    "    1. Rédige une lettre de motivation au format A4, bien structurée et professionnelle.\n",
    "    2. Mets en avant les compétences et expériences du candidat qui correspondent aux exigences du poste.\n",
    "    3. Mentionne des éléments spécifiques de l'entreprise ou du poste pour montrer que la candidature est personnalisée.\n",
    "    4. Explique pourquoi le candidat est motivé pour rejoindre cette entreprise en particulier.\n",
    "    5. Utilise un ton professionnel et évite les phrases génériques.\n",
    "    6. Ne laisse pas de champs vides et ne devine pas les informations manquantes.\n",
    "\n",
    "    **Format de la lettre :**\n",
    "    - En-tête : Nom, prénom, adresse, email, téléphone, date.\n",
    "    - Introduction : Présentation du candidat et motivation pour le poste.\n",
    "    - Corps : Compétences et expériences en lien avec le poste.\n",
    "    - Conclusion : Expression de l'enthousiasme et disponibilité pour un entretien.\n",
    "\n",
    "    **Exemple de structure :**\n",
    "    {nom}\n",
    "    {email}\n",
    "    {telephone}\n",
    "    {adresse}\n",
    "    {date}\n",
    "\n",
    "    Madame, Monsieur,\n",
    "    Je me permets de vous adresser ma candidature pour le poste de [poste] au sein de [entreprise]. [Motivation personnalisée].\n",
    "\n",
    "    Avec mon expérience en [domaine] et mes compétences en [compétences], je suis convaincu de pouvoir contribuer à [objectif de l'entreprise]. [Détail des expériences et compétences pertinentes].\n",
    "\n",
    "    Je serais ravi de discuter de ma candidature lors d'un entretien. Je reste à votre disposition pour toute information complémentaire.\n",
    "\n",
    "    Veuillez agréer, Madame, Monsieur, mes salutations distinguées.\n",
    "    {nom}\n",
    "    \"\"\"\n",
    "        \n",
    "    Lettre_motiv_genere = litellm.completion(\n",
    "                model=\"mistral/ministral-3b-latest\",  \n",
    "                messages=[{\"role\": \"user\", \"content\": prompt_lettre_motivation}],\n",
    "                max_tokens=1500,\n",
    "                temperature=0.3,\n",
    "                api_key=os.getenv(\"MISTRAL_API_KEY\"),\n",
    "            )\n",
    "\n",
    "\n",
    "    # Impact écologique\n",
    "    energy_usage, gwp = get_energy_usage(response=Lettre_motiv_genere)\n",
    "    monitoring_environnement.update_metrics(new_gwp=gwp, new_energy=energy_usage)\n",
    "\n",
    "    resultat = Lettre_motiv_genere[\"choices\"][0][\"message\"][\n",
    "                \"content\"\n",
    "            ].strip()\n",
    "    \n",
    "    return resultat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Edina Adjaro**\n",
      "adjaropatoussi@gmail.com\n",
      "075323475\n",
      "Lyon, France\n",
      "13 mars 2025\n",
      "\n",
      "**Madame, Monsieur,**\n",
      "\n",
      "Je me permets de vous adresser ma candidature pour le poste de Data Scientist au sein de AOSIS CONSULTING. Fort de mon parcours académique et professionnel en Data Science, je suis convaincu de pouvoir apporter une valeur ajoutée à votre équipe et contribuer à vos projets ambitieux.\n",
      "\n",
      "Actuellement étudiant en dernière année de Data Science à l'Université Lyon 2 Lumière, j'ai acquis une solide expertise en analyse de données avancée, en Big Data et en MLOps. Mon expérience inclut la réalisation de projets complexes tels que la création d'un package R de régression logistique et l'analyse NLP des avis TripAdvisor. Ces projets m'ont permis de développer des compétences en développement logiciel, en visualisation de données et en gestion de bases de données, tout en travaillant en équipe et en utilisant des méthodologies agiles.\n",
      "\n",
      "Mon parcours académique et professionnel m'a également permis de maîtriser des outils et technologies clés pour le poste de Data Scientist, tels que Python, SQL, TensorFlow, Scikit-learn, et des environnements cloud comme GCP. J'ai une expérience significative dans l'industrialisation des modèles dans des environnements cloud, ce qui correspond parfaitement aux exigences de votre offre.\n",
      "\n",
      "Ce qui m'attire particulièrement chez AOSIS CONSULTING, c'est votre engagement envers des enjeux importants tels que l'écologie, la citoyenneté et le sport. Ces valeurs résonnent profondément avec moi et je suis motivé par l'idée de contribuer à des projets qui ont un impact positif sur la société. De plus, votre approche collaborative et votre engagement envers des activités variées font de votre entreprise un lieu de travail dynamique et enrichissant.\n",
      "\n",
      "Je suis prêt à m'investir pleinement dans ce poste et à apporter mes compétences et mon expérience pour aider à identifier les difficultés de vos clients et proposer des solutions innovantes. Je suis également enthousiaste à l'idée de développer des outils de visualisation des données et de mettre en production des solutions robustes.\n",
      "\n",
      "Je serais ravi de discuter plus en détail de ma candidature lors d'un entretien. Je reste à votre disposition pour toute information complémentaire.\n",
      "\n",
      "Veuillez agréer, Madame, Monsieur, l'expression de mes salutations distinguées.\n",
      "\n",
      "**Edina Adjaro**\n"
     ]
    }
   ],
   "source": [
    "print(generate_lettre_motivation(text_brut, job_offer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[Votre Nom]\\n[Votre Adresse]\\n[Code Postal, Ville]\\n[Votre Email]\\n[Votre Numéro de Téléphone]\\n[Date]\\n\\nAOSIS CONSULTING\\n[Adresse de l'entreprise]\\n31 - Toulouse\\n\\nObjet : Candidature au poste de Data Scientist (H/F)\\n\\nMadame, Monsieur,\\n\\nJe me permets de vous adresser ma candidature pour le poste de Data Scientist au sein de votre entreprise, tel que publié sur votre site. Actuellement étudiant en Data Science à l'Université Lumière Lyon 2, je suis à la recherche d'une opportunité d'internship pour débuter ma carrière dans ce domaine passionnant.\\n\\nMon parcours académique et professionnel m'a permis de développer une solide expertise en data science, notamment en matière d'analyse avancée, de Big Data, de MLOps, et de predictive analytics. J'ai eu l'occasion de travailler sur divers projets qui m'ont permis de maîtriser des outils tels que Python, R, SQL, et des bibliothèques comme Scikit-learn, TensorFlow, et PySpark. Mon expérience inclut également la création de packages logiciels, la réalisation d'analyses NLP, et la gestion de bases de données NoSQL.\\n\\nAu cours de mon stage en tant que Data Analyst chez SYSBLOCK, j'ai eu l'opportunité de travailler sur des projets de dashboarding et d'analyse de données, ainsi que sur des projets de développement web et de blockchain. J'ai également développé des compétences en DevOps, notamment sur AWS, et j'ai une expérience significative avec des outils de visualisation comme Power BI et Tableau.\\n\\nCe qui m'attire particulièrement dans votre offre est votre engagement envers des valeurs importantes telles que la citoyenneté, l'écologie et le sport. Ces valeurs résonnent profondément avec moi et je suis convaincu que mon profil pourrait apporter une contribution significative à vos projets.\\n\\nJe suis particulièrement attiré par l'opportunité de travailler dans un environnement technique avancé, utilisant des outils tels que Python, SQL, Terraform, et des plateformes cloud comme GCP. Mon expérience en développement logiciel agile et ma maîtrise des méthodologies Git/Agile me permettent de m'intégrer rapidement et de collaborer efficacement avec des équipes multidisciplinaires.\\n\\nJe suis convaincu que mon parcours et mes compétences correspondent parfaitement aux exigences de ce poste. Je serais ravi de pouvoir discuter plus en détail de ma candidature lors d'un entretien.\\n\\nJe vous remercie par avance pour l'attention que vous porterez à ma demande et je reste à votre disposition pour toute information complémentaire.\\n\\nDans l'attente de votre réponse, je vous prie d'agréer, Madame, Monsieur, l'expression de mes salutations distinguées.\\n\\n[Votre Nom]\""
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"[Votre Nom]\\n[Votre Adresse]\\n[Code Postal, Ville]\\n[Votre Email]\\n[Votre Numéro de Téléphone]\\n[Date]\\n\\nAOSIS CONSULTING\\n[Adresse de l'entreprise]\\n31 - Toulouse\\n\\nObjet : Candidature au poste de Data Scientist (H/F)\\n\\nMadame, Monsieur,\\n\\nJe me permets de vous adresser ma candidature pour le poste de Data Scientist au sein de votre entreprise, tel que publié sur votre site. Actuellement étudiant en Data Science à l'Université Lumière Lyon 2, je suis à la recherche d'une opportunité d'internship pour débuter ma carrière dans ce domaine passionnant.\\n\\nMon parcours académique et professionnel m'a permis de développer une solide expertise en data science, notamment en matière d'analyse avancée, de Big Data, de MLOps, et de predictive analytics. J'ai eu l'occasion de travailler sur divers projets qui m'ont permis de maîtriser des outils tels que Python, R, SQL, et des bibliothèques comme Scikit-learn, TensorFlow, et PySpark. Mon expérience inclut également la création de packages logiciels, la réalisation d'analyses NLP, et la gestion de bases de données NoSQL.\\n\\nAu cours de mon stage en tant que Data Analyst chez SYSBLOCK, j'ai eu l'opportunité de travailler sur des projets de dashboarding et d'analyse de données, ainsi que sur des projets de développement web et de blockchain. J'ai également développé des compétences en DevOps, notamment sur AWS, et j'ai une expérience significative avec des outils de visualisation comme Power BI et Tableau.\\n\\nCe qui m'attire particulièrement dans votre offre est votre engagement envers des valeurs importantes telles que la citoyenneté, l'écologie et le sport. Ces valeurs résonnent profondément avec moi et je suis convaincu que mon profil pourrait apporter une contribution significative à vos projets.\\n\\nJe suis particulièrement attiré par l'opportunité de travailler dans un environnement technique avancé, utilisant des outils tels que Python, SQL, Terraform, et des plateformes cloud comme GCP. Mon expérience en développement logiciel agile et ma maîtrise des méthodologies Git/Agile me permettent de m'intégrer rapidement et de collaborer efficacement avec des équipes multidisciplinaires.\\n\\nJe suis convaincu que mon parcours et mes compétences correspondent parfaitement aux exigences de ce poste. Je serais ravi de pouvoir discuter plus en détail de ma candidature lors d'un entretien.\\n\\nJe vous remercie par avance pour l'attention que vous porterez à ma demande et je reste à votre disposition pour toute information complémentaire.\\n\\nDans l'attente de votre réponse, je vous prie d'agréer, Madame, Monsieur, l'expression de mes salutations distinguées.\\n\\n[Votre Nom]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "challengeIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
