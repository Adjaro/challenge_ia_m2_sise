{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libaries\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching France Travail for keyword: Data Analyst\n",
      "Error searching for jobs: 404 Client Error: Not Found for url: https://www.francetravail.fr/recherche?query=Data%20Analyst\n",
      "==================================================\n",
      "Titre : Data engineer (H/F)\n",
      "Entreprise : IONE TALENTS & TECHNOLOGY\n",
      "Contrat : CDI\n",
      "Localisation : 92 - CHATILLON\n",
      "Description :\n",
      "IONE Talents & Technology, société de Conseil en Système d'Information avec une forte expertise métier créée par un expert dans le domaine de la data, IONE Talents & Technology c'est surtout un ensemble de consultant.e.s capables d'intervenir à tous les niveaux d'un Système d'Information.\n",
      "\n",
      "Si vous souhaitez rejoindre une entreprise à taille humaine où chaque employé peut avoir un réel rôle à jouer dans son développement, vous êtes au bon endroit.\n",
      "\n",
      "Dans le cadre de notre croissance sur la région d'ile de France, nous recrutons actuellement un(e) Data engineer IT en CDI pour pour intervenir chez nos clients dans la mise en place de nouveaux projets.\n",
      "\n",
      "\n",
      "Profil recherché : \n",
      "- Expérience significative dans un environnement Cloud (AWS, Azure, GCP) \n",
      "- Pratique confirmée des méthodes Agiles \n",
      " Compétences techniques \n",
      "- Maîtrise des langages de programmation : Python 3, Scala, Spark \n",
      "- Expertise en technologies Big Data : Hadoop, Kafka, Hive \n",
      "- Expérience approfondie des bases de données SQL et NoSQL : PostgreSQL, MongoDB, Cassandra \n",
      "- Maîtrise des outils DevOps : Docker, Git, Kubernetes (AKS) \n",
      "- Expérience en visualisation de données : Power BI, Tableau, Jupyter \n",
      "- La connaissance de Streamlit/Dash et des outils d'infrastructure as code (Terraform, Ansible) est un plus \n",
      "- Curiosité intellectuelle et passion pour le traitement des données massives \n",
      "- Excellentes capacités de communication en français et en anglais \n",
      "- Aptitude à travailler dans un environnement international\n",
      "- Maîtrise d'un ou plusieurs outils d'alimentation ETL (SSIS,Talend.),\n",
      "\n",
      "Au-delà de votre formation et de votre expertise, nous recherchons de futurs collaborateurs motivés par la perspective d'intégrer une structure à taille humaine en pleine croissance, exigeante et favorisant l'esprit d'équipe.\n",
      "==================================================\n",
      "Titre : DATA ARCHITECT (H/F)\n",
      "Entreprise : HARDIS GROUPE\n",
      "Contrat : CDI\n",
      "Localisation : 38 - Grenoble\n",
      "Description :\n",
      "Vous possédez une solide expertise dans les technologies de la Data, l'ingénierie et la modélisation des données. Votre grande curiosité technologique et votre capacité avérée à vous adapter rapidement à toutes les évolutions font de vous un professionnel désireux de contribuer au développement d'une nouvelle activité stratégique au sein d'une entreprise axée sur l'innovation et l'ambition. Rejoignez Hardis Group ! \n",
      "\n",
      "\n",
      "Au sein de notre entité Services Tech Solutions Grenoble, nous renforçons continuellement nos équipes pour consolider notre savoir-faire en matière de Data. Dans le cadre de l'expansion de notre activité Services, Hardis Group recherche activement un Architecte Data (H/F) pour renforcer nos équipes grenobloises. \n",
      "\n",
      "En qualité d'expert, vous interviendrez sur diverses missions telles que le conseil, l'expertise, les audits techniques, la cartographie des processus, la définition de Roadmaps et d'architectures Data (Cloud/On premise), l'aide au choix d'outils, les PoC/MVP, le coaching/formations, etc. Vous pourrez également contribuer aux activités d'avant-vente en étroite collaboration avec notre équipe d'ingénieurs d'affaires. \n",
      "\n",
      "Participer au recrutement de jeunes talents data, les qualifier et les guider dans leur plan de carrière sera une part importante de votre rôle. Vous prendrez activement part à leur formation et à leur montée en compétence. Vous serez également impliqué(e) dans la veille technologique et l'innovation, animant la communauté data de Tech Solutions Grenoble avec l'aide de vos pairs et de votre manager. \n",
      "\n",
      "En option, vous avez la possibilité d'assumer un rôle de People leader, encadrant directement de 5 à 10 personnes.\n",
      "\n",
      "Compétences requises : \n",
      "- Au moins 8 à 10 ans d'expérience, comprenant des missions techniques et de conseil. \n",
      "- Excellente connaissance des architectures Data (Cloud/On premise). \n",
      "- Maîtrise d'un ETL et d'un outil de dataviz au minimum. \n",
      "- Culture approfondie des différentes modélisations. \n",
      "- Importance accordée à l'appartenance à une équipe. \n",
      "- Vous êtes à l'aise en anglais et en français, à l'écrit comme à l'oral\n",
      "\n",
      "Votre autonomie et votre curiosité technique vous permettront de relever de nouveaux défis et d'y apporter des solutions. Le sens de l'écoute et de la communication, ainsi qu'une forte capacité d'adaptation, sont indispensables pour ce poste. Enfin, un esprit d'équipe sera un atout déterminant pour convaincre de votre intégration chez Hardis. \n",
      "\n",
      " \n",
      "\n",
      "Vous avez lu la description mais il semble vous manquer une ou deux compétences ? C'est aussi notre travail de vous aider à monter en compétence et vous accompagner dans l'évolution de votre carrière.  \n",
      "\n",
      "De notre côté, en plus de faire partie de cette belle aventure, nous vous proposons :  \n",
      "- Un poste en CDI, avec une mission de longue durée  \n",
      "- Un suivi dans votre mission et la perspective d'en avoir de nouvelles en régie ou en agence  \n",
      "- La participation à des événements d'agence comme nos LABS, nos journées agences trimestrielles, nos soirées d'agence et afterwork !  \n",
      "- Une ambiance conviviale et bienveillante  \n",
      "- Un très bon équilibre vie pro / vie perso (flexibilité horaire, 2 à 3 jours de télétravail hebdomadaires possibles)  \n",
      "- Un dispositif de formation adapté à votre montée en compétences  \n",
      "- Un CSE actif en local et une véritable stratégie RSE  \n",
      "- Et en plus : Mutuelle avantageuse, prime de participation et intéressement, tickets restaurant de 9€ / Jour pris en charge à 60% par l'employeur, remboursement de l'abonnement transports à 75%.\n",
      "==================================================\n",
      "Titre : PRACTICE MANAGER DATA (H/F)\n",
      "Entreprise : HARDIS GROUPE\n",
      "Contrat : CDI\n",
      "Localisation : 38 - Grenoble\n",
      "Description :\n",
      "Vous rejoindrez notre équipe à la Presqu'Ile, dans nos supers locaux avec vue sur nos belles montagnes Grenobloises ! Vous êtes plutôt team vélo - boulot - rando ? où tram - boulot - pain choco ?  Ici, il y en a pour tous les goûts !   \n",
      "\n",
      "Hardis Group poursuit son développement et recherche son Practice Manager (H/F) au sein de son activité Tech Solutions de Grenoble.  \n",
      " \n",
      "Composée de plus de 100 consultants passionnés, notre Agence accompagne nos clients locaux et nationaux, des grands comptes et de belles ETI locales, avec un positionnement de Pure Player dans les domaines de la Data/IA et de la transformation vers le Cloud, des savoirs-faire en architectures modernes : DevSecOps, API Management et une capacité à maitriser les phases amont et aval d'un projet IT (gestion des exigences et vérification). \n",
      "\n",
      "En tant que Practice Manager Data, vous aurez la charge de porter nos offres et superviser les projets aux côtés de nos chefs et directeurs de projets. Sous la responsabilité du Directeur d'Agence, vos missions seront les suivantes : \n",
      "- Définition et pilotage de la stratégie de la practice  \n",
      "- Porter les offres DATA du groupe auprès de nos équipes et de nos clients, prospects. \n",
      "- Participer aux avant-ventes en collaboration avec nos Ingénieurs d'Affaires et intervenez aux propositions commerciales \n",
      "- Assurer le suivi client en direct sur certains comptes et les relations avec les partenaires \n",
      "- Assurer le pilotage complet de projets d'un point de vue macro : financier, organisationnel et humain (gestion d'un PNL) \n",
      "- Encadrer les équipes projets composées de Business analystes, Chefs de projets et Ingénieurs développement \n",
      "- Prôner et suivre les initiatives de notre Communauté technique en matière d'innovation \n",
      "- Participer aux process de recrutement.\n",
      "\n",
      "Vous justifiez d'au moins 5 ans d'expérience dans la gestion de projets cloud, data ou digitaux. Vous avez également une expérience réussie dans le développement commercial, avec une expertise en transformation numérique, idéalement dans un rôle de Delivery ou Practice Manager. \n",
      "\n",
      "Bon communicant, vous démontrez un réel leadership et pilotez en front. Vous aimez la relation client et disposez d'une fibre commerciale. \n",
      "Vous avez l'habitude d'être en contact avec une multitude d'interlocuteurs et savez gérer vos priorités. \n",
      "Votre curiosité, votre dynamisme et votre proactivité feront les clés de votre succès ! \n",
      "  \n",
      "De notre côté, en plus de faire partie de cette belle aventure, nous vous proposons : \n",
      "- Un poste en CDI, dans nos supers locaux en plein cœur de la Presqu'Ile \n",
      "- La participation à des événements d'agence comme les Journées Agence, Petits déj et goûters du jeudi, participation aux évènements de nos communautés UX / UI, Tribu Agile, ou encore à divers évènements sportifs (Ekiden, Trophées de l'Isère / EDF Trophy.) \n",
      "- Une ambiance conviviale et bienveillante   \n",
      "- Un très bon équilibre vie pro / vie perso (flexibilité horaire, plusieurs jours de télétravail possible)   \n",
      "- Un dispositif de formation adapté à votre montée en compétences   \n",
      "- Un CSE actif en local et une véritable stratégie RSE   \n",
      "- Et en plus : Mutuelle avantageuse, prime de participation et intéressement, tickets restaurant de 9€ / Jour pris en charge à 60% par l'employeur, remboursement de l'abonnement transports à 75%.\n",
      "==================================================\n",
      "Titre : Data analyst (F/H)\n",
      "Entreprise : RANDSTAD\n",
      "Contrat : MIS\n",
      "Localisation : 69 - Genay\n",
      "Description :\n",
      "Vous serez directement rattaché au Superviseur approvisionnements et données produits, vos missions principales consistent à gérer les données de base (Master Datas), en particulier :\n",
      "\n",
      "Vous créez et mettez à jour les articles dans SAP, les nomenclatures, les gammes associées, les recettes\n",
      "\n",
      "Vous assurez le maintien à jour de la base de données étiquettes produits finis et transport, ainsi que la traçabilité.\n",
      "==================================================\n",
      "Titre : Data scientist (H/F) SALON TAF Toulouse 2025\n",
      "Entreprise : AOSIS CONSULTING\n",
      "Contrat : CDI\n",
      "Localisation : 31 - TOULOUSE\n",
      "Description :\n",
      "Concrètement qu'est-ce qu'on fait ?\n",
      "Nous proposons des Services, des Logiciels et de la Formation dans le domaine de la Business Intelligence, de la Data Science, de la Gouvernance et de la Visualisation de la donnée. L'Infrastructure et le Développement font également partie du panel de nos compétences.\n",
      "Notre leitmotiv ? Citoyenneté, écologie et sport avec des experts de la donnée.\n",
      "Notre objectif ? Porter encore plus haut et plus fort nos valeurs de sport, d'écologie et de citoyenneté et accompagner nos consultants dans leur montée en compétence.\n",
      "\n",
      "Le poste\n",
      "Dans le cadre d'une ouverture de poste, nous sommes à la recherche d'un.e Data Scientist pour l'un de nos clients.\n",
      "Un.e data scientist senior (5 ans d'expérience) très autonome dans ses analyses et explorations, expérimenté dans l'industrialisation des modèles dans des environnements cloud.\n",
      "\n",
      "Vous interviendrez sur toutes les étapes du projet, vous devrez :\n",
      "\n",
      "Identifier leurs difficultés et proposer des solutions\n",
      "Evaluer la qualité des données, les nettoyer, les agréger, et mener des études adhoc\n",
      "Concevoir, implémenter et comparer différents algorithmes et méthodes statistiques\n",
      "Concevoir et mener des protocoles de test en conditions réelles (magasins, entrepôts, .)\n",
      "Développer des outils de visualisation des données\n",
      "Mettre en production, maintenir et itérer sur les solutions\n",
      "\n",
      "Environnement technique: Python, SQL, Terraform, Bitbucket, Jenkins, Airflow, Docker, Kubernetes, GCP (BigQuery, Spark DataProc)\n",
      "\n",
      "Profil recherché\n",
      "Vous êtes issu.e d'un Master en informatique ou mathématiques appliquées.\n",
      "Vous avez à minima 5 années d'expériences en Data Science et maitrisez les algorithmes d'apprentissage statistique.\n",
      "Vous maîtrisez Python et SQL\n",
      "Vous avez une expérience dans le développement logiciel agile avec multiples contributeurs\n",
      "Vous avez une expérience du cloud, idéalement GCP\n",
      "\n",
      "Pourquoi nous rejoindre ?\n",
      "Parce que nous sommes une société à taille humaine\n",
      "Parce que nous nous engageons (réellement) dans des enjeux importants : l'écologie, la citoyenneté et le sport\n",
      "Mais aussi parce que nous aimons réaliser tout un tas d'activités : des jeux, des afterworks, des restaurants, ... et plein d'autres choses encore :)\n",
      "==================================================\n",
      "Titre : Data Scientist - Deep Learning en Oncologie (H/F)\n",
      "Entreprise : CENTRE LEON BERARD\n",
      "Contrat : CDI\n",
      "Localisation : 69 - LYON 08\n",
      "Description :\n",
      "Dans le cadre d'une création de poste, nous souhaitons renforcer notre Direction des Systèmes d'Information et des Données (DSID) sur un poste de : Data Scientist - Deep Learning en Oncologie (F/H) - CDI - temps plein - statut cadre au forfait jours (205 jours par an).\n",
      "\n",
      "Contexte :\n",
      "Alors que les approches de prédictions fondées sur des données de santé multiples et complexes (cliniques, images de tumeurs, moléculaires) sont de plus en plus recherchées, le Centre Léon Bérard (Centre de Lutte contre le Cancer de Lyon) souhaite mettre à profit ses données institutionnelles pour développer de telles approches au service des questions de la cancérologie. L'objectif est de débuter sur un projet structuré sur les tumeurs rares de l'ovaire ayant des jeux de données exhaustifs mais aussi de pouvoir développer des projets annexes sur les tumeurs plus fréquentes comme les tumeurs du poumon.\n",
      "\n",
      "Le cancer épithélial de l'ovaire (EOC) regroupe des tumeurs variées, dont le carcinome à cellules claires (OCCC), connu pour son mauvais pronostic aux stades avancés en raison d'une forte résistance aux traitements et d'un taux élevé de rechutes. Bien que les immunothérapies aient transformé le traitement de certains cancers, seules 26 % des patientes atteintes d'OCCC répondent favorablement aux traitements anti-PD-L1, ce qui souligne la nécessité d'explorer d'autres mécanismes de résistance et de mieux identifier les patientes répondeuses.\n",
      "\n",
      "Des mutations spécifiques, comme celles affectant ARID1A, PIK3CA et ZNF217, jouent un rôle clé dans le développement des OCCC et ouvrent des opportunités pour des traitements ciblés. De plus, les différences entre patientes caucasiennes et japonaises, notamment en termes de fréquence et de réponse au traitement, méritent une étude approfondie pour mieux comprendre les facteurs biologiques et génétiques influençant la maladie.\n",
      "\n",
      "Nous proposons de développer un modèle multimodal basé sur des données combinées : lames anatomopathologiques, données cliniques et RNA-seq. Ce modèle permettra d'évaluer le risque de rechute pour les patientes diagnostiquées à un stade précoce et de personnaliser les stratégies thérapeutiques.\n",
      "\n",
      "Missions :\n",
      "- Concevoir, développer et implémenter des modèles de deep learning pour prédire le risque de rechute à partir des données patientes ;\n",
      "- Travailler avec des données hétérogènes (cliniques, omiques et imagerie) en assurant leur intégration, leur prétraitement, et la gestion de leur qualité ;\n",
      "- Explorer différentes approches de modélisation, incluant les réseaux de neurones convolutifs (CNN), les réseaux de neurones récurrents (RNN), et d'autres architectures de deep learning adaptées aux données biomédicales ;\n",
      "- Collaborer avec des équipes de bioinformatique et d'oncologie pour valider et interpréter les résultats des modèles, en garantissant leur pertinence clinique ;\n",
      "- Rédiger des rapports et des publications scientifiques sur les méthodes et les résultats obtenus.\n",
      "\n",
      "Profil et Compétences :\n",
      "- Diplôme de Master en Data Science, Bioinformatique, Biostatistique, ou autre domaine connexe, avec une spécialisation en machine learning et deep learning.\n",
      "- Expérience avérée dans le développement et l'implémentation de modèles de deep learning, idéalement appliqués aux données de santé.\n",
      "- Maîtrise des langages Python et R, avec une expertise dans les bibliothèques de deep learning (TensorFlow, PyTorch, etc.)\n",
      "- Esprit d'équipe et forte capacité d'adaptation dans un environnement multidisciplinaire.\n",
      "- Ambition de monter en compétence sur le développement de l'IA au service de la cancérologie, gestion de projet de type recherche des données à la publication.\n",
      "- Curiosité pour les questions de santé liée au cancer, envie de développer différents projets.\n",
      "==================================================\n",
      "Titre : Data manager (H/F)\n",
      "Entreprise : DIGIXART ENTERTAINMENT\n",
      "Contrat : CDI\n",
      "Localisation : 34 - MONTPELLIER\n",
      "Description :\n",
      "L'équipe a grandi avec l'ambition d'offrir des expériences de jeu significatives et divertissantes à un large public sur consoles et pc.\n",
      "Soucieux du bien-être de nos collaborateurs, vous rejoindrez une équipe passionnée, où vous pourrez vous épanouir. Nous portons une attention particulière sur le Work life balance et partageons des valeurs fortes : Créativité, Humilité et Fiabilité.\n",
      "http://www.digixart.com\n",
      "\n",
      "Suivez aussi notre quotidien sur Instagram : @digixart_studio.\n",
      "_____________________\n",
      "\n",
      "À propos de Digixart\n",
      "Fondé en 2015, Digixart est un studio de développement de jeux vidéo basé à Montpellier, en France. À l'origine du grand succès Road 96, l'entreprise fait désormais partie de Plaion.\n",
      "\n",
      "L'équipe s'est agrandie avec l'ambition d'offrir des expériences de jeu engageantes et porteuses de sens à un large public sur consoles et PC.\n",
      "\n",
      "Axé sur le bien-être de nos employés, vous rejoindrez une équipe passionnée, où vous pourrez vous épanouir. Nous accordons une attention particulière à l'équilibre entre vie professionnelle et personnelle et partageons des valeurs fortes : Créativité, Humilité et Fiabilité.\n",
      "\n",
      "Suivez notre quotidien sur Instagram : @digixart_studio\n",
      " Site web : http://www.digixart.com\n",
      "\n",
      "Qualifications requises :\n",
      "\n",
      "DevOps\n",
      "- Maîtrise des logiciels de gestion de versions (Perforce et Plastic SCM / Unity Version Control en particulier) afin d'assurer la transition de Plastic vers Perforce (équipe, outils, données).\n",
      "- Automatisation des déploiements et des pipelines CI/CD pour les jeux et les outils internes.\n",
      "- Construction et déploiement des mises à jour du moteur (UE5).\n",
      "- Participation aux phases de tests de charge et surveillance de la robustesse des systèmes.\n",
      "- Collaboration avec les équipes pour résoudre les problèmes liés à la disponibilité, à la latence ou à l'évolutivité.\n",
      "- Mise en place des meilleures pratiques de sécurité sur l'ensemble des processus DevOps.\n",
      "\n",
      "IT\n",
      "- Gestion et maintenance de l'infrastructure informatique de 40 employés.\n",
      "- Anticipation et commande des machines et accessoires.\n",
      "- Administration des systèmes et des réseaux.\n",
      "- Surveillance et gestion des performances des systèmes.\n",
      "- Gestion du télétravail.\n",
      "- Gestion des données de projet.\n",
      "- Gestion des serveurs, du réseau intranet, des machines de build et des dev kits.\n",
      "- Gestion de la sécurité et application des règles.\n",
      "\n",
      "Compétences globales\n",
      "- Rester informé des nouvelles technologies et solutions logicielles.\n",
      "\n",
      "Compétences appréciées\n",
      "- SN-DBS\n",
      "- Connaissances en programmation serveur\n",
      "- Connaissance de Visual Studio\n",
      "- Connaissances en bases de données\n",
      "- Gestion à la fois des logiciels et du matériel\n",
      "\n",
      "Soft skills\n",
      "- Adaptabilité\n",
      "- Capacité à passer facilement d'une tâche à une autre\n",
      "- Curiosité\n",
      "- Rigueur\n",
      "- Réactivité\n",
      "\n",
      "Localisation\n",
      "* Nous privilégions un candidat déjà à Montpellier ou prêt à s'y installer.\n",
      "\n",
      "Ce que nous offrons\n",
      "- Un environnement de travail agréable et confortable\n",
      "- Une excellente ambiance au sein de l'équipe\n",
      "- Un équilibre entre vie professionnelle et vie personnelle\n",
      "- Horaires flexibles de 35h/semaine\n",
      "- Télétravail possible 2 jours par semaine\n",
      "==================================================\n",
      "Titre : Alternance : Statisticien(ienne) - Data Analyste (H/F)\n",
      "Entreprise : U R S S A F RHONE ALPES\n",
      "Contrat : CDD\n",
      "Localisation : 26 - VALENCE\n",
      "Description :\n",
      "Organisme de sécurité sociale chargé de la collecte des cotisations sociales et d'allocations familiales, l'Urssaf Rhône-Alpes, qui compte environ 1 750 collaborateurs, est présent sur 8 départements géographiques (Ain, Ardèche, Drôme, Isère, Loire, Rhône, Savoie et Haute-Savoie).\n",
      "\n",
      "Les missions de l'organisme permettent d'assurer la gestion de plus de 900 000 comptes cotisants et consistent à :\n",
      "\n",
      "- Accompagner ses usagers au bénéfice du développement économique et social\n",
      "\n",
      "- Assurer le financement de la protection sociale au quotidien\n",
      "\n",
      "- Garantir les droits sociaux et l'équité entre tous les acteurs économiques\n",
      "\n",
      "Les 4 valeurs centrales de l'Urssaf Rhône-Alpes : l'équité, la solidarité, la proximité et la proactivité.\n",
      "\n",
      "Sous la responsabilité d'un(e) tuteur/tutrice, vous intégrerez le Pôle Statistiques de la Sous-direction de la Performance, pôle composé de 10 collaborateurs répartis sur 5 sites.\n",
      "\n",
      "Description du poste : \n",
      "\n",
      "En tant que Statisticien en alternance, vous viendrez en appui sur différents sujets :  \n",
      "\n",
      "- Modélisation et Développement d'outils de data visualisation permettant la mise en valeur des données statistiques  \n",
      "- Développement informatique sous SLC/Python \n",
      "- Réalisation d'extractions de données via SQL \n",
      "- Appui méthodologique à l'équipe de statisticiens selon leurs besoins\n",
      "\n",
      "\n",
      "Votre formation : \n",
      "\n",
      "Vous êtes actuellement en formation de niveau Licence, Bachelor ou Master (1 ou 2) dans un des domaines de formation suivants :\n",
      "\n",
      "- Métiers du décisionnel et de la statistique\n",
      "- Modélisation statistique\n",
      "- Mathématiques appliqués, statistique\n",
      "\n",
      "Vous êtes disponible pour un contrat d'alternance compter de la rentrée universitaire 2025/2026.\n",
      "\n",
      "- Vous êtes rigoureux\n",
      "- L'esprit d'équipe\n",
      "\n",
      "Durée de l'alternance : 12 ou 24 mois\n",
      "\n",
      "Informations complémentaires : \n",
      "\n",
      "Poste ouvert sur nos sites de Lyon Foch / Saint-Etienne / Privas ou Valence\n",
      "\n",
      "- Prime d'intéressement au prorata temporis\n",
      "\n",
      "- Horaires variables s'inscrivant dans une amplitude comprise entre 7H10 et 18H30\n",
      "\n",
      "- Possibilité de bénéficier du télétravail (sous conditions)\n",
      "\n",
      "- Titre-restaurant avec 60% de part patronale,\n",
      "\n",
      "- Mobilité durable/RSO : Participation au transport (vélo, transport en commun et co-voiturage)\n",
      "\n",
      "- Prestations CSE\n",
      "\n",
      "\n",
      "Vous êtes passionné(e) par l'analyse de données, et vous souhaitez mettre à profit vos acquis théoriques ?\n",
      "\n",
      "Vous avez plein d'idées et aimez partir à la découverte de nouveaux outils ?\n",
      "\n",
      "Découvrir un environnement en évolution et aux enjeux multiples vous attire ?\n",
      "\n",
      "Si vous souhaitez enrichir votre parcours professionnel tout en déployant votre potentiel, n'attendez plus . Rejoignez nous !\n",
      "\n",
      "Déposez votre candidature impérativement sur le site La Sécu Recrute. Votre dossier doit inclure un CV ainsi qu'une lettre de motivation, précisant le rythme de votre alternance, et être soumis au plus tard le 23 mars 2025.\n",
      "\n",
      "Processus de sélection :\n",
      "\n",
      "1 - Analyse des candidatures et pré-qualification téléphonique si nécessaire\n",
      "2 - Entretien individuel avec un jury, prévu la première quinzaine d'avril\n",
      "\n",
      "Pour toute question ou demande d'informations complémentaires, vous pouvez contacter M. Éric Laboubée, Coordonnateur régional, à l'adresse eric.laboubee@urssaf.fr ou par téléphone au 04 72 09 24 22.\n",
      "\n",
      "L'Urssaf Rhône-Alpes s'engage également pendant la phase du processus de recrutement à être à l'écoute des candidats qui auraient besoin d'aménagements spécifiques et individuels afin de passer les tests et les entretiens dans les meilleures conditions.\n",
      "==================================================\n",
      "Titre : Alternance : Statisticien(ienne) - Data Analyste (H/F)\n",
      "Entreprise : U R S S A F RHONE ALPES\n",
      "Contrat : CDD\n",
      "Localisation : 07 - PRIVAS\n",
      "Description :\n",
      "Organisme de sécurité sociale chargé de la collecte des cotisations sociales et d'allocations familiales, l'Urssaf Rhône-Alpes, qui compte environ 1 750 collaborateurs, est présent sur 8 départements géographiques (Ain, Ardèche, Drôme, Isère, Loire, Rhône, Savoie et Haute-Savoie).\n",
      "\n",
      "Les missions de l'organisme permettent d'assurer la gestion de plus de 900 000 comptes cotisants et consistent à :\n",
      "\n",
      "- Accompagner ses usagers au bénéfice du développement économique et social\n",
      "\n",
      "- Assurer le financement de la protection sociale au quotidien\n",
      "\n",
      "- Garantir les droits sociaux et l'équité entre tous les acteurs économiques\n",
      "\n",
      "Les 4 valeurs centrales de l'Urssaf Rhône-Alpes : l'équité, la solidarité, la proximité et la proactivité.\n",
      "\n",
      "Sous la responsabilité d'un(e) tuteur/tutrice, vous intégrerez le Pôle Statistiques de la Sous-direction de la Performance, pôle composé de 10 collaborateurs répartis sur 5 sites.\n",
      "\n",
      "Description du poste : \n",
      "\n",
      "En tant que Statisticien en alternance, vous viendrez en appui sur différents sujets :  \n",
      "\n",
      "- Modélisation et Développement d'outils de data visualisation permettant la mise en valeur des données statistiques  \n",
      "- Développement informatique sous SLC/Python \n",
      "- Réalisation d'extractions de données via SQL \n",
      "- Appui méthodologique à l'équipe de statisticiens selon leurs besoins\n",
      "\n",
      "\n",
      "Votre formation : \n",
      "\n",
      "Vous êtes actuellement en formation de niveau Licence, Bachelor ou Master (1 ou 2) dans un des domaines de formation suivants :\n",
      "\n",
      "- Métiers du décisionnel et de la statistique\n",
      "- Modélisation statistique\n",
      "- Mathématiques appliqués, statistique\n",
      "\n",
      "Vous êtes disponible pour un contrat d'alternance compter de la rentrée universitaire 2025/2026.\n",
      "\n",
      "- Vous êtes rigoureux\n",
      "- L'esprit d'équipe\n",
      "\n",
      "Durée de l'alternance : 12 ou 24 mois\n",
      "\n",
      "Informations complémentaires : \n",
      "\n",
      "Poste ouvert sur nos sites de Lyon Foch / Saint-Etienne / Privas ou Valence\n",
      "\n",
      "- Prime d'intéressement au prorata temporis\n",
      "\n",
      "- Horaires variables s'inscrivant dans une amplitude comprise entre 7H10 et 18H30\n",
      "\n",
      "- Possibilité de bénéficier du télétravail (sous conditions)\n",
      "\n",
      "- Titre-restaurant avec 60% de part patronale,\n",
      "\n",
      "- Mobilité durable/RSO : Participation au transport (vélo, transport en commun et co-voiturage)\n",
      "\n",
      "- Prestations CSE\n",
      "\n",
      "\n",
      "Vous êtes passionné(e) par l'analyse de données, et vous souhaitez mettre à profit vos acquis théoriques ?\n",
      "\n",
      "Vous avez plein d'idées et aimez partir à la découverte de nouveaux outils ?\n",
      "\n",
      "Découvrir un environnement en évolution et aux enjeux multiples vous attire ?\n",
      "\n",
      "Si vous souhaitez enrichir votre parcours professionnel tout en déployant votre potentiel, n'attendez plus . Rejoignez nous !\n",
      "\n",
      "Déposez votre candidature impérativement sur le site La Sécu Recrute. Votre dossier doit inclure un CV ainsi qu'une lettre de motivation, précisant le rythme de votre alternance, et être soumis au plus tard le 23 mars 2025.\n",
      "\n",
      "Processus de sélection :\n",
      "\n",
      "1 - Analyse des candidatures et pré-qualification téléphonique si nécessaire\n",
      "2 - Entretien individuel avec un jury, prévu la première quinzaine d'avril\n",
      "\n",
      "Pour toute question ou demande d'informations complémentaires, vous pouvez contacter M. Éric Laboubée, Coordonnateur régional, à l'adresse eric.laboubee@urssaf.fr ou par téléphone au 04 72 09 24 22.\n",
      "\n",
      "L'Urssaf Rhône-Alpes s'engage également pendant la phase du processus de recrutement à être à l'écoute des candidats qui auraient besoin d'aménagements spécifiques et individuels afin de passer les tests et les entretiens dans les meilleures conditions.\n",
      "==================================================\n",
      "Titre : Alternance : Statisticien(ienne) - Data Analyste (H/F)\n",
      "Entreprise : U R S S A F RHONE ALPES\n",
      "Contrat : CDD\n",
      "Localisation : 42 - ST ETIENNE\n",
      "Description :\n",
      "Organisme de sécurité sociale chargé de la collecte des cotisations sociales et d'allocations familiales, l'Urssaf Rhône-Alpes, qui compte environ 1 750 collaborateurs, est présent sur 8 départements géographiques (Ain, Ardèche, Drôme, Isère, Loire, Rhône, Savoie et Haute-Savoie).\n",
      "\n",
      "Les missions de l'organisme permettent d'assurer la gestion de plus de 900 000 comptes cotisants et consistent à :\n",
      "\n",
      "- Accompagner ses usagers au bénéfice du développement économique et social\n",
      "\n",
      "- Assurer le financement de la protection sociale au quotidien\n",
      "\n",
      "- Garantir les droits sociaux et l'équité entre tous les acteurs économiques\n",
      "\n",
      "Les 4 valeurs centrales de l'Urssaf Rhône-Alpes : l'équité, la solidarité, la proximité et la proactivité.\n",
      "\n",
      "Sous la responsabilité d'un(e) tuteur/tutrice, vous intégrerez le Pôle Statistiques de la Sous-direction de la Performance, pôle composé de 10 collaborateurs répartis sur 5 sites.\n",
      "\n",
      "Description du poste : \n",
      "\n",
      "En tant que Statisticien en alternance, vous viendrez en appui sur différents sujets :  \n",
      "\n",
      "- Modélisation et Développement d'outils de data visualisation permettant la mise en valeur des données statistiques  \n",
      "- Développement informatique sous SLC/Python \n",
      "- Réalisation d'extractions de données via SQL \n",
      "- Appui méthodologique à l'équipe de statisticiens selon leurs besoins\n",
      "\n",
      "\n",
      "Votre formation : \n",
      "\n",
      "Vous êtes actuellement en formation de niveau Licence, Bachelor ou Master (1 ou 2) dans un des domaines de formation suivants :\n",
      "\n",
      "- Métiers du décisionnel et de la statistique\n",
      "- Modélisation statistique\n",
      "- Mathématiques appliqués, statistique\n",
      "\n",
      "Vous êtes disponible pour un contrat d'alternance compter de la rentrée universitaire 2025/2026.\n",
      "\n",
      "- Vous êtes rigoureux\n",
      "- L'esprit d'équipe\n",
      "\n",
      "Durée de l'alternance : 12 ou 24 mois\n",
      "\n",
      "Informations complémentaires : \n",
      "\n",
      "Poste ouvert sur nos sites de Lyon Foch / Saint-Etienne / Privas ou Valence\n",
      "\n",
      "- Prime d'intéressement au prorata temporis\n",
      "\n",
      "- Horaires variables s'inscrivant dans une amplitude comprise entre 7H10 et 18H30\n",
      "\n",
      "- Possibilité de bénéficier du télétravail (sous conditions)\n",
      "\n",
      "- Titre-restaurant avec 60% de part patronale,\n",
      "\n",
      "- Mobilité durable/RSO : Participation au transport (vélo, transport en commun et co-voiturage)\n",
      "\n",
      "- Prestations CSE\n",
      "\n",
      "\n",
      "Vous êtes passionné(e) par l'analyse de données, et vous souhaitez mettre à profit vos acquis théoriques ?\n",
      "\n",
      "Vous avez plein d'idées et aimez partir à la découverte de nouveaux outils ?\n",
      "\n",
      "Découvrir un environnement en évolution et aux enjeux multiples vous attire ?\n",
      "\n",
      "Si vous souhaitez enrichir votre parcours professionnel tout en déployant votre potentiel, n'attendez plus . Rejoignez nous !\n",
      "\n",
      "Déposez votre candidature impérativement sur le site La Sécu Recrute. Votre dossier doit inclure un CV ainsi qu'une lettre de motivation, précisant le rythme de votre alternance, et être soumis au plus tard le 23 mars 2025.\n",
      "\n",
      "Processus de sélection :\n",
      "\n",
      "1 - Analyse des candidatures et pré-qualification téléphonique si nécessaire\n",
      "2 - Entretien individuel avec un jury, prévu la première quinzaine d'avril\n",
      "\n",
      "Pour toute question ou demande d'informations complémentaires, vous pouvez contacter M. Éric Laboubée, Coordonnateur régional, à l'adresse eric.laboubee@urssaf.fr ou par téléphone au 04 72 09 24 22.\n",
      "\n",
      "L'Urssaf Rhône-Alpes s'engage également pendant la phase du processus de recrutement à être à l'écoute des candidats qui auraient besoin d'aménagements spécifiques et individuels afin de passer les tests et les entretiens dans les meilleures conditions.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "class ScrapingFrancetravail:\n",
    "    # En-têtes pour imiter un vrai navigateur\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://www.francetravail.fr\"  # Base URL for France Travail\n",
    "\n",
    "    def scrape(self, url):\n",
    "        \"\"\"\n",
    "        Scrape data from a single France Travail URL.\n",
    "        \n",
    "        :param url: The URL to scrape.\n",
    "        :return: Scraped data as a dictionary or None if an error occurs.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Make a request to the URL\n",
    "            print(f\"Scraping France Travail URL: {url}\")\n",
    "            response = requests.get(url, headers=self.headers)\n",
    "            response.raise_for_status()  # Raise an error for bad status codes\n",
    "\n",
    "            # Parse the HTML content\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "            # Extract relevant data\n",
    "            job_title = soup.find(\"h1\").text.strip() if soup.find(\"h1\") else \"No Title\"\n",
    "            job_description = soup.find(\"div\", class_=\"description\").text.strip() if soup.find(\"div\", class_=\"description\") else \"No Description\"\n",
    "            company = soup.find(\"span\", class_=\"company-name\").text.strip() if soup.find(\"span\", class_=\"company-name\") else \"No Company\"\n",
    "            location = soup.find(\"span\", class_=\"job-location\").text.strip() if soup.find(\"span\", class_=\"job-location\") else \"No Location\"\n",
    "\n",
    "            return {\n",
    "                \"title\": job_title,\n",
    "                \"company\": company,\n",
    "                \"location\": location,\n",
    "                \"description\": job_description,\n",
    "                \"url\": url\n",
    "            }\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error scraping {url}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def scrapMany(self, keyWord, max_results=10):\n",
    "        \"\"\"\n",
    "        Scrape multiple job listings based on a keyword.\n",
    "        \n",
    "        :param keyWord: The keyword to search for.\n",
    "        :param max_results: The maximum number of results to return.\n",
    "        :return: A list of scraped job listings.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Construct the search URL\n",
    "            search_url = f\"{self.base_url}/recherche?query={keyWord}\"\n",
    "            print(f\"Searching France Travail for keyword: {keyWord}\")\n",
    "            response = requests.get(search_url, headers=self.headers)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            # Parse the search results\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            job_listings = []\n",
    "\n",
    "            # Find job listing elements\n",
    "            job_elements = soup.find_all(\"div\", class_=\"job-listing\", limit=max_results)\n",
    "            for job in job_elements:\n",
    "                # Extract job link\n",
    "                job_link = job.find(\"a\")[\"href\"]\n",
    "                full_job_url = urljoin(self.base_url, job_link)\n",
    "\n",
    "                # Scrape individual job details\n",
    "                job_data = self.scrape(full_job_url)\n",
    "                if job_data:\n",
    "                    job_listings.append(job_data)\n",
    "\n",
    "            return job_listings\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error searching for jobs: {e}\")\n",
    "            return []\n",
    "\n",
    "    def get_access_token(self):\n",
    "        \"\"\"\n",
    "        Retrieve the access token for the Pôle Emploi API.\n",
    "        \n",
    "        :return: The access token.\n",
    "        \"\"\"\n",
    "        payload = {\n",
    "            \"grant_type\": \"client_credentials\",\n",
    "            \"client_id\": CLIENT_ID,\n",
    "            \"client_secret\": CLIENT_SECRET,\n",
    "            \"scope\": \"api_offresdemploiv2 o2dsoffre\"\n",
    "        }\n",
    "        try:\n",
    "            response = requests.post(TOKEN_URL, data=payload)\n",
    "            response.raise_for_status()\n",
    "            return response.json()[\"access_token\"]\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error retrieving access token: {e}\")\n",
    "            return None\n",
    "\n",
    "    def get_job_offers(self, access_token, keyword, location=None, limit=5):\n",
    "        \"\"\"\n",
    "        Fetch job offers from the Pôle Emploi API.\n",
    "        \n",
    "        :param access_token: The access token for the API.\n",
    "        :param keyword: The keyword to search for.\n",
    "        :param location: The postal code or location (optional).\n",
    "        :param limit: The maximum number of results to return.\n",
    "        :return: A list of job offers.\n",
    "        \"\"\"\n",
    "        url = \"https://api.pole-emploi.io/partenaire/offresdemploi/v2/offres/search\"\n",
    "        headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "        params = {\n",
    "            \"motsCles\": keyword,\n",
    "            \"lieuTravail.codePostal\": location,\n",
    "            \"range\": f\"0-{limit-1}\"  # Number of offers to retrieve\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, params=params)\n",
    "            response.raise_for_status()\n",
    "            return response.json().get(\"resultats\", [])\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error fetching job offers: {e}\")\n",
    "            return []\n",
    "\n",
    "    def display_offers(self, offers):\n",
    "        \"\"\"\n",
    "        Display job offers in a readable format.\n",
    "        \n",
    "        :param offers: A list of job offers.\n",
    "        \"\"\"\n",
    "        for offer in offers:\n",
    "            titre = offer.get(\"intitule\", \"N/A\")\n",
    "            entreprise = offer.get(\"entreprise\", {}).get(\"nom\", \"N/A\")\n",
    "            contrat = offer.get(\"typeContrat\", \"N/A\")\n",
    "            localisation = offer.get(\"lieuTravail\", {}).get(\"libelle\", \"N/A\")\n",
    "            description = offer.get(\"description\", \"N/A\")\n",
    "\n",
    "            print(\"=\" * 50)\n",
    "            print(f\"Titre : {titre}\")\n",
    "            print(f\"Entreprise : {entreprise}\")\n",
    "            print(f\"Contrat : {contrat}\")\n",
    "            print(f\"Localisation : {localisation}\")\n",
    "            print(f\"Description :\\n{description}\")\n",
    "\n",
    "# Exécution du script\n",
    "if __name__ == \"__main__\":\n",
    "    # Create an instance of ScrapingFrancetravail\n",
    "    scraper = ScrapingFrancetravail()\n",
    "\n",
    "    # Option 1: Scrape job listings from the website\n",
    "    keyword = \"Data Analyst\"\n",
    "    job_listings = scraper.scrapMany(keyWord=keyword, max_results=5)\n",
    "    for job in job_listings:\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Title: {job['title']}\")\n",
    "        print(f\"Company: {job['company']}\")\n",
    "        print(f\"Location: {job['location']}\")\n",
    "        print(f\"Description: {job['description']}\")\n",
    "        print(f\"URL: {job['url']}\")\n",
    "\n",
    "    # Option 2: Fetch job listings from the Pôle Emploi API\n",
    "    access_token = scraper.get_access_token()\n",
    "    if access_token:\n",
    "        keyword = \"Data *\"\n",
    "        location = \"75000\"  # Code postal (optionnel)\n",
    "        offers = scraper.get_job_offers(access_token, keyword, location, limit=10)\n",
    "        scraper.display_offers(offers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# information about the job\n",
    "url = \"https://candidat.francetravail.fr/offres/recherche/detail/189KKQR\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titre : Offre n° 189KKQRDéveloppeur Full Stack .Net  (H/F)\n",
      "Entreprise : Non renseigné\n",
      "Contrat : Non renseigné\n",
      "Localisation : Non renseigné\n",
      "Description :\n",
      "Rejoignez une équipe sympathique et dynamique, dans un groupe en forte croissance !\n",
      "\n",
      "POSTE et MISSION\n",
      "\n",
      "Au sein du pôle «Développement et R&D», vous serez intégré-e à l'équipe chargée du développement de nos Suites logicielles de gestion des risques Qualité, Sécurité, Environnement. A ce titre, vous travaillerez sur la conception et le développement de nos logiciels (algorithmes, IHM, API, persistance, Front End, Back End, etc) :\n",
      "\n",
      "- Intégrez une petite équipe d'ingénieurs, stable, qui travaille en étroite collaboration avec les autres services (notamment métier), selon la méthode Agile (Scrum), sur des projets durables,\n",
      "\n",
      "- A partir de spécifications fonctionnelles, vous concevez et développez les évolutions et nouvelles fonctionnalités de nos applications web en ASP.Net MVC (C#, Javascript, frontEnd) et de notre moteur métier (en C#, C++, backEnd),\n",
      "\n",
      "- Vous préparez avec l'équipe, la prochaine génération de notre application (technologies, langages, frameworks, processus seront à définir). Vos expériences sont des atouts !\n",
      "\n",
      "- Vous contribuez à la veille technologique, à la stratégie de tests, et à la hotline de 2ème niveau (en soutien à l'équipe Hotline)\n",
      "\n",
      "- Travail en équipe, autonomie, rigueur, souplesse et sens du service client sont indispensables\n",
      "\n",
      "Nous utilisons actuellement Visual Studio 2022, GIT, Jira, Azure DevOps, N8N (Middleware). Nous nous appuyons sur une base de données objet propriétaire et SQL Server. Nous gérons les évolutions de nos solutions en client lourd, Web hébergé - Saas et responsive.\n",
      "\n",
      "Lieu de travail et télétravail à convenir, en France métropolitaine\n",
      "\n",
      "Rémunération à convenir (35 à 50 K€ selon parcours). Mutuelle avantageuse, chèques-déjeuner, avantages CSE. Idéalement temps plein. Horaires de bureau, pas d'astreinte. Opportunités de carrières, mobilité à l'International.\n"
     ]
    }
   ],
   "source": [
    "# En-têtes pour imiter un vrai navigateur\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Envoyer la requête HTTP\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = bs(response.text, \"html.parser\")\n",
    "\n",
    "    # Extraction du titre de l'offre\n",
    "    titre = soup.find(\"h1\").text.strip() if soup.find(\"h1\") else \"Non disponible\"\n",
    "\n",
    "    # Extraction du nom de l'entreprise\n",
    "    entreprise = soup.find(\"div\", class_=\"t4\").text.strip() if soup.find(\"div\", class_=\"t4\") else \"Non renseigné\"\n",
    "\n",
    "    # Extraction de la description du poste\n",
    "    description = soup.find(\"div\", class_=\"description\").text.strip() if soup.find(\"div\", class_=\"description\") else \"Non disponible\"\n",
    "\n",
    "    # Extraction du type de contrat\n",
    "    contrat = soup.find(\"span\", class_=\"contrat\").text.strip() if soup.find(\"span\", class_=\"contrat\") else \"Non renseigné\"\n",
    "\n",
    "    # Extraction de la localisation\n",
    "    localisation = soup.find(\"span\", class_=\"lieu\").text.strip() if soup.find(\"span\", class_=\"lieu\") else \"Non renseigné\"\n",
    "\n",
    "    # Affichage des résultats\n",
    "    print(f\"Titre : {titre}\")\n",
    "    print(f\"Entreprise : {entreprise}\")\n",
    "    print(f\"Contrat : {contrat}\")\n",
    "    print(f\"Localisation : {localisation}\")\n",
    "    print(f\"Description :\\n{description}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Échec de la récupération des données. Code HTTP : {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Paramètres d'authentification (remplace avec tes propres identifiants)\n",
    "CLIENT_ID = \"PAR_sise_6ecb7de16380e8802b4565918fcd2dab184e5916e58cba3b4ba4e09a9d124064\"\n",
    "CLIENT_SECRET = \"fdd7ac75d36925e84f2fcbe0ed7cecf9619d01553708c4ac58f2c648e6bf3927\"\n",
    "TOKEN_URL = \"https://entreprise.pole-emploi.fr/connexion/oauth2/access_token?realm=/partenaire\"\n",
    "\n",
    "# Récupération du token d'accès\n",
    "def get_access_token():\n",
    "    payload = {\n",
    "        \"grant_type\": \"client_credentials\",\n",
    "        \"client_id\": CLIENT_ID,\n",
    "        \"client_secret\": CLIENT_SECRET,\n",
    "        \"scope\": \"api_offresdemploiv2 o2dsoffre\"\n",
    "    }\n",
    "    response = requests.post(TOKEN_URL, data=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"access_token\"]\n",
    "\n",
    "# Récupération des offres d'emploi\n",
    "def get_job_offers(access_token, keyword, location=None, limit=5):\n",
    "    url = \"https://api.pole-emploi.io/partenaire/offresdemploi/v2/offres/search\"\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "    params = {\n",
    "        \"motsCles\": keyword,\n",
    "        \"lieuTravail.codePostal\": location,\n",
    "        \"range\": f\"0-{limit-1}\"  # Nombre d'offres à récupérer\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    return response.json().get(\"resultats\", [])\n",
    "\n",
    "# Affichage des offres\n",
    "def display_offers(offers):\n",
    "    for offer in offers:\n",
    "        titre = offer.get(\"intitule\", \"N/A\")\n",
    "        entreprise = offer.get(\"entreprise\", {}).get(\"nom\", \"N/A\")\n",
    "        contrat = offer.get(\"typeContrat\", \"N/A\")\n",
    "        localisation = offer.get(\"lieuTravail\", {}).get(\"libelle\", \"N/A\")\n",
    "        description = offer.get(\"description\", \"N/A\")\n",
    "\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Titre : {titre}\")\n",
    "        print(f\"Entreprise : {entreprise}\")\n",
    "        print(f\"Contrat : {contrat}\")\n",
    "        print(f\"Localisation : {localisation}\")\n",
    "        print(f\"Description :\\n{description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Titre : DATA ARCHITECT (H/F)\n",
      "Entreprise : HARDIS GROUPE\n",
      "Contrat : CDI\n",
      "Localisation : 38 - Grenoble\n",
      "Description :\n",
      "Vous possédez une solide expertise dans les technologies de la Data, l'ingénierie et la modélisation des données. Votre grande curiosité technologique et votre capacité avérée à vous adapter rapidement à toutes les évolutions font de vous un professionnel désireux de contribuer au développement d'une nouvelle activité stratégique au sein d'une entreprise axée sur l'innovation et l'ambition. Rejoignez Hardis Group ! \n",
      "\n",
      "\n",
      "Au sein de notre entité Services Tech Solutions Grenoble, nous renforçons continuellement nos équipes pour consolider notre savoir-faire en matière de Data. Dans le cadre de l'expansion de notre activité Services, Hardis Group recherche activement un Architecte Data (H/F) pour renforcer nos équipes grenobloises. \n",
      "\n",
      "En qualité d'expert, vous interviendrez sur diverses missions telles que le conseil, l'expertise, les audits techniques, la cartographie des processus, la définition de Roadmaps et d'architectures Data (Cloud/On premise), l'aide au choix d'outils, les PoC/MVP, le coaching/formations, etc. Vous pourrez également contribuer aux activités d'avant-vente en étroite collaboration avec notre équipe d'ingénieurs d'affaires. \n",
      "\n",
      "Participer au recrutement de jeunes talents data, les qualifier et les guider dans leur plan de carrière sera une part importante de votre rôle. Vous prendrez activement part à leur formation et à leur montée en compétence. Vous serez également impliqué(e) dans la veille technologique et l'innovation, animant la communauté data de Tech Solutions Grenoble avec l'aide de vos pairs et de votre manager. \n",
      "\n",
      "En option, vous avez la possibilité d'assumer un rôle de People leader, encadrant directement de 5 à 10 personnes.\n",
      "\n",
      "Compétences requises : \n",
      "- Au moins 8 à 10 ans d'expérience, comprenant des missions techniques et de conseil. \n",
      "- Excellente connaissance des architectures Data (Cloud/On premise). \n",
      "- Maîtrise d'un ETL et d'un outil de dataviz au minimum. \n",
      "- Culture approfondie des différentes modélisations. \n",
      "- Importance accordée à l'appartenance à une équipe. \n",
      "- Vous êtes à l'aise en anglais et en français, à l'écrit comme à l'oral\n",
      "\n",
      "Votre autonomie et votre curiosité technique vous permettront de relever de nouveaux défis et d'y apporter des solutions. Le sens de l'écoute et de la communication, ainsi qu'une forte capacité d'adaptation, sont indispensables pour ce poste. Enfin, un esprit d'équipe sera un atout déterminant pour convaincre de votre intégration chez Hardis. \n",
      "\n",
      " \n",
      "\n",
      "Vous avez lu la description mais il semble vous manquer une ou deux compétences ? C'est aussi notre travail de vous aider à monter en compétence et vous accompagner dans l'évolution de votre carrière.  \n",
      "\n",
      "De notre côté, en plus de faire partie de cette belle aventure, nous vous proposons :  \n",
      "- Un poste en CDI, avec une mission de longue durée  \n",
      "- Un suivi dans votre mission et la perspective d'en avoir de nouvelles en régie ou en agence  \n",
      "- La participation à des événements d'agence comme nos LABS, nos journées agences trimestrielles, nos soirées d'agence et afterwork !  \n",
      "- Une ambiance conviviale et bienveillante  \n",
      "- Un très bon équilibre vie pro / vie perso (flexibilité horaire, 2 à 3 jours de télétravail hebdomadaires possibles)  \n",
      "- Un dispositif de formation adapté à votre montée en compétences  \n",
      "- Un CSE actif en local et une véritable stratégie RSE  \n",
      "- Et en plus : Mutuelle avantageuse, prime de participation et intéressement, tickets restaurant de 9€ / Jour pris en charge à 60% par l'employeur, remboursement de l'abonnement transports à 75%.\n",
      "==================================================\n",
      "Titre : PRACTICE MANAGER DATA (H/F)\n",
      "Entreprise : HARDIS GROUPE\n",
      "Contrat : CDI\n",
      "Localisation : 38 - Grenoble\n",
      "Description :\n",
      "Vous rejoindrez notre équipe à la Presqu'Ile, dans nos supers locaux avec vue sur nos belles montagnes Grenobloises ! Vous êtes plutôt team vélo - boulot - rando ? où tram - boulot - pain choco ?  Ici, il y en a pour tous les goûts !   \n",
      "\n",
      "Hardis Group poursuit son développement et recherche son Practice Manager (H/F) au sein de son activité Tech Solutions de Grenoble.  \n",
      " \n",
      "Composée de plus de 100 consultants passionnés, notre Agence accompagne nos clients locaux et nationaux, des grands comptes et de belles ETI locales, avec un positionnement de Pure Player dans les domaines de la Data/IA et de la transformation vers le Cloud, des savoirs-faire en architectures modernes : DevSecOps, API Management et une capacité à maitriser les phases amont et aval d'un projet IT (gestion des exigences et vérification). \n",
      "\n",
      "En tant que Practice Manager Data, vous aurez la charge de porter nos offres et superviser les projets aux côtés de nos chefs et directeurs de projets. Sous la responsabilité du Directeur d'Agence, vos missions seront les suivantes : \n",
      "- Définition et pilotage de la stratégie de la practice  \n",
      "- Porter les offres DATA du groupe auprès de nos équipes et de nos clients, prospects. \n",
      "- Participer aux avant-ventes en collaboration avec nos Ingénieurs d'Affaires et intervenez aux propositions commerciales \n",
      "- Assurer le suivi client en direct sur certains comptes et les relations avec les partenaires \n",
      "- Assurer le pilotage complet de projets d'un point de vue macro : financier, organisationnel et humain (gestion d'un PNL) \n",
      "- Encadrer les équipes projets composées de Business analystes, Chefs de projets et Ingénieurs développement \n",
      "- Prôner et suivre les initiatives de notre Communauté technique en matière d'innovation \n",
      "- Participer aux process de recrutement.\n",
      "\n",
      "Vous justifiez d'au moins 5 ans d'expérience dans la gestion de projets cloud, data ou digitaux. Vous avez également une expérience réussie dans le développement commercial, avec une expertise en transformation numérique, idéalement dans un rôle de Delivery ou Practice Manager. \n",
      "\n",
      "Bon communicant, vous démontrez un réel leadership et pilotez en front. Vous aimez la relation client et disposez d'une fibre commerciale. \n",
      "Vous avez l'habitude d'être en contact avec une multitude d'interlocuteurs et savez gérer vos priorités. \n",
      "Votre curiosité, votre dynamisme et votre proactivité feront les clés de votre succès ! \n",
      "  \n",
      "De notre côté, en plus de faire partie de cette belle aventure, nous vous proposons : \n",
      "- Un poste en CDI, dans nos supers locaux en plein cœur de la Presqu'Ile \n",
      "- La participation à des événements d'agence comme les Journées Agence, Petits déj et goûters du jeudi, participation aux évènements de nos communautés UX / UI, Tribu Agile, ou encore à divers évènements sportifs (Ekiden, Trophées de l'Isère / EDF Trophy.) \n",
      "- Une ambiance conviviale et bienveillante   \n",
      "- Un très bon équilibre vie pro / vie perso (flexibilité horaire, plusieurs jours de télétravail possible)   \n",
      "- Un dispositif de formation adapté à votre montée en compétences   \n",
      "- Un CSE actif en local et une véritable stratégie RSE   \n",
      "- Et en plus : Mutuelle avantageuse, prime de participation et intéressement, tickets restaurant de 9€ / Jour pris en charge à 60% par l'employeur, remboursement de l'abonnement transports à 75%.\n",
      "==================================================\n",
      "Titre : Data analyst (F/H)\n",
      "Entreprise : RANDSTAD\n",
      "Contrat : MIS\n",
      "Localisation : 69 - Genay\n",
      "Description :\n",
      "Vous serez directement rattaché au Superviseur approvisionnements et données produits, vos missions principales consistent à gérer les données de base (Master Datas), en particulier :\n",
      "\n",
      "Vous créez et mettez à jour les articles dans SAP, les nomenclatures, les gammes associées, les recettes\n",
      "\n",
      "Vous assurez le maintien à jour de la base de données étiquettes produits finis et transport, ainsi que la traçabilité.\n",
      "==================================================\n",
      "Titre : Data scientist (H/F) SALON TAF Toulouse 2025\n",
      "Entreprise : AOSIS CONSULTING\n",
      "Contrat : CDI\n",
      "Localisation : 31 - TOULOUSE\n",
      "Description :\n",
      "Concrètement qu'est-ce qu'on fait ?\n",
      "Nous proposons des Services, des Logiciels et de la Formation dans le domaine de la Business Intelligence, de la Data Science, de la Gouvernance et de la Visualisation de la donnée. L'Infrastructure et le Développement font également partie du panel de nos compétences.\n",
      "Notre leitmotiv ? Citoyenneté, écologie et sport avec des experts de la donnée.\n",
      "Notre objectif ? Porter encore plus haut et plus fort nos valeurs de sport, d'écologie et de citoyenneté et accompagner nos consultants dans leur montée en compétence.\n",
      "\n",
      "Le poste\n",
      "Dans le cadre d'une ouverture de poste, nous sommes à la recherche d'un.e Data Scientist pour l'un de nos clients.\n",
      "Un.e data scientist senior (5 ans d'expérience) très autonome dans ses analyses et explorations, expérimenté dans l'industrialisation des modèles dans des environnements cloud.\n",
      "\n",
      "Vous interviendrez sur toutes les étapes du projet, vous devrez :\n",
      "\n",
      "Identifier leurs difficultés et proposer des solutions\n",
      "Evaluer la qualité des données, les nettoyer, les agréger, et mener des études adhoc\n",
      "Concevoir, implémenter et comparer différents algorithmes et méthodes statistiques\n",
      "Concevoir et mener des protocoles de test en conditions réelles (magasins, entrepôts, .)\n",
      "Développer des outils de visualisation des données\n",
      "Mettre en production, maintenir et itérer sur les solutions\n",
      "\n",
      "Environnement technique: Python, SQL, Terraform, Bitbucket, Jenkins, Airflow, Docker, Kubernetes, GCP (BigQuery, Spark DataProc)\n",
      "\n",
      "Profil recherché\n",
      "Vous êtes issu.e d'un Master en informatique ou mathématiques appliquées.\n",
      "Vous avez à minima 5 années d'expériences en Data Science et maitrisez les algorithmes d'apprentissage statistique.\n",
      "Vous maîtrisez Python et SQL\n",
      "Vous avez une expérience dans le développement logiciel agile avec multiples contributeurs\n",
      "Vous avez une expérience du cloud, idéalement GCP\n",
      "\n",
      "Pourquoi nous rejoindre ?\n",
      "Parce que nous sommes une société à taille humaine\n",
      "Parce que nous nous engageons (réellement) dans des enjeux importants : l'écologie, la citoyenneté et le sport\n",
      "Mais aussi parce que nous aimons réaliser tout un tas d'activités : des jeux, des afterworks, des restaurants, ... et plein d'autres choses encore :)\n",
      "==================================================\n",
      "Titre : Data Scientist - Deep Learning en Oncologie (H/F)\n",
      "Entreprise : CENTRE LEON BERARD\n",
      "Contrat : CDI\n",
      "Localisation : 69 - LYON 08\n",
      "Description :\n",
      "Dans le cadre d'une création de poste, nous souhaitons renforcer notre Direction des Systèmes d'Information et des Données (DSID) sur un poste de : Data Scientist - Deep Learning en Oncologie (F/H) - CDI - temps plein - statut cadre au forfait jours (205 jours par an).\n",
      "\n",
      "Contexte :\n",
      "Alors que les approches de prédictions fondées sur des données de santé multiples et complexes (cliniques, images de tumeurs, moléculaires) sont de plus en plus recherchées, le Centre Léon Bérard (Centre de Lutte contre le Cancer de Lyon) souhaite mettre à profit ses données institutionnelles pour développer de telles approches au service des questions de la cancérologie. L'objectif est de débuter sur un projet structuré sur les tumeurs rares de l'ovaire ayant des jeux de données exhaustifs mais aussi de pouvoir développer des projets annexes sur les tumeurs plus fréquentes comme les tumeurs du poumon.\n",
      "\n",
      "Le cancer épithélial de l'ovaire (EOC) regroupe des tumeurs variées, dont le carcinome à cellules claires (OCCC), connu pour son mauvais pronostic aux stades avancés en raison d'une forte résistance aux traitements et d'un taux élevé de rechutes. Bien que les immunothérapies aient transformé le traitement de certains cancers, seules 26 % des patientes atteintes d'OCCC répondent favorablement aux traitements anti-PD-L1, ce qui souligne la nécessité d'explorer d'autres mécanismes de résistance et de mieux identifier les patientes répondeuses.\n",
      "\n",
      "Des mutations spécifiques, comme celles affectant ARID1A, PIK3CA et ZNF217, jouent un rôle clé dans le développement des OCCC et ouvrent des opportunités pour des traitements ciblés. De plus, les différences entre patientes caucasiennes et japonaises, notamment en termes de fréquence et de réponse au traitement, méritent une étude approfondie pour mieux comprendre les facteurs biologiques et génétiques influençant la maladie.\n",
      "\n",
      "Nous proposons de développer un modèle multimodal basé sur des données combinées : lames anatomopathologiques, données cliniques et RNA-seq. Ce modèle permettra d'évaluer le risque de rechute pour les patientes diagnostiquées à un stade précoce et de personnaliser les stratégies thérapeutiques.\n",
      "\n",
      "Missions :\n",
      "- Concevoir, développer et implémenter des modèles de deep learning pour prédire le risque de rechute à partir des données patientes ;\n",
      "- Travailler avec des données hétérogènes (cliniques, omiques et imagerie) en assurant leur intégration, leur prétraitement, et la gestion de leur qualité ;\n",
      "- Explorer différentes approches de modélisation, incluant les réseaux de neurones convolutifs (CNN), les réseaux de neurones récurrents (RNN), et d'autres architectures de deep learning adaptées aux données biomédicales ;\n",
      "- Collaborer avec des équipes de bioinformatique et d'oncologie pour valider et interpréter les résultats des modèles, en garantissant leur pertinence clinique ;\n",
      "- Rédiger des rapports et des publications scientifiques sur les méthodes et les résultats obtenus.\n",
      "\n",
      "Profil et Compétences :\n",
      "- Diplôme de Master en Data Science, Bioinformatique, Biostatistique, ou autre domaine connexe, avec une spécialisation en machine learning et deep learning.\n",
      "- Expérience avérée dans le développement et l'implémentation de modèles de deep learning, idéalement appliqués aux données de santé.\n",
      "- Maîtrise des langages Python et R, avec une expertise dans les bibliothèques de deep learning (TensorFlow, PyTorch, etc.)\n",
      "- Esprit d'équipe et forte capacité d'adaptation dans un environnement multidisciplinaire.\n",
      "- Ambition de monter en compétence sur le développement de l'IA au service de la cancérologie, gestion de projet de type recherche des données à la publication.\n",
      "- Curiosité pour les questions de santé liée au cancer, envie de développer différents projets.\n"
     ]
    }
   ],
   "source": [
    "# Exécution du script\n",
    "if __name__ == \"__main__\":\n",
    "    access_token = get_access_token()\n",
    "    keyword = \"Data *\"  # Change selon le type de poste recherché\n",
    "    location = \"75000\"  # Code postal (optionnel)\n",
    "\n",
    "    offers = get_job_offers(access_token, keyword, location, limit=5)\n",
    "    display_offers(offers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "challenge_ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
